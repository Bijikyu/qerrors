This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
.github/
  workflows/
    node-test.yml
.local/
  state/
    replit/
      agent/
        .latest.json
.upm/
  store.json
attached_assets/
  Pasted--Centralized-Error-Handling-Utility-This-module-provides-standardized-error-handling-pa-1750137599049_1750137599050.txt
  Pasted--Centralized-Error-Handling-Utility-This-module-provides-standardized-error-handling-pa-1750139496255_1750139496256.txt
  Pasted--Enhanced-Logging-System-for-Scrooge-Payment-API-This-module-provides-a-comprehensive-l-1750141501295_1750141501296.txt
  Pasted--Handles-controller-errors-with-standardized-response-Rationale-Provides-consistent-error-h-1750140224456_1750140224457.txt
  Pasted--Rationale-API-responses-should-be-consistent-and-safe-This-function-ensures-all-JSON-resp-1750140247024_1750140247024.txt
  Pasted-const-logEntry-this-createLogEntry-levelConfig-message-context-requestId-Console-output-1750141515603_1750141515603.txt
lib/
  config.js
  envUtils.js
  errorTypes.js
  logger.js
  qerrors.js
  queueManager.js
  sanitization.js
  utils.js
stubs/
  axios.js
  denque.js
  escape-html.js
  lru-cache.js
  p-limit.js
  qtests.js
  winston-daily-rotate-file.js
  winston.js
test/
  analyzeError.test.js
  centralizedErrorHandling.test.js
  cleanupMetrics.test.js
  clearCache.test.js
  configFunctions.test.js
  contextStringify.test.js
  enhancedLogging.test.js
  envUtils.test.js
  errorTypes.test.js
  index.test.js
  initWarn.test.js
  integration.qerrors.test.js
  logger.test.js
  loggerFunctions.test.js
  logLevel.test.js
  maxFreeSockets.test.js
  maxSockets.test.js
  maxTokens.test.js
  postWithRetry.test.js
  qerrors.test.js
  queue.test.js
  serviceName.test.js
  timeout.test.js
  verbose.test.js
  verboseLog.test.js
.gitignore
.replit
AGENTS.md
index.js
package.json
README.md
replit.md
replit.nix
setup.js
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path=".local/state/replit/agent/.latest.json">
{"latest": "main"}
</file>

<file path=".upm/store.json">
{"version":2,"languages":{"nodejs-npm":{"specfileHash":"bc95d689633157aa325a7ee4062e65af","lockfileHash":"71a847f92612eaa24a5c935a3f1e3d7e"}}}
</file>

<file path="test/initWarn.test.js">
const test = require('node:test'); //node test runner
const assert = require('node:assert/strict'); //assert helpers
const qtests = require('qtests'); //stub helper

function loadQerrors() {
  delete require.cache[require.resolve('../lib/qerrors')];
  return require('../lib/qerrors');
}

test('warn when limits exceed safe threshold', async () => {
  const origConc = process.env.QERRORS_CONCURRENCY; //backup concurrency
  const origQueue = process.env.QERRORS_QUEUE_LIMIT; //backup queue limit
  process.env.QERRORS_CONCURRENCY = '2000'; //excessive concurrency
  process.env.QERRORS_QUEUE_LIMIT = '2000'; //excessive queue
  const logger = await require('../lib/logger'); //logger instance
  let warned = false; //track warn calls
  const restoreWarn = qtests.stubMethod(logger, 'warn', () => { warned = true; });
  try {
    loadQerrors(); //module initialization triggers warning
    await Promise.resolve(); //allow async logger call
  } finally {
    restoreWarn(); //restore logger.warn
    if (origConc === undefined) { delete process.env.QERRORS_CONCURRENCY; } else { process.env.QERRORS_CONCURRENCY = origConc; }
    if (origQueue === undefined) { delete process.env.QERRORS_QUEUE_LIMIT; } else { process.env.QERRORS_QUEUE_LIMIT = origQueue; }
    delete require.cache[require.resolve('../lib/qerrors')]; //reset module
    require('../lib/qerrors'); //reload defaults
  }
  assert.equal(warned, true); //expect warning emitted
});

test('limits below custom threshold do not warn', async () => { //verify config clamp usage
  const origConc = process.env.QERRORS_CONCURRENCY; //backup concurrency value
  const origQueue = process.env.QERRORS_QUEUE_LIMIT; //backup queue value
  const origSafe = process.env.QERRORS_SAFE_THRESHOLD; //backup safe threshold
  process.env.QERRORS_CONCURRENCY = '1500'; //value above default threshold
  process.env.QERRORS_QUEUE_LIMIT = '1500'; //value above default threshold
  process.env.QERRORS_SAFE_THRESHOLD = '2000'; //raise threshold so no warn expected
  const logger = await require('../lib/logger'); //logger instance
  let warned = false; //track warn state
  const restoreWarn = qtests.stubMethod(logger, 'warn', () => { warned = true; });
  try {
    loadQerrors(); //reload with custom env values
    await Promise.resolve(); //allow async logger call
  } finally {
    restoreWarn(); //restore logger.warn method
    if (origConc === undefined) { delete process.env.QERRORS_CONCURRENCY; } else { process.env.QERRORS_CONCURRENCY = origConc; }
    if (origQueue === undefined) { delete process.env.QERRORS_QUEUE_LIMIT; } else { process.env.QERRORS_QUEUE_LIMIT = origQueue; }
    if (origSafe === undefined) { delete process.env.QERRORS_SAFE_THRESHOLD; } else { process.env.QERRORS_SAFE_THRESHOLD = origSafe; }
    delete require.cache[require.resolve('../lib/qerrors')]; //reset cached module
    require('../lib/qerrors'); //restore defaults
  }
  assert.equal(warned, false); //expect no warning when within custom threshold
});
</file>

<file path="test/integration.qerrors.test.js">
const test = require('node:test'); //node test runner
const assert = require('node:assert/strict'); //strict assertions
const qtests = require('qtests'); //stubbing utilities

const qerrors = require('../lib/qerrors'); //module under test
const { axiosInstance } = qerrors; //axios instance used by qerrors
const logger = require('../lib/logger'); //logger promise instance

function createRes() { //minimal express like response mock
  return {
    headersSent: false, //flag for header state
    statusCode: null, //status tracking
    payload: null, //captured payload
    status(code) { this.statusCode = code; return this; }, //status setter
    json(data) { this.payload = data; return this; }, //json payload
    send(html) { this.payload = html; return this; } //html payload
  };
}

test('qerrors integration logs error and analyzes context', async () => {
  const restoreAxios = qtests.stubMethod(axiosInstance, 'post', async () => ({ data: { choices: [{ message: { content: { ok: true } } }] } })); //stub axiosInstance.post with object content
  let logArg; //capture logger.error argument
  const realLogger = await logger; //resolve logger promise
  const origLog = realLogger.error; //store original function
  realLogger.error = (...args) => { logArg = args[0]; return origLog.apply(realLogger, args); }; //wrap logger.error to capture call //(wrap to spy while preserving)
  const origToken = process.env.OPENAI_TOKEN; //store token to restore after test
  process.env.OPENAI_TOKEN = 'tkn'; //set token for analyzeError to run
  const res = createRes(); //create mock res
  const err = new Error('boom'); //sample error
  try {
    await qerrors(err, 'spyCtx', {}, res); //invoke qerrors real functions
    await new Promise(r => setTimeout(r, 0)); //wait for queued analysis to finish
  } finally {
    restoreAxios(); //restore axios.post
    realLogger.error = origLog; //restore logger.error
    if (origToken === undefined) { delete process.env.OPENAI_TOKEN; } else { process.env.OPENAI_TOKEN = origToken; } //restore token after test
  }
  assert.ok(logArg.uniqueErrorName); //ensure log contains id
  assert.equal(logArg.uniqueErrorName, err.uniqueErrorName); //id matches error
  assert.equal(logArg.context, 'spyCtx'); //verify context was logged correctly
});
</file>

<file path="test/maxSockets.test.js">
const test = require('node:test'); //node test runner
const assert = require('node:assert/strict'); //strict assertions

function reloadQerrors() { //reload qerrors with current env
  delete require.cache[require.resolve('../lib/qerrors')]; //remove cached qerrors
  delete require.cache[require.resolve('../lib/config')]; //remove cached config to apply defaults
  return require('../lib/qerrors'); //return fresh module
}

test('axiosInstance honors QERRORS_MAX_SOCKETS', () => {
  const orig = process.env.QERRORS_MAX_SOCKETS; //save original value
  process.env.QERRORS_MAX_SOCKETS = '10'; //set custom sockets
  const { axiosInstance } = reloadQerrors(); //reload with env variable
  try {
    assert.equal(axiosInstance.defaults.httpAgent.maxSockets, 10); //http agent uses env
    assert.equal(axiosInstance.defaults.httpsAgent.maxSockets, 10); //https agent uses env
  } finally {
    if (orig === undefined) { delete process.env.QERRORS_MAX_SOCKETS; } else { process.env.QERRORS_MAX_SOCKETS = orig; }
    reloadQerrors(); //restore module state
  }
});

test('axiosInstance uses default max sockets when env missing', () => {
  const orig = process.env.QERRORS_MAX_SOCKETS; //capture original env
  delete process.env.QERRORS_MAX_SOCKETS; //unset for default test
  const { axiosInstance } = reloadQerrors(); //reload with defaults
  try {
    assert.equal(axiosInstance.defaults.httpAgent.maxSockets, 50); //default http agent value
    assert.equal(axiosInstance.defaults.httpsAgent.maxSockets, 50); //default https agent value
  } finally {
    if (orig === undefined) { delete process.env.QERRORS_MAX_SOCKETS; } else { process.env.QERRORS_MAX_SOCKETS = orig; }
    reloadQerrors(); //reset module state
  }
});

test('axiosInstance uses default max sockets with invalid env', () => { //invalid value falls back
  const orig = process.env.QERRORS_MAX_SOCKETS; //preserve original
  process.env.QERRORS_MAX_SOCKETS = 'abc'; //set non-numeric
  const { axiosInstance } = reloadQerrors(); //reload module with invalid env
  try {
    assert.equal(axiosInstance.defaults.httpAgent.maxSockets, 50); //default http agent value
    assert.equal(axiosInstance.defaults.httpsAgent.maxSockets, 50); //default https agent value
  } finally {
    if (orig === undefined) { delete process.env.QERRORS_MAX_SOCKETS; } else { process.env.QERRORS_MAX_SOCKETS = orig; }
    reloadQerrors(); //clean module state
  }
});

test('max sockets above threshold clamps and warns', async () => {
  const orig = process.env.QERRORS_MAX_SOCKETS; //remember original sockets value
  process.env.QERRORS_MAX_SOCKETS = '5000'; //set excessive sockets
  const logger = await require('../lib/logger'); //resolve logger for stubbing
  let warned = false; //capture warn calls
  const restoreWarn = require('qtests').stubMethod(logger, 'warn', () => { warned = true; });
  let sockets; //will hold resulting sockets value
  try {
    const { axiosInstance } = reloadQerrors(); //reload module with big value
    sockets = axiosInstance.defaults.httpAgent.maxSockets; //record clamped result
    await Promise.resolve(); //allow async warn to run
  } finally {
    restoreWarn(); //restore logger warn
    if (orig === undefined) { delete process.env.QERRORS_MAX_SOCKETS; } else { process.env.QERRORS_MAX_SOCKETS = orig; }
    reloadQerrors(); //reset module state
  }
  assert.equal(sockets, 1000); //expect clamp to safe threshold
  assert.equal(warned, true); //warning should trigger
});
</file>

<file path="test/postWithRetry.test.js">
const test = require('node:test'); //node test runner
const assert = require('node:assert/strict'); //assert helpers
const qtests = require('qtests'); //stub utility

const qerrorsModule = require('../lib/qerrors'); //module under test
const { postWithRetry, axiosInstance } = qerrorsModule; //target helper and axios

function withRetryEnv(retry, base, max) { //temporarily set retry env vars
  const origRetry = process.env.QERRORS_RETRY_ATTEMPTS; //save attempts
  const origBase = process.env.QERRORS_RETRY_BASE_MS; //save base delay
  const origMax = process.env.QERRORS_RETRY_MAX_MS; //save cap delay
  if (retry === undefined) { delete process.env.QERRORS_RETRY_ATTEMPTS; } else { process.env.QERRORS_RETRY_ATTEMPTS = String(retry); }
  if (base === undefined) { delete process.env.QERRORS_RETRY_BASE_MS; } else { process.env.QERRORS_RETRY_BASE_MS = String(base); }
  if (max === undefined) { delete process.env.QERRORS_RETRY_MAX_MS; } else { process.env.QERRORS_RETRY_MAX_MS = String(max); }
  return () => { //restore env vars
    if (origRetry === undefined) { delete process.env.QERRORS_RETRY_ATTEMPTS; } else { process.env.QERRORS_RETRY_ATTEMPTS = origRetry; }
    if (origBase === undefined) { delete process.env.QERRORS_RETRY_BASE_MS; } else { process.env.QERRORS_RETRY_BASE_MS = origBase; }
    if (origMax === undefined) { delete process.env.QERRORS_RETRY_MAX_MS; } else { process.env.QERRORS_RETRY_MAX_MS = origMax; }
  };
}

test('postWithRetry adds jitter to wait time', async () => {
  const restoreEnv = withRetryEnv(1, 100); //set small base for test
  let callCount = 0; //track axios.post calls
  const restoreAxios = qtests.stubMethod(axiosInstance, 'post', async () => { //stub axios
    callCount++; //increment on each call
    if (callCount === 1) { throw new Error('fail'); } //fail first
    return { ok: true }; //succeed second
  });
  let waited; //capture wait duration
  const restoreTimeout = qtests.stubMethod(global, 'setTimeout', (fn, ms) => { waited = ms; fn(); }); //capture delay and run immediately
  const origRandom = Math.random; //keep original random
  Math.random = () => 0.5; //predictable jitter
  try {
    const res = await postWithRetry('url', {}); //call helper
    assert.equal(res.ok, true); //success after retry
    assert.equal(callCount, 2); //called twice
    assert.ok(waited >= 100 && waited < 200); //jitter range check
  } finally {
    Math.random = origRandom; //restore Math.random
    restoreTimeout(); //restore timeout
    restoreAxios(); //restore axios
    restoreEnv(); //restore env
  }
});

test('postWithRetry uses defaults with invalid env', async () => { //invalid values fallback to defaults
  const restoreEnv = withRetryEnv('abc', 'abc'); //set invalid strings
  let callCount = 0; //track axios calls
  const restoreAxios = qtests.stubMethod(axiosInstance, 'post', async () => { //stub post
    callCount++; //increment each time
    if (callCount === 1) { throw new Error('fail'); } //first call fails
    return { ok: true }; //success second
  });
  let waited; //capture delay used
  const restoreTimeout = qtests.stubMethod(global, 'setTimeout', (fn, ms) => { waited = ms; fn(); }); //intercept timeout
  const origRandom = Math.random; //save random
  Math.random = () => 0.5; //predictable jitter
  try {
    const res = await postWithRetry('url', {}); //invoke helper
    assert.equal(res.ok, true); //successful result
    assert.equal(callCount, 2); //one retry
    assert.ok(waited >= 100 && waited < 200); //default base of 100 used
  } finally {
    Math.random = origRandom; //restore random
    restoreTimeout(); //restore timeout
    restoreAxios(); //restore axios
    restoreEnv(); //restore env vars
  }
});

test('postWithRetry enforces backoff cap', async () => { //cap ensures wait time not excessive
  const restoreEnv = withRetryEnv(1, 300, 400); //set base and cap
  let callCount = 0; //track axios calls
  const restoreAxios = qtests.stubMethod(axiosInstance, 'post', async () => { //stub post
    callCount++; //increment each time
    if (callCount === 1) { throw new Error('fail'); } //fail first
    return { ok: true }; //succeed second
  });
  let waited; //capture capped wait
  const restoreTimeout = qtests.stubMethod(global, 'setTimeout', (fn, ms) => { waited = ms; fn(); }); //capture delay
  const origRandom = Math.random; //save random
  Math.random = () => 0.5; //predictable jitter
  try {
    const res = await postWithRetry('url', {}); //invoke helper
    assert.equal(res.ok, true); //successful result
    assert.equal(waited, 400); //delay capped at 400
  } finally {
    Math.random = origRandom; //restore random
    restoreTimeout(); //restore timeout
    restoreAxios(); //restore axios
    restoreEnv(); //restore env
  }
});

test('postWithRetry uses Retry-After header for rate limit', async () => { //header controls wait
  const restoreEnv = withRetryEnv(1, 100); //set base delay
  const err = new Error('rate'); //error for first attempt
  err.response = { status: 429, headers: { 'retry-after': '1' } }; //429 with header
  let count = 0; //track calls
  const restoreAxios = qtests.stubMethod(axiosInstance, 'post', async () => { //stub axios
    count++; //increment each call
    if (count === 1) { throw err; } //fail first attempt
    return { ok: true }; //succeed second
  });
  let waited; //capture wait time
  const restoreTimeout = qtests.stubMethod(global, 'setTimeout', (fn, ms) => { waited = ms; fn(); }); //capture delay
  try {
    const res = await postWithRetry('url', {}); //invoke helper
    assert.equal(res.ok, true); //success after retry
    assert.equal(waited, 1000); //wait from header used
  } finally {
    restoreTimeout(); //restore timeout
    restoreAxios(); //restore axios
    restoreEnv(); //restore env
  }
});

test('postWithRetry doubles delay when rate limit header missing', async () => { //extend backoff
  const restoreEnv = withRetryEnv(1, 100); //use default cap
  const err = new Error('unavail'); //error for first attempt
  err.response = { status: 503, headers: {} }; //503 without header
  let count = 0; //track calls
  const restoreAxios = qtests.stubMethod(axiosInstance, 'post', async () => { //stub axios
    count++; //increment each call
    if (count === 1) { throw err; } //fail first
    return { ok: true }; //succeed second
  });
  let waited; //capture backoff
  const restoreTimeout = qtests.stubMethod(global, 'setTimeout', (fn, ms) => { waited = ms; fn(); }); //capture delay
  const origRandom = Math.random; //store random
  Math.random = () => 0.5; //predictable jitter
  try {
    const res = await postWithRetry('url', {}); //call helper
    assert.equal(res.ok, true); //succeeded after retry
    assert.equal(waited, 300); //100 base +50 jitter doubled
  } finally {
    Math.random = origRandom; //restore random
    restoreTimeout(); //restore timeout
    restoreAxios(); //restore axios
    restoreEnv(); //restore env
  }
});
</file>

<file path="test/serviceName.test.js">
const test = require('node:test'); //node test runner
const assert = require('node:assert/strict'); //assert helpers
const qtests = require('qtests'); //stubbing helper
const winston = require('winston'); //stubbed winston module

function reloadLogger() { //reload logger with current env
  delete require.cache[require.resolve('../lib/logger')];
  delete require.cache[require.resolve('../lib/config')];
  return require('../lib/logger');
}

test('logger uses QERRORS_SERVICE_NAME env var', async () => {
  const orig = process.env.QERRORS_SERVICE_NAME; //save original value
  process.env.QERRORS_SERVICE_NAME = 'svc'; //set custom name
  let captured; //will capture config passed to createLogger
  const restore = qtests.stubMethod(winston, 'createLogger', (cfg) => { captured = cfg; return { defaultMeta: cfg.defaultMeta, warn() {}, info() {}, error() {} }; }); //include warn for startup check
  const logger = await reloadLogger(); //reload module and await
  try {
    assert.equal(captured.defaultMeta.service, 'svc'); //verify custom service
    assert.equal((await logger).defaultMeta.service, 'svc'); //logger carries meta
  } finally {
    restore(); //restore stubbed method
    if (orig === undefined) { delete process.env.QERRORS_SERVICE_NAME; } else { process.env.QERRORS_SERVICE_NAME = orig; }
    reloadLogger(); //reset cache
  }
});

test('logger defaults QERRORS_SERVICE_NAME when unset', async () => {
  const orig = process.env.QERRORS_SERVICE_NAME; //store original
  delete process.env.QERRORS_SERVICE_NAME; //unset for default test
  let captured; //capture config
  const restore = qtests.stubMethod(winston, 'createLogger', (cfg) => { captured = cfg; return { defaultMeta: cfg.defaultMeta, warn() {}, info() {}, error() {} }; }); //include warn for startup check
  const logger = await reloadLogger(); //reload module and await
  try {
    assert.equal(captured.defaultMeta.service, 'qerrors'); //uses default
    assert.equal((await logger).defaultMeta.service, 'qerrors'); //logger meta default
  } finally {
    restore(); //restore stub
    if (orig === undefined) { delete process.env.QERRORS_SERVICE_NAME; } else { process.env.QERRORS_SERVICE_NAME = orig; }
    reloadLogger(); //restore cache
  }
});
</file>

<file path="test/timeout.test.js">
const test = require('node:test'); //node test runner
const assert = require('node:assert/strict'); //strict assertion helpers

function reloadQerrors() { //helper to reload module with current env
  delete require.cache[require.resolve('../lib/qerrors')]; //remove cached module
  return require('../lib/qerrors'); //reload qerrors fresh
}

test('axiosInstance honors QERRORS_TIMEOUT', () => {
  const orig = process.env.QERRORS_TIMEOUT; //save existing value
  process.env.QERRORS_TIMEOUT = '1234'; //set custom timeout for test
  const { axiosInstance } = reloadQerrors(); //reload module with env
  try {
    assert.equal(axiosInstance.defaults.timeout, 1234); //timeout matches env
  } finally {
    if (orig === undefined) { delete process.env.QERRORS_TIMEOUT; } else { process.env.QERRORS_TIMEOUT = orig; }
    reloadQerrors(); //restore module state
  }
});

test('axiosInstance uses default timeout when env missing', () => {
  const orig = process.env.QERRORS_TIMEOUT; //capture original env
  delete process.env.QERRORS_TIMEOUT; //remove to test default
  const { axiosInstance } = reloadQerrors(); //reload module with defaults
  try {
    assert.equal(axiosInstance.defaults.timeout, 10000); //default set
  } finally {
    if (orig === undefined) { delete process.env.QERRORS_TIMEOUT; } else { process.env.QERRORS_TIMEOUT = orig; }
    reloadQerrors(); //reset module state
  }
});

test('axiosInstance uses default timeout with invalid env', () => { //invalid value fallback
  const orig = process.env.QERRORS_TIMEOUT; //save current env
  process.env.QERRORS_TIMEOUT = 'abc'; //set invalid
  const { axiosInstance } = reloadQerrors(); //reload with invalid value
  try {
    assert.equal(axiosInstance.defaults.timeout, 10000); //should use default
  } finally {
    if (orig === undefined) { delete process.env.QERRORS_TIMEOUT; } else { process.env.QERRORS_TIMEOUT = orig; }
    reloadQerrors(); //reset module
  }
});
</file>

<file path=".gitignore">
# Logs
logs
*.log
npm-debug.log*
yarn-debug.log*
yarn-error.log*
lerna-debug.log*
.pnpm-debug.log*

# Diagnostic reports (https://nodejs.org/api/report.html)
report.[0-9]*.[0-9]*.[0-9]*.[0-9]*.json

# Runtime data
pids
*.pid
*.seed
*.pid.lock

# Directory for instrumented libs generated by jscoverage/JSCover
lib-cov

# Coverage directory used by tools like istanbul
coverage
*.lcov

# nyc test coverage
.nyc_output

# Grunt intermediate storage (https://gruntjs.com/creating-plugins#storing-task-files)
.grunt

# Bower dependency directory (https://bower.io/)
bower_components

# node-waf configuration
.lock-wscript

# Compiled binary addons (https://nodejs.org/api/addons.html)
build/Release

# Dependency directories
node_modules/
jspm_packages/

# Snowpack dependency directory (https://snowpack.dev/)
web_modules/

# TypeScript cache
*.tsbuildinfo

# Optional npm cache directory
.npm

# Optional eslint cache
.eslintcache

# Optional stylelint cache
.stylelintcache

# Microbundle cache
.rpt2_cache/
.rts2_cache_cjs/
.rts2_cache_es/
.rts2_cache_umd/

# Optional REPL history
.node_repl_history

# Output of 'npm pack'
*.tgz

# Yarn Integrity file
.yarn-integrity

# dotenv environment variable files
.env
.env.development.local
.env.test.local
.env.production.local
.env.local

# parcel-bundler cache (https://parceljs.org/)
.cache
.parcel-cache

# Next.js build output
.next
out

# Nuxt.js build / generate output
.nuxt
dist

# Gatsby files
.cache/
# Comment in the public line in if your project uses Gatsby and not Next.js
# https://nextjs.org/blog/next-9-1#public-directory-support
# public

# vuepress build output
.vuepress/dist

# vuepress v2.x temp and cache directory
.temp
.cache

# Docusaurus cache and generated files
.docusaurus

# Serverless directories
.serverless/

# FuseBox cache
.fusebox/

# DynamoDB Local files
.dynamodb/

# TernJS port file
.tern-port

# Stores VSCode versions used for testing VSCode extensions
.vscode-test

# yarn v2
.yarn/cache
.yarn/unplugged
.yarn/build-state.yml
.yarn/install-state.gz
.pnp.*

# Replit debugger
.breakpoints
</file>

<file path=".replit">
modules = ["nodejs-20", "nix"]
hidden = [".config", "package-lock.json"]
run = "node index.js"

[gitHubImport]
requiredFiles = [".replit", "replit.nix", "package.json", "package-lock.json"]

[nix]
channel = "stable-24_05"

[unitTest]
language = "nodejs"

[deployment]
run = ["sh", "-c", "node index.js"]
deploymentTarget = "cloudrun"
ignorePorts = false
</file>

<file path="replit.nix">
{pkgs}: {
  deps = [ ];
}
</file>

<file path="attached_assets/Pasted--Centralized-Error-Handling-Utility-This-module-provides-standardized-error-handling-pa-1750137599049_1750137599050.txt">
/**
 * Centralized Error Handling Utility
 * 
 * This module provides standardized error handling patterns across the application,
 * ensuring consistent error responses, proper logging, and appropriate error
 * classification. It implements error handling best practices including:
 * 
 * 1. Standardized error response format for API consistency
 * 2. Error classification for appropriate handling strategies
 * 3. Context-aware logging for debugging and monitoring
 * 4. Request ID tracking for error correlation
 * 5. Severity-based error routing and alerting
 * 
 * Design Rationale:
 * - Centralizes error handling logic to reduce code duplication
 * - Provides consistent user experience across all endpoints
 * - Enables comprehensive error monitoring and debugging
 * - Supports multiple error handling strategies based on error type
 * - Maintains backward compatibility with existing error patterns
 */

const { qerrors } = require('qerrors');
const { sendJsonResponse } = require('./responseUtils');
const { getRequestId } = require('./requestUtils');

/**
 * Error type classification for appropriate handling strategies
 * 
 * Rationale: Different error types require different handling approaches.
 * This classification enables appropriate response codes, user messages,
 * logging levels, and recovery strategies.
 */
const ErrorTypes = {
    VALIDATION: 'validation',           // User input errors (400)
    AUTHENTICATION: 'authentication',   // Auth failures (401)
    AUTHORIZATION: 'authorization',     // Permission errors (403)
    NOT_FOUND: 'not_found',            // Resource not found (404)
    RATE_LIMIT: 'rate_limit',          // Rate limiting (429)
    NETWORK: 'network',                // External service errors (502/503)
    DATABASE: 'database',              // Database errors (500)
    SYSTEM: 'system',                  // Internal system errors (500)
    CONFIGURATION: 'configuration'      // Config/setup errors (500)
};

/**
 * Error severity levels for logging and alerting
 * 
 * Rationale: Different error severities require different response strategies.
 * This classification enables appropriate logging, alerting, and escalation.
 */
const ErrorSeverity = {
    LOW: 'low',           // Expected errors, user mistakes
    MEDIUM: 'medium',     // Operational issues, recoverable
    HIGH: 'high',         // Service degradation, requires attention
    CRITICAL: 'critical'  // Service disruption, immediate response needed
};

/**
 * Maps error types to appropriate HTTP status codes
 * 
 * Rationale: Consistent HTTP status code mapping ensures proper client
 * behavior and follows REST API conventions.
 */
const ERROR_STATUS_MAP = {
    [ErrorTypes.VALIDATION]: 400,
    [ErrorTypes.AUTHENTICATION]: 401,
    [ErrorTypes.AUTHORIZATION]: 403,
    [ErrorTypes.NOT_FOUND]: 404,
    [ErrorTypes.RATE_LIMIT]: 429,
    [ErrorTypes.NETWORK]: 502,
    [ErrorTypes.DATABASE]: 500,
    [ErrorTypes.SYSTEM]: 500,
    [ErrorTypes.CONFIGURATION]: 500
};

/**
 * Maps error types to severity levels for monitoring
 * 
 * Rationale: Automatic severity classification enables appropriate
 * alerting and escalation without manual intervention.
 */
const ERROR_SEVERITY_MAP = {
    [ErrorTypes.VALIDATION]: ErrorSeverity.LOW,
    [ErrorTypes.AUTHENTICATION]: ErrorSeverity.LOW,
    [ErrorTypes.AUTHORIZATION]: ErrorSeverity.MEDIUM,
    [ErrorTypes.NOT_FOUND]: ErrorSeverity.LOW,
    [ErrorTypes.RATE_LIMIT]: ErrorSeverity.MEDIUM,
    [ErrorTypes.NETWORK]: ErrorSeverity.MEDIUM,
    [ErrorTypes.DATABASE]: ErrorSeverity.HIGH,
    [ErrorTypes.SYSTEM]: ErrorSeverity.HIGH,
    [ErrorTypes.CONFIGURATION]: ErrorSeverity.CRITICAL
};

/**
 * Creates a standardized error object with consistent format
 * 
 * Rationale: Standardized error format ensures consistent API responses
 * and enables proper error handling on the client side. Includes all
 * necessary information for debugging and user feedback.
 * 
 * @param {string} code - Error code for programmatic handling
 * @param {string} message - Human-readable error message
 * @param {string} type - Error type from ErrorTypes enum
 * @param {Object} context - Additional context for debugging
 * @returns {Object} Standardized error object
 */
function createError(code, message, type, context = {}) { // build standard error object
    return {
        code,
        message,
        type,
        timestamp: new Date().toISOString(),
        requestId: context.requestId || getRequestId(context.req),
        context: {
            ...context,
            req: undefined, // Remove req object to prevent circular references
            res: undefined  // Remove res object to prevent circular references
        }
    };
}

/**
 * Logs error with appropriate severity and context
 * 
 * Rationale: Centralized error logging ensures consistent log format
 * and enables proper monitoring and alerting. Different severities
 * can be routed to different logging destinations.
 * 
 * @param {Object} error - Error object or Error instance
 * @param {string} functionName - Name of function where error occurred
 * @param {Object} context - Request context and additional information
 * @param {string} severity - Error severity level
 */
function logError(error, functionName, context = {}, severity = ErrorSeverity.MEDIUM) { // log with severity context
    const logContext = {
        ...context,
        severity,
        timestamp: new Date().toISOString(),
        requestId: context.requestId || getRequestId(context.req)
    };

    // Use existing qerrors for consistent logging
    qerrors(error, functionName, logContext);

    // Additional logging based on severity
    if (severity === ErrorSeverity.CRITICAL) {
        console.error(`CRITICAL ERROR in ${functionName}:`, {
            error: error.message || error,
            context: logContext
        });
    } else if (severity === ErrorSeverity.HIGH) {
        console.error(`HIGH SEVERITY ERROR in ${functionName}:`, {
            error: error.message || error,
            context: logContext
        });
    }
}

/**
 * Handles controller errors with standardized response
 * 
 * Rationale: Provides consistent error handling across all controllers
 * while maintaining existing responseUtils integration. Automatically
 * determines appropriate status codes and response format.
 * 
 * @param {Object} res - Express response object
 * @param {Object} error - Error object or Error instance
 * @param {string} functionName - Name of function where error occurred
 * @param {Object} context - Request context
 * @param {string} userMessage - Optional user-friendly message override
 */
function handleControllerError(res, error, functionName, context = {}, userMessage = null) { // send standardized error response
    const errorType = error.type || ErrorTypes.SYSTEM;
    const severity = ERROR_SEVERITY_MAP[errorType];
    const statusCode = ERROR_STATUS_MAP[errorType];

    // Log the error with appropriate severity
    logError(error, functionName, context, severity);

    // Create standardized error response
    const errorResponse = createError(
        error.code || 'INTERNAL_ERROR',
        userMessage || error.message || 'An internal error occurred',
        errorType,
        context
    );

    // Send standardized JSON response
    sendJsonResponse(res, statusCode, { error: errorResponse });
}

/**
 * Wraps async operations with standardized error handling
 * 
 * Rationale: Reduces boilerplate code in controllers while ensuring
 * consistent error handling. Automatically catches and handles errors
 * according to their type and severity.
 * 
 * @param {Function} operation - Async operation to execute
 * @param {string} functionName - Name for logging purposes
 * @param {Object} context - Request context
 * @param {*} fallback - Fallback value on error (optional)
 * @returns {*} Operation result or fallback value
 */
async function withErrorHandling(operation, functionName, context = {}, fallback = null) { // execute operation with safety net
    try {
        const result = await operation();
        console.log(`${functionName} is returning result`);
        return result;
    } catch (error) {
        logError(error, functionName, context);
        return fallback;
    }
}
</file>

<file path="attached_assets/Pasted--Centralized-Error-Handling-Utility-This-module-provides-standardized-error-handling-pa-1750139496255_1750139496256.txt">
/**
 * Centralized Error Handling Utility
 * 
 * This module provides standardized error handling patterns across the application,
 * ensuring consistent error responses, proper logging, and appropriate error
 * classification. It implements error handling best practices including:
 * 
 * 1. Standardized error response format for API consistency
 * 2. Error classification for appropriate handling strategies
 * 3. Context-aware logging for debugging and monitoring
 * 4. Request ID tracking for error correlation
 * 5. Severity-based error routing and alerting
 * 
 * Design Rationale:
 * - Centralizes error handling logic to reduce code duplication
 * - Provides consistent user experience across all endpoints
 * - Enables comprehensive error monitoring and debugging
 * - Supports multiple error handling strategies based on error type
 * - Maintains backward compatibility with existing error patterns
 */

const { qerrors } = require('qerrors');
const { sendJsonResponse } = require('./responseUtils');
const { getRequestId } = require('./requestUtils');

/**
 * Error type classification for appropriate handling strategies
 * 
 * Rationale: Different error types require different handling approaches.
 * This classification enables appropriate response codes, user messages,
 * logging levels, and recovery strategies.
 */
const ErrorTypes = {
    VALIDATION: 'validation',           // User input errors (400)
    AUTHENTICATION: 'authentication',   // Auth failures (401)
    AUTHORIZATION: 'authorization',     // Permission errors (403)
    NOT_FOUND: 'not_found',            // Resource not found (404)
    RATE_LIMIT: 'rate_limit',          // Rate limiting (429)
    NETWORK: 'network',                // External service errors (502/503)
    DATABASE: 'database',              // Database errors (500)
    SYSTEM: 'system',                  // Internal system errors (500)
    CONFIGURATION: 'configuration'      // Config/setup errors (500)
};

/**
 * Error severity levels for logging and alerting
 * 
 * Rationale: Different error severities require different response strategies.
 * This classification enables appropriate logging, alerting, and escalation.
 */
const ErrorSeverity = {
    LOW: 'low',           // Expected errors, user mistakes
    MEDIUM: 'medium',     // Operational issues, recoverable
    HIGH: 'high',         // Service degradation, requires attention
    CRITICAL: 'critical'  // Service disruption, immediate response needed
};

/**
 * Maps error types to appropriate HTTP status codes
 * 
 * Rationale: Consistent HTTP status code mapping ensures proper client
 * behavior and follows REST API conventions.
 */
const ERROR_STATUS_MAP = {
    [ErrorTypes.VALIDATION]: 400,
    [ErrorTypes.AUTHENTICATION]: 401,
    [ErrorTypes.AUTHORIZATION]: 403,
    [ErrorTypes.NOT_FOUND]: 404,
    [ErrorTypes.RATE_LIMIT]: 429,
    [ErrorTypes.NETWORK]: 502,
    [ErrorTypes.DATABASE]: 500,
    [ErrorTypes.SYSTEM]: 500,
    [ErrorTypes.CONFIGURATION]: 500
};

/**
 * Maps error types to severity levels for monitoring
 * 
 * Rationale: Automatic severity classification enables appropriate
 * alerting and escalation without manual intervention.
 */
const ERROR_SEVERITY_MAP = {
    [ErrorTypes.VALIDATION]: ErrorSeverity.LOW,
    [ErrorTypes.AUTHENTICATION]: ErrorSeverity.LOW,
    [ErrorTypes.AUTHORIZATION]: ErrorSeverity.MEDIUM,
    [ErrorTypes.NOT_FOUND]: ErrorSeverity.LOW,
    [ErrorTypes.RATE_LIMIT]: ErrorSeverity.MEDIUM,
    [ErrorTypes.NETWORK]: ErrorSeverity.MEDIUM,
    [ErrorTypes.DATABASE]: ErrorSeverity.HIGH,
    [ErrorTypes.SYSTEM]: ErrorSeverity.HIGH,
    [ErrorTypes.CONFIGURATION]: ErrorSeverity.CRITICAL
};

/**
 * Creates a standardized error object with consistent format
 * 
 * Rationale: Standardized error format ensures consistent API responses
 * and enables proper error handling on the client side. Includes all
 * necessary information for debugging and user feedback.
 * 
 * @param {string} code - Error code for programmatic handling
 * @param {string} message - Human-readable error message
 * @param {string} type - Error type from ErrorTypes enum
 * @param {Object} context - Additional context for debugging
 * @returns {Object} Standardized error object
 */
function createError(code, message, type, context = {}) { // build standard error object
    return {
        code,
        message,
        type,
        timestamp: new Date().toISOString(),
        requestId: context.requestId || getRequestId(context.req),
        context: {
            ...context,
            req: undefined, // Remove req object to prevent circular references
            res: undefined  // Remove res object to prevent circular references
        }
    };
}

/**
 * Logs error with appropriate severity and context
 * 
 * Rationale: Centralized error logging ensures consistent log format
 * and enables proper monitoring and alerting. Different severities
 * can be routed to different logging destinations.
 * 
 * @param {Object} error - Error object or Error instance
 * @param {string} functionName - Name of function where error occurred
 * @param {Object} context - Request context and additional information
 * @param {string} severity - Error severity level
 */
function logError(error, functionName, context = {}, severity = ErrorSeverity.MEDIUM) { // log with severity context
    const logContext = {
        ...context,
        severity,
        timestamp: new Date().toISOString(),
        requestId: context.requestId || getRequestId(context.req)
    };

    // Use existing qerrors for consistent logging
    qerrors(error, functionName, logContext);

    // Additional logging based on severity
    if (severity === ErrorSeverity.CRITICAL) {
        console.error(`CRITICAL ERROR in ${functionName}:`, {
            error: error.message || error,
            context: logContext
        });
    } else if (severity === ErrorSeverity.HIGH) {
        console.error(`HIGH SEVERITY ERROR in ${functionName}:`, {
            error: error.message || error,
            context: logContext
        });
    }
}

/**
 * Handles controller errors with standardized response
 * 
 * Rationale: Provides consistent error handling across all controllers
 * while maintaining existing responseUtils integration. Automatically
 * determines appropriate status codes and response format.
 * 
 * @param {Object} res - Express response object
 * @param {Object} error - Error object or Error instance
 * @param {string} functionName - Name of function where error occurred
 * @param {Object} context - Request context
 * @param {string} userMessage - Optional user-friendly message override
 */
function handleControllerError(res, error, functionName, context = {}, userMessage = null) { // send standardized error response
    const errorType = error.type || ErrorTypes.SYSTEM;
    const severity = ERROR_SEVERITY_MAP[errorType];
    const statusCode = ERROR_STATUS_MAP[errorType];

    // Log the error with appropriate severity
    logError(error, functionName, context, severity);

    // Create standardized error response
    const errorResponse = createError(
        error.code || 'INTERNAL_ERROR',
        userMessage || error.message || 'An internal error occurred',
        errorType,
        context
    );

    // Send standardized JSON response
    sendJsonResponse(res, statusCode, { error: errorResponse });
}

/**
 * Wraps async operations with standardized error handling
 * 
 * Rationale: Reduces boilerplate code in controllers while ensuring
 * consistent error handling. Automatically catches and handles errors
 * according to their type and severity.
 * 
 * @param {Function} operation - Async operation to execute
 * @param {string} functionName - Name for logging purposes
 * @param {Object} context - Request context
 * @param {*} fallback - Fallback value on error (optional)
 * @returns {*} Operation result or fallback value
 */
async function withErrorHandling(operation, functionName, context = {}, fallback = null) { // execute operation with safety net
    try {
        const result = await operation();
        console.log(`${functionName} is returning result`);
        return result;
    } catch (error) {
        logError(error, functionName, context);
        return fallback;
    }
}

/**
 * Creates specific error types with predefined configurations
 * 
 * Rationale: Provides convenient error creation functions for common
 * error scenarios, ensuring consistent error codes and messages.
 */
const ErrorFactory = {
    /**
     * Creates validation error for user input issues
     */
    validation(message, field = null, context = {}) {
        return createError(
            'VALIDATION_ERROR',
            message,
            ErrorTypes.VALIDATION,
            { ...context, field }
        );
    },

    /**
     * Creates authentication error for login/auth issues
     */
    authentication(message = 'Authentication required', context = {}) {
        return createError(
            'AUTHENTICATION_ERROR',
            message,
            ErrorTypes.AUTHENTICATION,
            context
        );
    },

    /**
     * Creates authorization error for permission issues
     */
    authorization(message = 'Insufficient permissions', context = {}) {
        return createError(
            'AUTHORIZATION_ERROR',
            message,
            ErrorTypes.AUTHORIZATION,
            context
        );
    },

    /**
     * Creates not found error for missing resources
     */
    notFound(resource, context = {}) {
        return createError(
            'NOT_FOUND',
            `${resource} not found`,
            ErrorTypes.NOT_FOUND,
            context
        );
    },

    /**
     * Creates rate limit error for quota violations
     */
    rateLimit(message = 'Rate limit exceeded', context = {}) {
        return createError(
            'RATE_LIMIT_EXCEEDED',
            message,
            ErrorTypes.RATE_LIMIT,
            context
        );
    },

    /**
     * Creates network error for external service issues
     */
    network(message, service = null, context = {}) {
        return createError(
            'NETWORK_ERROR',
            message,
            ErrorTypes.NETWORK,
            { ...context, service }
        );
    },

    /**
     * Creates database error for data persistence issues
     */
    database(message, operation = null, context = {}) {
        return createError(
            'DATABASE_ERROR',
            message,
            ErrorTypes.DATABASE,
            { ...context, operation }
        );
    },

    /**
     * Creates system error for internal issues
     */
    system(message, component = null, context = {}) {
        return createError(
            'SYSTEM_ERROR',
            message,
            ErrorTypes.SYSTEM,
            { ...context, component }
        );
    }
};

/**
 * Middleware for global error handling
 * 
 * Rationale: Catches any unhandled errors in the Express middleware chain
 * and ensures they are properly logged and responded to with consistent format.
 */
function errorMiddleware(error, req, res, next) {
    const context = {
        req,
        url: req.url,
        method: req.method,
        ip: req.ip
    };

    handleControllerError(res, error, 'errorMiddleware', context);
}

module.exports = {
    ErrorTypes,
    ErrorSeverity,
    createError,
    logError,
    handleControllerError,
    withErrorHandling,
    ErrorFactory,
    errorMiddleware
};
</file>

<file path="attached_assets/Pasted--Enhanced-Logging-System-for-Scrooge-Payment-API-This-module-provides-a-comprehensive-l-1750141501295_1750141501296.txt">
/**
 * Enhanced Logging System for Scrooge Payment API
 * 
 * This module provides a comprehensive logging infrastructure that supports structured
 * logging, multiple log levels, performance monitoring, and production-ready log
 * management. It replaces basic console.log statements with a robust logging system
 * designed for payment processing applications that require detailed audit trails.
 * 
 * Architecture rationale:
 * - Structured JSON logging for easy parsing by monitoring systems
 * - Multiple log levels for appropriate filtering in different environments
 * - Performance timing capabilities for monitoring API response times
 * - Request correlation IDs for tracking user journeys across microservices
 * - Security-aware logging that masks sensitive payment information
 * - Environment-specific configuration for development vs production
 * 
 * Business benefits:
 * - Improved debugging capabilities reduce incident resolution time
 * - Compliance support through comprehensive audit trails
 * - Performance monitoring enables proactive optimization
 * - Structured logs integrate with monitoring platforms for alerting
 * - Security logging helps detect and respond to potential threats
 */

const fs = require('fs');
const path = require('path');
const { isOffline } = require('./offlineMode');

/**
 * Log Levels Configuration
 * 
 * Purpose: Defines hierarchical log levels for filtering and routing messages
 * Each level has a numeric priority for comparison and filtering operations.
 * Higher numbers indicate higher priority/severity levels.
 * 
 * Level usage guidelines:
 * - DEBUG: Detailed debugging information for development
 * - INFO: General operational messages about system behavior
 * - WARN: Warning conditions that should be noted but don't stop operation
 * - ERROR: Error conditions that require attention
 * - FATAL: Critical errors that may cause system shutdown
 * - AUDIT: Security and compliance-related events requiring permanent retention
 */
const LOG_LEVELS = {
  DEBUG: { priority: 10, color: '\x1b[36m', name: 'DEBUG' }, // Cyan
  INFO:  { priority: 20, color: '\x1b[32m', name: 'INFO' },  // Green
  WARN:  { priority: 30, color: '\x1b[33m', name: 'WARN' },  // Yellow
  ERROR: { priority: 40, color: '\x1b[31m', name: 'ERROR' }, // Red
  FATAL: { priority: 50, color: '\x1b[35m', name: 'FATAL' }, // Magenta
  AUDIT: { priority: 60, color: '\x1b[34m', name: 'AUDIT' }  // Blue
};

/**
 * Logger Configuration
 * 
 * Purpose: Centralizes logging configuration with environment-specific defaults
 * The configuration adapts to different deployment environments while maintaining
 * consistent logging behavior across the application.
 * 
 * Configuration rationale:
 * - Environment-based log level filtering reduces noise in production
 * - File logging for persistence and monitoring system integration
 * - Console logging for development debugging and container environments
 * - Structured format enables automated log parsing and analysis
 */
class LoggerConfig {
  constructor() {
    this.logLevel = this.getLogLevel();
    this.logDir = process.env.LOG_DIR || './logs';
    this.enableFileLogging = process.env.ENABLE_FILE_LOGGING !== 'false';
    this.enableConsoleLogging = process.env.ENABLE_CONSOLE_LOGGING !== 'false';
    this.enableStructuredLogging = process.env.NODE_ENV === 'production';
    this.maxLogFiles = parseInt(process.env.MAX_LOG_FILES) || 30;
    this.maxLogSizeMB = parseInt(process.env.MAX_LOG_SIZE_MB) || 100;
    
    this.ensureLogDirectory();
  }

  /**
   * Environment-based Log Level Detection
</file>

<file path="attached_assets/Pasted--Handles-controller-errors-with-standardized-response-Rationale-Provides-consistent-error-h-1750140224456_1750140224457.txt">
* Handles controller errors with standardized response
 * 
 * Rationale: Provides consistent error handling across all controllers
 * while maintaining existing responseUtils integration. Automatically
 * determines appropriate status codes and response format.
 * 
 * @param {Object} res - Express response object
 * @param {Object} error - Error object or Error instance
 * @param {string} functionName - Name of function where error occurred
 * @param {Object} context - Request context
 * @param {string} userMessage - Optional user-friendly message override
 */
function handleControllerError(res, error, functionName, context = {}, userMessage = null) { // send standardized error response
    const errorType = error.type || ErrorTypes.SYSTEM;
    const severity = ERROR_SEVERITY_MAP[errorType];
    const statusCode = ERROR_STATUS_MAP[errorType];

    // Log the error with appropriate severity
    logError(error, functionName, context, severity);

    // Create standardized error response
    const errorResponse = createError(
        error.code || 'INTERNAL_ERROR',
        userMessage || error.message || 'An internal error occurred',
        errorType,
        context
    );

    // Send standardized JSON response
    sendJsonResponse(res, statusCode, { error: errorResponse });
}

/**
 * Wraps async operations with standardized error handling
 * 
 * Rationale: Reduces boilerplate code in controllers while ensuring
 * consistent error handling. Automatically catches and handles errors
 * according to their type and severity.
 * 
 * @param {Function} operation - Async operation to execute
 * @param {string} functionName - Name for logging purposes
 * @param {Object} context - Request context
 * @param {*} fallback - Fallback value on error (optional)
 * @returns {*} Operation result or fallback value
 */
async function withErrorHandling(operation, functionName, context = {}, fallback = null) { // execute operation with safety net
    try {
        const result = await operation();
        console.log(`${functionName} is returning result`);
        return result;
    } catch (error) {
        logError(error, functionName, context);
        return fallback;
    }
}

/**
 * Creates specific error types with predefined configurations
 * 
 * Rationale: Provides convenient error creation functions for common
 * error scenarios, ensuring consistent error codes and messages.
 */
const ErrorFactory = {
    /**
     * Creates validation error for user input issues
     */
    validation(message, field = null, context = {}) {
        return createError(
            'VALIDATION_ERROR',
            message,
            ErrorTypes.VALIDATION,
            { ...context, field }
        );
    },

    /**
     * Creates authentication error for login/auth issues
     */
    authentication(message = 'Authentication required', context = {}) {
        return createError(
            'AUTHENTICATION_ERROR',
            message,
            ErrorTypes.AUTHENTICATION,
            context
        );
    },

    /**
     * Creates authorization error for permission issues
     */
    authorization(message = 'Insufficient permissions', context = {}) {
        return createError(
            'AUTHORIZATION_ERROR',
            message,
            ErrorTypes.AUTHORIZATION,
            context
        );
    },

    /**
     * Creates not found error for missing resources
     */
    notFound(resource, context = {}) {
        return createError(
            'NOT_FOUND',
            `${resource} not found`,
            ErrorTypes.NOT_FOUND,
            context
        );
    },

    /**
     * Creates rate limit error for quota violations
     */
    rateLimit(message = 'Rate limit exceeded', context = {}) {
        return createError(
            'RATE_LIMIT_EXCEEDED',
            message,
            ErrorTypes.RATE_LIMIT,
            context
        );
    },

    /**
     * Creates network error for external service issues
     */
    network(message, service = null, context = {}) {
        return createError(
            'NETWORK_ERROR',
            message,
            ErrorTypes.NETWORK,
            { ...context, service }
        );
    },

    /**
     * Creates database error for data persistence issues
     */
    database(message, operation = null, context = {}) {
        return createError(
            'DATABASE_ERROR',
            message,
            ErrorTypes.DATABASE,
            { ...context, operation }
        );
    },

    /**
     * Creates system error for internal issues
     */
    system(message, component = null, context = {}) {
        return createError(
            'SYSTEM_ERROR',
            message,
            ErrorTypes.SYSTEM,
            { ...context, component }
        );
    }
};

/**
 * Middleware for global error handling
 * 
 * Rationale: Catches any unhandled errors in the Express middleware chain
 * and ensures they are properly logged and responded to with consistent format.
 */
function errorMiddleware(error, req, res, next) {
    const context = {
        req,
        url: req.url,
        method: req.method,
        ip: req.ip
    };

    handleControllerError(res, error, 'errorMiddleware', context);
}

module.exports = {
    ErrorTypes,
    ErrorSeverity,
    createError,
    logError,
    handleControllerError,
    withErrorHandling,
    ErrorFactory,
    errorMiddleware
</file>

<file path="attached_assets/Pasted--Rationale-API-responses-should-be-consistent-and-safe-This-function-ensures-all-JSON-resp-1750140247024_1750140247024.txt">
* 
 * Rationale: API responses should be consistent and safe. This function ensures
 * all JSON responses follow the same pattern and gracefully handles any
 * serialization errors that might occur with complex objects. The logging helps
 * with debugging by showing exactly what was sent to clients, which is crucial
 * for API gateway functionality where responses pass through multiple layers.
 * 
 * @param {Object} res - Express response object
 * @param {number} statusCode - HTTP status code to send
 * @param {Object} payload - Data to send as JSON response
 */
// sendJsonResponse provided by qgenutils handles JSON output and logging

/**
 * Standardized error handling for controller functions
 * 
 * Rationale: Controllers throughout the application need consistent error handling.
 * This function provides a single point of error logging and response formatting,
 * ensuring clients always receive meaningful error messages while maintaining
 * detailed logging for debugging.
 * 
 * The conditional request logging allows this function to be used in both
 * request-based contexts (normal API calls) and non-request contexts (background tasks).
 * 
 * The headersSent check prevents Express errors when trying to send multiple responses,
 * which can happen in complex middleware chains or async error scenarios.
 * 
 * @param {Object} res - Express response object
 * @param {Error} error - The error object that occurred
 * @param {string} message - Human-readable error message for the client
 * @param {Object} [req] - Optional Express request object for additional context
 */
function handleControllerError(res, error, message, req){ // unified error response
    console.log(`handleControllerError is running with ${message}`); // Log error handling initiation
    try {
        if(req){
            qerrors(error, message, req); // Log error with full request context for better debugging
        } else {
            qerrors(error, message); // Log error without request context (background operations)
        }
        
        // Only send response if headers haven't been sent already
        // This prevents "Cannot set headers after they are sent" errors
        if(!res.headersSent){
            sendJsonResponse(res, 500, { error: message }); // Send standardized error response
        }
        console.log(`handleControllerError has run resulting in a final value of ${message}`); // Log completion
    } catch(err){
        // Handle meta-errors (errors in error handling itself)
        // This provides a fallback to prevent complete system failure
        qerrors(err, 'handleControllerError', { message }); // Log the meta-error
    }
}

module.exports = { sendJsonResponse, handleControllerError }; // Export utility functions for use across controllers
</file>

<file path="attached_assets/Pasted-const-logEntry-this-createLogEntry-levelConfig-message-context-requestId-Console-output-1750141515603_1750141515603.txt">
const logEntry = this.createLogEntry(levelConfig, message, context, requestId);

  // Console output with color coding for development
  if (this.config.enableConsoleLogging) {
    this.outputToConsole(logEntry, levelConfig);
  }

  // File output for persistence and monitoring
  if (this.config.enableFileLogging) {
    this.outputToFile(logEntry, levelConfig);
  }

  // Return log entry for testing purposes
  return logEntry;
}

/**
 * Structured Log Entry Creation
 * 
 * Purpose: Creates consistent log entry format for all log messages
 * Ensures all logs contain necessary metadata for filtering and analysis.
 */
createLogEntry(levelConfig, message, context, requestId) {
  const entry = {
    timestamp: new Date().toISOString(),
    level: levelConfig.name,
    message: this.sanitizeMessage(message, levelConfig.name),
    service: 'scrooge-payment-api',
    version: require('../package.json').version || '1.0.0',
    environment: process.env.NODE_ENV || 'development',
    pid: process.pid
  };

  // Add request correlation ID if available
  if (requestId) {
    entry.requestId = requestId;
  }

  // Add context data if provided
  if (context && Object.keys(context).length > 0) {
    entry.context = this.sanitizeContext(context, levelConfig.name);
  }

  // Add memory usage for performance monitoring
  if (levelConfig.priority >= LOG_LEVELS.WARN.priority) {
    const memUsage = process.memoryUsage();
    entry.memory = {
      heapUsed: Math.round(memUsage.heapUsed / 1024 / 1024),
      heapTotal: Math.round(memUsage.heapTotal / 1024 / 1024),
      external: Math.round(memUsage.external / 1024 / 1024)
    };
  }

  return entry;
}

/**
 * Security-Aware Message Sanitization
 * 
 * Purpose: Removes or masks sensitive information from log messages
 * Critical for payment applications to prevent logging of sensitive data.
 */
sanitizeMessage(message, level) {
  if (typeof message !== 'string') {
    message = JSON.stringify(message);
  }

  // Mask sensitive payment information
  const sensitivePatterns = [
    /(\b\d{4}[\s-]?\d{4}[\s-]?\d{4}[\s-]?\d{4}\b)/g, // Credit card numbers
    /(\b\d{3}[\s-]?\d{2}[\s-]?\d{4}\b)/g, // SSN patterns
    /(cvv?[:=]\s*)\d{3,4}/gi, // CVV codes
    /(password[:=]\s*)[\w\W]+/gi, // Passwords
    /(api[_-]?key[:=]\s*)[\w\W]+/gi // API keys
  ];

  let sanitized = message;
  sensitivePatterns.forEach(pattern => {
    sanitized = sanitized.replace(pattern, (match, prefix) => {
      return prefix ? prefix + '[REDACTED]' : '[REDACTED]';
    });
  });

  return sanitized;
</file>

<file path="lib/queueManager.js">
/**
 * Queue Management Utilities for qerrors
 * 
 * This module handles concurrency limiting, queue metrics, and background
 * task management for AI analysis operations. Provides centralized queue
 * management with monitoring and health tracking capabilities.
 * 
 * Design rationale:
 * - Centralized queue logic separates concerns from main error handling
 * - Concurrency limiting prevents resource exhaustion
 * - Metrics collection enables monitoring and alerting
 * - Background cleanup tasks maintain system health
 * - Configurable limits adapt to different deployment environments
 */

const config = require('./config'); //load configuration utilities

let queueRejectCount = 0; //track rejected queue operations for monitoring
let adviceCleanupInterval = null; //track cleanup interval for lifecycle management
let queueMetricsInterval = null; //track metrics interval for lifecycle management

/**
 * Simple Concurrency Limiter
 * 
 * Purpose: Limits concurrent operations without external dependencies
 * Provides identical functionality to p-limit while maintaining module independence.
 */
function createLimiter(max) { //(local concurrency limiter to avoid p-limit dependency while providing identical functionality)
  let running = 0; //(count currently executing operations)
  const queue = []; //(pending operations waiting for execution slot)
  
  const next = () => { //(process next queued operation when slot becomes available)
    if (queue.length > 0 && running < max) { //(check for pending work and available capacity)
      running++; //(claim execution slot)
      const { task, resolve, reject } = queue.shift(); //(get next pending operation)
      task().then(result => { //(execute the queued task)
        running--; //(release execution slot)
        resolve(result); //(resolve with task result)
        next(); //(trigger next operation if queue has more work)
      }).catch(err => { //(handle task failures)
        running--; //(release execution slot)
        reject(err); //(propagate error to caller)
        next(); //(continue processing remaining queue items)
      });
    }
  };
  
  return (task) => { //(limiter function accepts async task and returns promise)
    return new Promise((resolve, reject) => { //(wrap task execution in promise for queue management)
      if (running < max) { //(immediate execution when under limit)
        running++; //(claim execution slot)
        task().then(result => { //(execute task immediately)
          running--; //(release execution slot)
          resolve(result); //(resolve with result)
          next(); //(check for queued work)
        }).catch(err => { //(handle immediate execution errors)
          running--; //(release execution slot)
          reject(err); //(propagate error)
          next(); //(continue queue processing)
        });
      } else { //(queue when at capacity)
        queue.push({ task, resolve, reject }); //(add to pending queue)
      }
    });
  };
}

/**
 * Queue Length Monitoring
 * 
 * Purpose: Provides visibility into queue depth for monitoring and alerting
 */
function getQueueLength() { return queueLength; } //expose current queue depth for monitoring
function getQueueRejectCount() { return queueRejectCount; } //expose reject count

/**
 * Queue Metrics Logging
 * 
 * Purpose: Periodically logs queue health metrics for monitoring
 */
function logQueueMetrics() { //(write queue metrics to logger)
  const logger = require('./logger'); //(load logger for metric output)
  logger.then(log => log.info(`Queue metrics: length=${getQueueLength()}, rejects=${queueRejectCount}`)); //(log current queue state)
}

function startQueueMetrics() { //(begin periodic queue metric logging)
  const intervalMs = config.getInt('QERRORS_METRIC_INTERVAL_MS', 1000); //(configurable metric interval)
  if (!queueMetricsInterval) { queueMetricsInterval = setInterval(logQueueMetrics, intervalMs); } //(start interval if not already running)
}

function stopQueueMetrics() { //(halt metric emission)
  if (queueMetricsInterval) { clearInterval(queueMetricsInterval); queueMetricsInterval = null; } //(clear interval and reset tracker)
}

/**
 * Advice Cache Cleanup Management
 * 
 * Purpose: Manages periodic cleanup of expired cache entries
 */
function startAdviceCleanup(purgeFunction) { //(kick off periodic advice cleanup)
  const ttl = config.getInt('QERRORS_CACHE_TTL', 86400) * 1000; //(convert TTL to milliseconds for interval timing)
  const intervalMs = Math.max(ttl / 4, 60000); //(cleanup every quarter TTL, minimum 1 minute)
  if (!adviceCleanupInterval) { adviceCleanupInterval = setInterval(purgeFunction, intervalMs); } //(start cleanup if not running)
}

function stopAdviceCleanup() { //(stop periodic purge when needed)
  if (adviceCleanupInterval) { clearInterval(adviceCleanupInterval); adviceCleanupInterval = null; } //(clear interval and reset tracker)
}

/**
 * Queue Limit Enforcement
 * 
 * Purpose: Enforces queue size limits and increments reject counters
 */
function enforceQueueLimit(currentLength, maxLength) { //(check if operation should be queued or rejected)
  if (currentLength >= maxLength) {
    queueRejectCount++; //(increment reject counter for monitoring)
    return false; //(reject operation)
  }
  return true; //(allow operation)
}

module.exports = { //(export queue management utilities)
  createLimiter, //(concurrency limiting utility)
  getQueueLength, //(queue depth monitoring)
  getQueueRejectCount, //(reject count monitoring)
  logQueueMetrics, //(manual metrics logging)
  startQueueMetrics, //(start periodic metrics)
  stopQueueMetrics, //(stop periodic metrics)
  startAdviceCleanup, //(start cache cleanup)
  stopAdviceCleanup, //(stop cache cleanup)
  enforceQueueLimit //(queue limit enforcement)
};
</file>

<file path="lib/sanitization.js">
/**
 * Security-Aware Data Sanitization Utilities
 * 
 * This module provides comprehensive data sanitization capabilities for removing
 * or masking sensitive information from log messages, context objects, and other
 * data structures. Critical for applications handling sensitive data like payment
 * processing, user authentication, and API communications.
 * 
 * Design rationale:
 * - Centralized sanitization logic ensures consistent security practices
 * - Pattern-based detection handles various sensitive data formats
 * - Recursive object processing maintains data structure while securing content
 * - Configurable sensitivity levels adapt to different logging contexts
 * - Performance optimized for high-volume logging scenarios
 */

/**
 * Security-Aware Message Sanitization
 * 
 * Purpose: Removes or masks sensitive information from log messages
 * Critical for error handling applications to prevent logging of sensitive data
 * such as API keys, passwords, credit card numbers, and other PII.
 * 
 * Design rationale:
 * - Regex patterns identify common sensitive data formats
 * - Replacement preserves context while masking actual values
 * - Configurable for different security levels based on log level
 * - Maintains log readability while ensuring compliance
 */
function sanitizeMessage(message, level = 'INFO') { //sanitize log messages to prevent sensitive data exposure
    if (typeof message !== 'string') {
        message = JSON.stringify(message); //convert objects to strings for sanitization
    }

    // Enhanced sensitive data patterns for comprehensive protection
    const sensitivePatterns = [
        { pattern: /(\b\d{4}[\s-]?\d{4}[\s-]?\d{4}[\s-]?\d{4}\b)/g, replacement: '[CARD-REDACTED]' }, // Credit card numbers
        { pattern: /(\b\d{3}[\s-]?\d{2}[\s-]?\d{4}\b)/g, replacement: '[SSN-REDACTED]' }, // SSN patterns
        { pattern: /(cvv?[:=]\s*)\d{3,4}/gi, replacement: '$1[REDACTED]' }, // CVV codes
        { pattern: /(password[:=]\s*)[\w\W]+?(?=\s|$|,|\}|\])/gi, replacement: '$1[REDACTED]' }, // Passwords
        { pattern: /(api[_-]?key[:=]\s*)[\w\W]+?(?=\s|$|,|\}|\])/gi, replacement: '$1[REDACTED]' }, // API keys
        { pattern: /(token[:=]\s*)[\w\W]+?(?=\s|$|,|\}|\])/gi, replacement: '$1[REDACTED]' }, // Auth tokens
        { pattern: /(secret[:=]\s*)[\w\W]+?(?=\s|$|,|\}|\])/gi, replacement: '$1[REDACTED]' }, // Secrets
        { pattern: /([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,})/g, replacement: '[EMAIL-REDACTED]' }, // Email addresses
        { pattern: /(\b(?:\+?1[-.\s]?)?\(?[0-9]{3}\)?[-.\s]?[0-9]{3}[-.\s]?[0-9]{4}\b)/g, replacement: '[PHONE-REDACTED]' } // Phone numbers
    ];

    let sanitized = message;
    sensitivePatterns.forEach(({ pattern, replacement }) => {
        sanitized = sanitized.replace(pattern, replacement);
    });

    return sanitized;
}

/**
 * Context Sanitization for Complex Objects
 * 
 * Purpose: Recursively sanitizes context objects while preserving structure
 * Handles nested objects and arrays that may contain sensitive information.
 */
function sanitizeContext(context, level = 'INFO') { //sanitize context objects recursively
    if (!context || typeof context !== 'object') {
        return context; //return primitive values as-is
    }

    if (Array.isArray(context)) {
        return context.map(item => {
            if (typeof item === 'string') {
                return sanitizeMessage(item, level); //sanitize string array items
            } else if (typeof item === 'object') {
                return sanitizeContext(item, level); //recursively sanitize object array items
            } else {
                return item; //preserve primitive array items
            }
        });
    }

    const sanitized = {};
    Object.keys(context).forEach(key => {
        const value = context[key];
        
        // Check if key itself suggests sensitive data
        const sensitiveKeys = ['password', 'token', 'secret', 'auth', 'credential'];
        const isSensitiveKey = sensitiveKeys.some(sensKey => key.toLowerCase().includes(sensKey));
        
        if (isSensitiveKey) {
            sanitized[key] = '[REDACTED]'; //mask entire value for sensitive keys
        } else if (typeof value === 'string') {
            sanitized[key] = sanitizeMessage(value, level); //sanitize string values
        } else if (typeof value === 'object') {
            sanitized[key] = sanitizeContext(value, level); //recursively sanitize nested objects
        } else {
            sanitized[key] = value; //preserve non-string, non-object values
        }
    });

    return sanitized;
}

/**
 * Custom Sanitization Rule Registry
 * 
 * Purpose: Allows applications to register custom sanitization patterns
 * for domain-specific sensitive data formats.
 */
const customPatterns = []; //registry for application-specific patterns

function addCustomSanitizationPattern(pattern, replacement, description = '') { //register custom sanitization rule
    customPatterns.push({ pattern, replacement, description });
}

function clearCustomSanitizationPatterns() { //clear all custom patterns for testing or reconfiguration
    customPatterns.length = 0;
}

/**
 * Advanced Sanitization with Custom Patterns
 * 
 * Purpose: Enhanced sanitization that includes custom application-specific patterns
 * in addition to the standard sensitive data patterns.
 */
function sanitizeWithCustomPatterns(message, level = 'INFO') { //sanitize with both standard and custom patterns
    let sanitized = sanitizeMessage(message, level); //apply standard sanitization first
    
    // Apply custom patterns
    customPatterns.forEach(({ pattern, replacement }) => {
        sanitized = sanitized.replace(pattern, replacement);
    });
    
    return sanitized;
}

module.exports = { //(export sanitization utilities for secure logging)
    sanitizeMessage, //(core message sanitization function)
    sanitizeContext, //(recursive context object sanitization)
    addCustomSanitizationPattern, //(register custom sanitization rules)
    clearCustomSanitizationPatterns, //(clear custom patterns for testing)
    sanitizeWithCustomPatterns //(enhanced sanitization with custom rules)
};
</file>

<file path="lib/utils.js">
/**
 * Common Utility Functions for qerrors module
 * 
 * This module centralizes utility functions that are used across multiple
 * components of the qerrors system. Provides safe operations, string processing,
 * and debugging helpers that maintain consistency throughout the codebase.
 * 
 * Design rationale:
 * - Centralized utilities prevent code duplication
 * - Safe operations provide consistent error handling
 * - String processing utilities handle various data types safely
 * - Debugging helpers maintain consistent logging patterns
 * - Performance utilities enable optimization tracking
 */

/**
 * Safe Function Execution Wrapper
 * 
 * Purpose: Provides consistent error handling for operations that might fail
 * Prevents crashes while maintaining observability of failures.
 */
function safeRun(name, fn, fallback, info) { //utility wrapper for try/catch operations
  try { 
    return fn(); 
  } catch (err) { 
    console.error(`${name} failed`, info); 
    return fallback; 
  }
}

/**
 * Safe Context Stringification
 * 
 * Purpose: Safely converts context objects to strings without throwing on circular references
 * Handles various data types and provides consistent output for logging and debugging.
 */
function stringifyContext(ctx) { //safely stringify context without errors
  try {
    if (typeof ctx === 'string') {
      console.log('stringifyContext is running with string'); //(debug output for development)
      return ctx;
    }
    if (typeof ctx === 'object' && ctx !== null) {
      console.log('stringifyContext is running with object'); //(debug output for development)
      return JSON.stringify(ctx, (key, value) => {
        if (typeof value === 'object' && value !== null) {
          if (value === ctx) return '[Circular *1]'; //(handle self-reference)
          const seen = new Set();
          if (seen.has(value)) return '[Circular]'; //(handle other circular references)
          seen.add(value);
        }
        return value;
      });
    }
    console.log('stringifyContext is running with other type'); //(debug output for development)
    return String(ctx);
  } catch (err) {
    console.log('stringifyContext is returning unknown context'); //(debug output for development)
    return 'unknown context'; //(fallback for any stringify failures)
  }
}

/**
 * Conditional Verbose Logging
 * 
 * Purpose: Provides conditional console output for debugging without logger dependencies
 * Respects environment configuration for verbose output control.
 */
function verboseLog(msg) { //conditional console output helper for debugging without logger dependency
  if (process.env.QERRORS_VERBOSE === 'true') { console.log(msg); } //(respect verbose flag)
}

/**
 * Environment Variable Parsing with Validation
 * 
 * Purpose: Safely parses integer environment variables with bounds checking
 * Provides consistent default handling across the module.
 */
function parseIntWithMin(envVar, defaultValue, minValue = 1) { //parse integer env var with minimum enforcement
  const parsed = parseInt(envVar, 10);
  const value = Number.isNaN(parsed) ? defaultValue : parsed;
  return value >= minValue ? value : minValue;
}

/**
 * Unique Identifier Generation
 * 
 * Purpose: Generates unique identifiers for request correlation and error tracking
 * Uses crypto for strong randomness when available, falls back to timestamp-based IDs.
 */
function generateUniqueId(prefix = '') { //generate unique identifier for tracking
  try {
    const crypto = require('crypto');
    return prefix + crypto.randomUUID();
  } catch (err) {
    // Fallback for environments without crypto.randomUUID
    return prefix + Date.now().toString(36) + Math.random().toString(36).substr(2);
  }
}

/**
 * Deep Object Cloning
 * 
 * Purpose: Creates deep copies of objects to prevent mutation issues
 * Handles circular references and various data types safely.
 */
function deepClone(obj) { //create deep copy of object without mutation risks
  if (obj === null || typeof obj !== 'object') {
    return obj; //return primitives as-is
  }
  
  if (obj instanceof Date) {
    return new Date(obj.getTime()); //handle Date objects
  }
  
  if (Array.isArray(obj)) {
    return obj.map(item => deepClone(item)); //recursively clone array items
  }
  
  const cloned = {};
  Object.keys(obj).forEach(key => {
    cloned[key] = deepClone(obj[key]); //recursively clone object properties
  });
  
  return cloned;
}

/**
 * Performance Timing Utilities
 * 
 * Purpose: Provides high-resolution timing for performance monitoring
 * Uses process.hrtime.bigint() for nanosecond precision when available.
 */
function createTimer() { //create high-resolution timer for performance monitoring
  const startTime = process.hrtime.bigint();
  
  return {
    elapsed() { //get elapsed time in milliseconds
      const endTime = process.hrtime.bigint();
      return Number(endTime - startTime) / 1000000; //convert nanoseconds to milliseconds
    },
    
    elapsedFormatted() { //get formatted elapsed time string
      const ms = this.elapsed();
      if (ms < 1000) {
        return `${ms.toFixed(2)}ms`;
      } else if (ms < 60000) {
        return `${(ms / 1000).toFixed(2)}s`;
      } else {
        return `${(ms / 60000).toFixed(2)}m`;
      }
    }
  };
}

/**
 * Array Processing Utilities
 * 
 * Purpose: Provides safe array operations with null/undefined handling
 */
function safeArrayOperation(arr, operation, defaultValue = []) { //safely perform array operations
  if (!Array.isArray(arr)) {
    return defaultValue; //return default for non-arrays
  }
  
  try {
    return operation(arr);
  } catch (err) {
    verboseLog(`Array operation failed: ${err.message}`);
    return defaultValue;
  }
}

module.exports = { //(export utility functions for use across qerrors module)
  safeRun, //(safe function execution wrapper)
  stringifyContext, //(safe context stringification)
  verboseLog, //(conditional verbose logging)
  parseIntWithMin, //(integer parsing with validation)
  generateUniqueId, //(unique identifier generation)
  deepClone, //(deep object cloning)
  createTimer, //(performance timing utilities)
  safeArrayOperation //(safe array operations)
};
</file>

<file path="stubs/axios.js">
// axios stub used in tests to prevent actual HTTP requests
function stubPost() { //default unmocked post throws to catch stray calls
  throw new Error('axios.post not stubbed'); //fail fast if not stubbed
}

module.exports = {
  post: async () => { stubPost(); }, //simulate axios.post for tests
  create: (opts = {}) => ({ post: async () => { stubPost(); }, defaults: opts }) //mimic axios.create returning instance with post and defaults
};
</file>

<file path="stubs/lru-cache.js">
// simplified LRU cache stub for testing cache logic without external dependency
class LRUCache {
  constructor(opts = {}) {
    this.max = opts.max ?? Infinity; //limit of entries
    this.ttl = opts.ttl ?? 0; //time to live in ms
    this.store = new Map(); //internal storage Map
  }
  get size() { return this.store.size; }
  get(key) { //retrieve value or undefined
    const entry = this.store.get(key);
    if (!entry) return undefined;
    if (this.ttl && Date.now() - entry.ts > this.ttl) { this.store.delete(key); return undefined; }
    this.store.delete(key); this.store.set(key, entry); //move to newest
    return entry.val;
  }
  set(key, val) { //insert value and enforce size limit
    this.store.delete(key);
    this.store.set(key, { val, ts: Date.now() });
    if (this.store.size > this.max) { const first = this.store.keys().next().value; this.store.delete(first); }
  }
  has(key) { return this.get(key) !== undefined; }
  delete(key) { return this.store.delete(key); }
  clear() { this.store.clear(); }
  purgeStale() { //remove expired entries
    if (!this.ttl) return; const now = Date.now();
    for (const [k, e] of this.store) { if (now - e.ts > this.ttl) this.store.delete(k); }
  }
}
module.exports = LRUCache; //export class as module default for CommonJS consumers
module.exports.LRUCache = LRUCache; //provide named export to mimic real module
</file>

<file path="stubs/p-limit.js">
// simplified p-limit stub to control concurrency during tests
module.exports = function(limit){
  let active=0; //current running count
  const queue=[]; //queued functions waiting to run
  const next=()=>{
    if(active>=limit||queue.length===0) return; //respect concurrency and queue length
    const {fn,resolve,reject}=queue.shift();
    active++; //increase active count for concurrency limit
    Promise.resolve().then(fn).then((val)=>{ active--; resolve(val); next(); }).catch((err)=>{ active--; reject(err); next(); });
  };
  const limiter=(fn)=>{ //returned limit function
    return new Promise((resolve,reject)=>{ queue.push({fn,resolve,reject}); next(); });
  };
  Object.defineProperties(limiter,{ activeCount:{get:()=>active}, pendingCount:{get:()=>queue.length} }); //expose counts so tests can inspect usage
  return limiter; //return throttle function
};
</file>

<file path="stubs/qtests.js">
// helper stub for temporarily replacing object methods during tests
module.exports.stubMethod = function(obj, method, impl) {
  const original = obj[method]; //save original function
  obj[method] = impl;
  return function restore() {
    obj[method] = original; //restore original
  };
};
</file>

<file path="stubs/winston.js">
// winston stub to capture logging without side effects
function dummy() { return () => {}; } //placeholder formatter
const format = {
  combine: (...args) => ({ combine: args }),
  timestamp: dummy,
  errors: dummy,
  splat: dummy,
  json: dummy,
  printf: (fn) => fn
};
class File { constructor() {} } //placeholder transport
class Console { constructor() {} } //placeholder transport
module.exports = {
  createLogger: () => ({ error() {}, warn() {}, info() {} }), //return minimal logger object
  format,
  transports: { File, Console }
};
</file>

<file path="test/envUtils.test.js">
const test = require('node:test'); //node test runner //(import node test)

const assert = require('assert');
const qtests = require('qtests');
const { getMissingEnvVars, throwIfMissingEnvVars, warnIfMissingEnvVars } = require('../lib/envUtils');

function withEnvVars(vars) {
       const original = {}; //(store original values)
       Object.entries(vars).forEach(([key, value]) => {
               original[key] = process.env[key]; //(save original)
               if (value === undefined) {
                       delete process.env[key]; //(remove var)
               } else {
                       process.env[key] = value; //(set var)
               }
       });
       return () => { //(restore function)
               Object.entries(original).forEach(([key, value]) => {
                       if (value === undefined) {
                               delete process.env[key]; //(remove restored var)
                       } else {
                               process.env[key] = value; //(restore var)
                       }
               });
       };
}

// Scenario: detect missing environment variables
test('getMissingEnvVars identifies missing variables', () => {
       const restore = withEnvVars({ TEST_VAR1: 'present', TEST_VAR2: undefined });
       try {
               const missing = getMissingEnvVars(['TEST_VAR1', 'TEST_VAR2', 'TEST_VAR3']);
               assert.deepEqual(missing, ['TEST_VAR2', 'TEST_VAR3']); //missing vars returned
       } finally {
               restore();
       }
});

// Scenario: return empty array when all variables present
test('getMissingEnvVars returns empty array when all present', () => {
       const restore = withEnvVars({ TEST_VAR1: 'present', TEST_VAR2: 'also_present' });
       try {
               const missing = getMissingEnvVars(['TEST_VAR1', 'TEST_VAR2']);
               assert.deepEqual(missing, []); //no vars missing
       } finally {
               restore();
       }
});

// Scenario: throw error when required variables missing
test('throwIfMissingEnvVars throws when variables missing', () => {
       const restore = withEnvVars({ REQUIRED_VAR: undefined });
       try {
               assert.throws(() => { //throws when required var absent
                       throwIfMissingEnvVars(['REQUIRED_VAR']);
               }, /Missing required environment variables: REQUIRED_VAR/);
       } finally {
               restore();
       }
});

// Scenario: return empty array when all required variables present
test('throwIfMissingEnvVars returns empty array when all present', () => {
       const restore = withEnvVars({ REQUIRED_VAR: 'present' });
       try {
               const result = throwIfMissingEnvVars(['REQUIRED_VAR']); //returns empty array
               assert.deepEqual(result, []); //no errors thrown
       } finally {
               restore();
       }
});

// Scenario: warn about missing optional variables
test('warnIfMissingEnvVars returns false when variables missing', () => {
       const restore = withEnvVars({ OPTIONAL_VAR: undefined });
       let warnings = [];
       const restoreWarn = qtests.stubMethod(console, 'warn', (msg) => warnings.push(msg));
       try {
               const result = warnIfMissingEnvVars(['OPTIONAL_VAR']); //warn about missing
               assert.equal(result, false); //function indicates missing
               assert.equal(warnings.length, 1); //one warning logged
               assert.ok(warnings[0].includes('OPTIONAL_VAR')); //message references var
       } finally {
               restore();
               restoreWarn();
       }
});

// Scenario: return true when all optional variables present
test('warnIfMissingEnvVars returns true when all present', () => {
       const restore = withEnvVars({ OPTIONAL_VAR: 'present' });
       try {
               const result = warnIfMissingEnvVars(['OPTIONAL_VAR']); //nothing missing
               assert.equal(result, true); //no warning needed
       } finally {
               restore();
       }
});

// Scenario: use custom warning message
test('warnIfMissingEnvVars uses custom message', () => {
       const restore = withEnvVars({ CUSTOM_VAR: undefined });
       let warnings = [];
       const restoreWarn = qtests.stubMethod(console, 'warn', (msg) => warnings.push(msg));
       try {
               warnIfMissingEnvVars(['CUSTOM_VAR'], 'Custom warning message'); //custom warn text
               assert.equal(warnings[0], 'Custom warning message'); //exact message logged
       } finally {
               restore();
               restoreWarn();
       }
});
</file>

<file path="test/index.test.js">
const test = require('node:test'); //node test runner
const assert = require('node:assert/strict'); //strict assertion helpers

const pkg = require('../index'); //entry module with exports to verify
const qerrors = require('../lib/qerrors'); //expected qerrors function
const logger = require('../lib/logger'); //expected logger instance

// Scenario: ensure module exports match the library internals
test('index exports qerrors and logger', () => {
  assert.equal(pkg.qerrors, qerrors); //public export matches implementation
  assert.equal(pkg.logger, logger); //logger exported directly
  assert.equal(pkg.default, qerrors); //default export provided
});
</file>

<file path="test/maxFreeSockets.test.js">
const test = require('node:test'); //node test runner
const assert = require('node:assert/strict'); //strict assertions

function reloadQerrors() { //reload module to apply env vars
  delete require.cache[require.resolve('../lib/qerrors')]; //clear qerrors cache
  delete require.cache[require.resolve('../lib/config')]; //clear config cache
  return require('../lib/qerrors'); //return fresh module
}

test('axiosInstance honors QERRORS_MAX_FREE_SOCKETS', () => {
  const orig = process.env.QERRORS_MAX_FREE_SOCKETS; //save original env value
  process.env.QERRORS_MAX_FREE_SOCKETS = '100'; //set custom free sockets
  const { axiosInstance } = reloadQerrors(); //reload with env variable
  try {
    assert.equal(axiosInstance.defaults.httpAgent.maxFreeSockets, 100); //http agent uses env
    assert.equal(axiosInstance.defaults.httpsAgent.maxFreeSockets, 100); //https agent uses env
  } finally {
    if (orig === undefined) { delete process.env.QERRORS_MAX_FREE_SOCKETS; } else { process.env.QERRORS_MAX_FREE_SOCKETS = orig; }
    reloadQerrors(); //reset module state
  }
});

test('axiosInstance uses default max free sockets when env missing', () => {
  const orig = process.env.QERRORS_MAX_FREE_SOCKETS; //capture original env
  delete process.env.QERRORS_MAX_FREE_SOCKETS; //unset for default test
  const { axiosInstance } = reloadQerrors(); //reload with defaults
  try {
    assert.equal(axiosInstance.defaults.httpAgent.maxFreeSockets, 256); //default http agent value
    assert.equal(axiosInstance.defaults.httpsAgent.maxFreeSockets, 256); //default https agent value
  } finally {
    if (orig === undefined) { delete process.env.QERRORS_MAX_FREE_SOCKETS; } else { process.env.QERRORS_MAX_FREE_SOCKETS = orig; }
    reloadQerrors(); //restore module state
  }
});

test('axiosInstance uses default max free sockets with invalid env', () => { //invalid value fallback
  const orig = process.env.QERRORS_MAX_FREE_SOCKETS; //preserve original value
  process.env.QERRORS_MAX_FREE_SOCKETS = 'abc'; //set non-numeric
  const { axiosInstance } = reloadQerrors(); //reload module with invalid env
  try {
    assert.equal(axiosInstance.defaults.httpAgent.maxFreeSockets, 256); //default http agent value
    assert.equal(axiosInstance.defaults.httpsAgent.maxFreeSockets, 256); //default https agent value
  } finally {
    if (orig === undefined) { delete process.env.QERRORS_MAX_FREE_SOCKETS; } else { process.env.QERRORS_MAX_FREE_SOCKETS = orig; }
    reloadQerrors(); //clean module state
  }
});
</file>

<file path="test/maxTokens.test.js">
const test = require('node:test'); //node test runner
const assert = require('node:assert/strict'); //assert helpers
const qtests = require('qtests'); //stub utilities

function reloadQerrors() { //reload module to apply env vars
  delete require.cache[require.resolve('../lib/qerrors')];
  delete require.cache[require.resolve('../lib/config')];
  return require('../lib/qerrors');
}

function withToken(token) { //temporarily set OPENAI_TOKEN
  const orig = process.env.OPENAI_TOKEN; //save original
  if (token === undefined) { delete process.env.OPENAI_TOKEN; } else { process.env.OPENAI_TOKEN = token; }
  return () => { //restore previous value
    if (orig === undefined) { delete process.env.OPENAI_TOKEN; } else { process.env.OPENAI_TOKEN = orig; }
  };
}

test('analyzeError uses QERRORS_MAX_TOKENS', async () => {
  const restoreToken = withToken('tok'); //provide token for API
  const orig = process.env.QERRORS_MAX_TOKENS; //capture original value
  process.env.QERRORS_MAX_TOKENS = '4096'; //set custom env
  const fresh = reloadQerrors(); //reload with new env
  const capture = {}; //store axios call
  const restoreAxios = qtests.stubMethod(fresh.axiosInstance, 'post', async (u, b) => { capture.body = b; return { data: { choices: [{ message: { content: {} } }] } }; }); //stub post
  try {
    const err = new Error('tok');
    err.uniqueErrorName = 'TOK1';
    await fresh.analyzeError(err, 'ctx');
  } finally {
    restoreAxios();
    if (orig === undefined) { delete process.env.QERRORS_MAX_TOKENS; } else { process.env.QERRORS_MAX_TOKENS = orig; }
    reloadQerrors();
    restoreToken();
  }
  assert.equal(capture.body.max_tokens, 4096); //expect env value used
});

test('analyzeError defaults QERRORS_MAX_TOKENS when unset', async () => {
  const restoreToken = withToken('tok');
  const orig = process.env.QERRORS_MAX_TOKENS; //save env
  delete process.env.QERRORS_MAX_TOKENS; //unset variable
  const fresh = reloadQerrors(); //reload for defaults
  const capture = {}; //capture post body
  const restoreAxios = qtests.stubMethod(fresh.axiosInstance, 'post', async (u, b) => { capture.body = b; return { data: { choices: [{ message: { content: {} } }] } }; });
  try {
    const err = new Error('def');
    err.uniqueErrorName = 'TOKDEF';
    await fresh.analyzeError(err, 'ctx');
  } finally {
    restoreAxios();
    if (orig === undefined) { delete process.env.QERRORS_MAX_TOKENS; } else { process.env.QERRORS_MAX_TOKENS = orig; }
    reloadQerrors();
    restoreToken();
  }
  assert.equal(capture.body.max_tokens, 2048); //default should apply
});

test('analyzeError defaults QERRORS_MAX_TOKENS with invalid env', async () => {
  const restoreToken = withToken('tok');
  const orig = process.env.QERRORS_MAX_TOKENS; //store current
  process.env.QERRORS_MAX_TOKENS = 'abc'; //invalid value
  const fresh = reloadQerrors(); //reload module
  const capture = {}; //capture body
  const restoreAxios = qtests.stubMethod(fresh.axiosInstance, 'post', async (u, b) => { capture.body = b; return { data: { choices: [{ message: { content: {} } }] } }; });
  try {
    const err = new Error('bad');
    err.uniqueErrorName = 'TOKBAD';
    await fresh.analyzeError(err, 'ctx');
  } finally {
    restoreAxios();
    if (orig === undefined) { delete process.env.QERRORS_MAX_TOKENS; } else { process.env.QERRORS_MAX_TOKENS = orig; }
    reloadQerrors();
    restoreToken();
  }
  assert.equal(capture.body.max_tokens, 2048); //invalid falls back
});
</file>

<file path="test/qerrors.test.js">
const test = require('node:test'); //node test runner
const assert = require('node:assert/strict'); //strict assertion helpers
const qtests = require('qtests'); //qtests stubbing utilities

const qerrors = require('../lib/qerrors'); //module under test
const logger = require('../lib/logger'); //winston logger stubbed during tests


function createRes() { //construct minimal Express-like response mock
  return {
    headersSent: false, //simulates whether headers have been sent
    statusCode: null, //captured status for assertions
    payload: null, //body content returned by status/json/send
    status(code) { this.statusCode = code; return this; }, //chainable setter
    json(data) { this.payload = data; return this; }, //capture JSON payload
    send(html) { this.payload = html; return this; } //capture HTML output
  };
}

async function stubDeps(loggerFn, analyzeFn) { //create combined stub utility for tests
  const realLogger = await logger; //wait for logger instance
  const restoreLogger = qtests.stubMethod(realLogger, 'error', loggerFn); //stub logger.error with provided function
  const restoreAnalyze = qtests.stubMethod(qerrors, 'analyzeError', analyzeFn); //stub analyzeError with provided function
  return () => { //return unified restore
    restoreLogger(); //restore logger.error after each test
    restoreAnalyze(); //restore analyzeError after each test
  };
}

// Scenario: standard JSON error handling and next() invocation
test('qerrors logs and responds with json then calls next', async () => {
  let logged; //capture logger output for assertions
  const restore = await stubDeps((err) => { logged = err; }, async () => 'adv'); //stub logger and analyze with helper
  const res = createRes(); //mock response object
  const req = { headers: {} }; //minimal request object
  const err = new Error('boom'); //sample error to handle
  let nextArg; //store argument passed to next()
  const next = (e) => { nextArg = e; }; //spy for next()
  try {
    await qerrors(err, 'ctx', req, res, next);
    await new Promise(r => setTimeout(r, 0)); //wait for queued analysis completion
  } finally {
    restore(); //restore all stubs after test
  }
  assert.ok(err.uniqueErrorName); //unique id added to error
  assert.equal(res.statusCode, 500); //status defaults to 500
  assert.deepEqual(res.payload.error.uniqueErrorName, err.uniqueErrorName); //response includes id
  assert.deepEqual(logged.uniqueErrorName, err.uniqueErrorName); //logged same id
  assert.equal(nextArg, err); //next called with error
});

// Scenario: send HTML when browser requests it
test('qerrors sends html when accept header requests it', async () => {
  const restore = await stubDeps(() => {}, async () => {}); //stub logger and analyze with helper
  const res = createRes(); //mock response object to capture html
  const req = { headers: { accept: 'text/html' } }; //request asking for html
  const err = new Error('boom'); //sample error to send
  try {
    await qerrors(err, 'ctx', req, res);
    await new Promise(r => setTimeout(r, 0)); //wait for queued analysis completion
  } finally {
    restore(); //restore all stubs after test
  }
  assert.equal(res.statusCode, 500); //html response uses error status
  assert.ok(typeof res.payload === 'string'); //payload is html string
});

// Scenario: sanitize html output to avoid injection
test('qerrors escapes html content', async () => {
  const restore = await stubDeps(() => {}, async () => {}); //stub logger and analyze with helper
  const res = createRes(); //mock response object
  const req = { headers: { accept: 'text/html' } }; //requesting html
  const err = new Error('<script>boom</script>'); //error message containing html
  err.stack = '<script>stack</script>'; //custom stack with html
  try {
    await qerrors(err, 'ctx', req, res);
    await new Promise(r => setTimeout(r, 0)); //wait for queued analysis completion
  } finally {
    restore(); //restore stubs after test
  }
  assert.ok(!res.payload.includes('<script>')); //ensure raw tag removed
  assert.ok(res.payload.includes('&lt;script&gt;')); //escaped content present
});

// Scenario: use statusCode from error object in json response
test('qerrors honors error.statusCode in json', async () => {
  const restore = await stubDeps(() => {}, async () => {}); //stub logger and analyze with helper
  const res = createRes(); //mock response for json
  const req = { headers: {} }; //no html accept header
  const err = new Error('not found'); //error with custom status
  err.statusCode = 404; //status code to verify
  try {
    await qerrors(err, 'ctx', req, res); //invoke handler with status
    await new Promise(r => setTimeout(r, 0)); //wait for queued analysis completion
  } finally {
    restore(); //restore stubs after test
  }
  assert.equal(res.statusCode, 404); //expect custom code set in response
  assert.equal(res.payload.error.statusCode, 404); //json includes status code
});

// Scenario: use statusCode from error object in html response
test('qerrors honors error.statusCode in html', async () => {
  const restore = await stubDeps(() => {}, async () => {}); //stub logger and analyze with helper
  const res = createRes(); //mock response for html
  const req = { headers: { accept: 'text/html' } }; //html accept header
  const err = new Error('not found'); //error with custom status
  err.statusCode = 404; //status code to verify
  try {
    await qerrors(err, 'ctx', req, res); //invoke handler with status and html
    await new Promise(r => setTimeout(r, 0)); //wait for queued analysis completion
  } finally {
    restore(); //restore stubs after test
  }
  assert.equal(res.statusCode, 404); //expect custom code set in response
  assert.ok(res.payload.includes('Error: 404')); //html output reflects code
});

// Scenario: skip response when headers already sent
test('qerrors does nothing when headers already sent', async () => {
  const restore = await stubDeps(() => {}, async () => {}); //stub logger and analyze with helper
  const res = createRes(); //mock response object with headers already sent
  res.headersSent = true; //simulate Express sending headers prior
  const err = new Error('boom'); //error to pass into handler
  let nextCalled = false; //track if next() invoked
  try {
    await qerrors(err, 'ctx', {}, res, () => { nextCalled = true; });
    await new Promise(r => setTimeout(r, 0)); //wait for queued analysis completion
  } finally {
    restore(); //restore all stubs after test
  }
  assert.equal(res.statusCode, null); //handler skipped sending response
  assert.equal(nextCalled, false); //next not called when headersSent
});

// Scenario: operate without Express objects
test('qerrors handles absence of req res and next', async () => {
  let logged; //capture logger output
  const restore = await stubDeps((err) => { logged = err; }, async () => {}); //stub logger and analyze with helper
  const err = new Error('boom'); //error for generic usage
  try {
    await qerrors(err);
    await new Promise(r => setTimeout(r, 0)); //wait for queued analysis completion
  } finally {
    restore(); //restore all stubs after test
  }
  assert.ok(err.uniqueErrorName); //middleware assigned id
  assert.equal(logged.context, 'unknown context'); //default context logged
});

// Scenario: still call next when res is undefined
test('qerrors calls next without res', async () => {
  const restore = await stubDeps(() => {}, async () => {}); //stub logger and analyze with helper
  const err = new Error('boom'); //error when res missing
  let nextArg; //captured arg for next()
  try {
    await qerrors(err, 'ctx', undefined, undefined, (e) => { nextArg = e; });
    await new Promise(r => setTimeout(r, 0)); //wait for queued analysis completion
  } finally {
    restore(); //restore all stubs after test
  }
  assert.equal(nextArg, err); //next receives original error
});

// Scenario: warn and exit when called without an error
test('qerrors exits if no error provided', async () => {
  const restore = await stubDeps(() => {}, async () => {}); //stub logger and analyze with helper
  let warned = false; //track if warn was called
  const restoreWarn = qtests.stubMethod(console, 'warn', () => { warned = true; }); //use qtests to stub console.warn
  try {
    await qerrors(null, 'ctx');
    await new Promise(r => setTimeout(r, 0)); //wait for queued analysis completion
    assert.equal(warned, true); //warn called when missing error
  } finally {
    restoreWarn(); //restore console.warn after test
    restore(); //restore all stubs after test
  }
});
</file>

<file path="test/queue.test.js">
const test = require('node:test'); //node test runner
const assert = require('node:assert/strict'); //assert helpers
const qtests = require('qtests'); //stub utilities

function reloadQerrors() { //load fresh module with env
  delete require.cache[require.resolve('../lib/qerrors')];
  return require('../lib/qerrors');
}

test('scheduleAnalysis rejects when queue exceeds limit', async () => {
  const origConc = process.env.QERRORS_CONCURRENCY; //save original concurrency
  const origQueue = process.env.QERRORS_QUEUE_LIMIT; //save original queue limit
  process.env.QERRORS_CONCURRENCY = '1'; //one concurrent analysis
  process.env.QERRORS_QUEUE_LIMIT = '1'; //allow single queued item
  const qerrors = reloadQerrors(); //reload with env vars
  const logger = await require('../lib/logger'); //logger instance
  let logged; //capture logged error
  const restoreLog = qtests.stubMethod(logger, 'error', (e) => { logged = e; });
  const restoreAnalyze = qtests.stubMethod(qerrors, 'analyzeError', async () => {
    return new Promise((r) => setTimeout(r, 20)); //simulate long analysis
  });
  try {
    qerrors(new Error('one')); //first call fills active slot
    qerrors(new Error('two')); //second call should exceed queue limit
    qerrors(new Error('three')); //third call also exceeds queue limit
    await new Promise((r) => setTimeout(r, 30)); //wait for processing
  } finally {
    restoreLog(); //restore logger stub
    restoreAnalyze(); //restore analyze stub
    if (origConc === undefined) { delete process.env.QERRORS_CONCURRENCY; } else { process.env.QERRORS_CONCURRENCY = origConc; }
    if (origQueue === undefined) { delete process.env.QERRORS_QUEUE_LIMIT; } else { process.env.QERRORS_QUEUE_LIMIT = origQueue; }
    reloadQerrors(); //reset module
  }
  assert.ok(logged instanceof Error); //expect error object logged
  assert.equal(logged.message, 'queue full'); //message indicates queue full
});

test('queue reject count increments when queue exceeds limit', async () => {
  const origConc = process.env.QERRORS_CONCURRENCY; //backup env
  const origQueue = process.env.QERRORS_QUEUE_LIMIT; //backup env
  process.env.QERRORS_CONCURRENCY = '1'; //force single concurrency
  process.env.QERRORS_QUEUE_LIMIT = '1'; //allow one queued before rejection
  const qerrors = reloadQerrors(); //reload to apply env
  const logger = await require('../lib/logger'); //logger instance
  const restoreWarn = qtests.stubMethod(logger, 'warn', () => {}); //silence warn
  const restoreError = qtests.stubMethod(logger, 'error', () => {}); //silence err
  const restoreAnalyze = qtests.stubMethod(qerrors, 'analyzeError', async () => {
    return new Promise((r) => setTimeout(r, 20)); //simulate analysis time
  });
  try {
    qerrors(new Error('one')); //consume active slot
    qerrors(new Error('two')); //first rejection increments counter
    qerrors(new Error('three')); //second rejection increments counter
    await new Promise((r) => setTimeout(r, 30)); //allow tasks
  } finally {
    restoreWarn(); //restore warn stub
    restoreError(); //restore error stub
    restoreAnalyze(); //restore analyze stub
    if (origConc === undefined) { delete process.env.QERRORS_CONCURRENCY; } else { process.env.QERRORS_CONCURRENCY = origConc; }
    if (origQueue === undefined) { delete process.env.QERRORS_QUEUE_LIMIT; } else { process.env.QERRORS_QUEUE_LIMIT = origQueue; }
    reloadQerrors(); //reset state
  }
  assert.equal(qerrors.getQueueRejectCount(), 2); //expect two rejections
});

test('getQueueLength reflects queued analyses', async () => {
  const origConc = process.env.QERRORS_CONCURRENCY; //backup env
  const origQueue = process.env.QERRORS_QUEUE_LIMIT; //backup env
  process.env.QERRORS_CONCURRENCY = '1'; //force single concurrency
  process.env.QERRORS_QUEUE_LIMIT = '2'; //allow one queued item
  process.env.OPENAI_TOKEN = 'tkn'; //enable analyzeError path
  const qerrors = reloadQerrors(); //reload to apply env
  const logger = await require('../lib/logger'); //logger instance
  const restoreWarn = qtests.stubMethod(logger, 'warn', () => {}); //silence warn
  const restoreError = qtests.stubMethod(logger, 'error', () => {}); //silence err
  const capture = {}; //track axios args
  const restorePost = qtests.stubMethod(qerrors.axiosInstance, 'post', async () => {
    return new Promise((r) => setTimeout(() => r({ data: { choices: [{ message: { content: '{}' } }] } }), 20)); //simulate delay
  });
  try {
    qerrors(new Error('one')); //consume concurrency slot
    qerrors(new Error('two')); //queued under limit
    await new Promise((r) => setTimeout(r, 15)); //allow queue update
    assert.equal(qerrors.getQueueLength(), 1); //expect one item queued
    await new Promise((r) => setTimeout(r, 30)); //allow tasks
  } finally {
    restoreWarn(); //restore warn stub
    restoreError(); //restore error stub
    restorePost(); //restore axios stub
    if (origConc === undefined) { delete process.env.QERRORS_CONCURRENCY; } else { process.env.QERRORS_CONCURRENCY = origConc; }
    if (origQueue === undefined) { delete process.env.QERRORS_QUEUE_LIMIT; } else { process.env.QERRORS_QUEUE_LIMIT = origQueue; }
    delete process.env.OPENAI_TOKEN; //cleanup token
    reloadQerrors(); //reset state
  }
});

test('scheduleAnalysis uses defaults on invalid env', () => { //verify helper fallback
  const origConc = process.env.QERRORS_CONCURRENCY; //backup
  const origQueue = process.env.QERRORS_QUEUE_LIMIT; //backup
  process.env.QERRORS_CONCURRENCY = 'abc'; //invalid concurrency
  process.env.QERRORS_QUEUE_LIMIT = 'abc'; //invalid queue limit
  delete require.cache[require.resolve('../lib/config')]; //reload config
  const cfg = require('../lib/config'); //load fresh config
  try {
    assert.equal(cfg.getInt('QERRORS_CONCURRENCY'), 5); //falls back to default
    assert.equal(cfg.getInt('QERRORS_QUEUE_LIMIT'), 100); //falls back to default
  } finally {
    if (origConc === undefined) { delete process.env.QERRORS_CONCURRENCY; } else { process.env.QERRORS_CONCURRENCY = origConc; }
    if (origQueue === undefined) { delete process.env.QERRORS_QUEUE_LIMIT; } else { process.env.QERRORS_QUEUE_LIMIT = origQueue; }
    delete require.cache[require.resolve('../lib/config')]; //reset module
    require('../lib/config'); //reapply defaults
  }
});

test('queue never exceeds limit under high concurrency', async () => {
  const origConc = process.env.QERRORS_CONCURRENCY; //backup env
  const origQueue = process.env.QERRORS_QUEUE_LIMIT; //backup env
  process.env.QERRORS_CONCURRENCY = '3'; //allow more active analyses
  process.env.QERRORS_QUEUE_LIMIT = '1'; //only one queued task
  const qerrors = reloadQerrors(); //reload config vars
  const logger = await require('../lib/logger'); //logger instance
  const restoreWarn = qtests.stubMethod(logger, 'warn', () => {}); //silence warn
  const restoreError = qtests.stubMethod(logger, 'error', () => {}); //silence error
  const restoreAnalyze = qtests.stubMethod(qerrors, 'analyzeError', async () => new Promise(r => setTimeout(r, 20))); //simulate work
  try {
    qerrors(new Error('one')); //start first analysis
    qerrors(new Error('two')); //rejected since limit reached
    qerrors(new Error('three')); //rejected since limit reached
    qerrors(new Error('four')); //rejected since limit reached
    qerrors(new Error('five')); //another rejection due to limit
    await new Promise(r => setTimeout(r, 50)); //allow processing
  } finally {
    restoreWarn();
    restoreError();
    restoreAnalyze();
    if (origConc === undefined) { delete process.env.QERRORS_CONCURRENCY; } else { process.env.QERRORS_CONCURRENCY = origConc; }
    if (origQueue === undefined) { delete process.env.QERRORS_QUEUE_LIMIT; } else { process.env.QERRORS_QUEUE_LIMIT = origQueue; }
    reloadQerrors(); //reset state
  }
  assert.ok(qerrors.getQueueLength() <= 1); //queue length at most limit
  assert.equal(qerrors.getQueueRejectCount(), 4); //four tasks rejected
});

test('metrics stop when queue drains then restart on new analysis', async () => {
  const origConc = process.env.QERRORS_CONCURRENCY; //backup concurrency
  const origInterval = process.env.QERRORS_METRIC_INTERVAL_MS; //backup metric interval
  const realSet = global.setInterval; //save original setInterval
  const realClear = global.clearInterval; //save original clearInterval
  let startCount = 0; //track interval creation
  global.setInterval = (fn, ms) => { startCount++; fn(); return { unref() {} }; }; //simulate immediate tick
  global.clearInterval = () => {}; //noop for test
  process.env.QERRORS_CONCURRENCY = '1'; //single task
  process.env.QERRORS_METRIC_INTERVAL_MS = '5'; //fast metrics
  const qerrors = reloadQerrors(); //reload with env
  const logger = await require('../lib/logger'); //logger instance
  let metrics = 0; //metric log count
  const restoreInfo = qtests.stubMethod(logger, 'info', (m) => { if (String(m).startsWith('metrics')) metrics++; });
  const restoreWarn = qtests.stubMethod(logger, 'warn', () => {}); //silence warn
  const restoreError = qtests.stubMethod(logger, 'error', () => {}); //silence error
  const restoreAnalyze = qtests.stubMethod(qerrors, 'analyzeError', async () => new Promise(r => setTimeout(r, 10))); //simulate work
  try {
    qerrors(new Error('one')); //start first analysis
    await new Promise(r => setTimeout(r, 20)); //wait for completion
    const first = metrics; //capture metric count
    await new Promise(r => setTimeout(r, 5)); //allow stopQueueMetrics
    qerrors(new Error('two')); //restart queue
    await new Promise(r => setTimeout(r, 20)); //wait for run
    assert.ok(metrics > first); //metrics resumed
    assert.equal(startCount, 3); //cleanup once and metrics twice
  } finally {
    global.setInterval = realSet; //restore interval
    global.clearInterval = realClear; //restore clear
    restoreInfo();
    restoreWarn();
    restoreError();
    restoreAnalyze();
    if (origConc === undefined) { delete process.env.QERRORS_CONCURRENCY; } else { process.env.QERRORS_CONCURRENCY = origConc; }
    if (origInterval === undefined) { delete process.env.QERRORS_METRIC_INTERVAL_MS; } else { process.env.QERRORS_METRIC_INTERVAL_MS = origInterval; }
    reloadQerrors();
  }
});
</file>

<file path="test/verbose.test.js">
const test = require('node:test'); //node test runner
const assert = require('node:assert/strict'); //assert helpers
const qtests = require('qtests'); //stubbing util
const winston = require('winston'); //winston stub

function reloadLogger() { //reload logger for each test
  delete require.cache[require.resolve('../lib/logger')];
  delete require.cache[require.resolve('../lib/config')];
  return require('../lib/logger');
}

test('logger adds Console transport when verbose true', async () => {
  const orig = process.env.QERRORS_VERBOSE; //save original env
  process.env.QERRORS_VERBOSE = 'true'; //enable console logging
  let captured; //will hold config passed in
  let warned = false; //track verbose warning
  const restore = qtests.stubMethod(winston, 'createLogger', cfg => { captured = cfg; return { transports: cfg.transports, warn: () => { warned = true; }, info() {}, error() {} }; }); //capture transports and watch warn
  const logger = await reloadLogger(); //load module under new env
  await logger;
  try {
    const hasConsole = captured.transports.some(t => t instanceof winston.transports.Console); //check captured transports
    assert.equal(hasConsole, true); //expect console present
    assert.equal(logger.transports.length, captured.transports.length); //logger returns same transports
    assert.equal(warned, true); //expect startup warning
  } finally {
    restore(); //restore stub
    if (orig === undefined) { delete process.env.QERRORS_VERBOSE; } else { process.env.QERRORS_VERBOSE = orig; } //restore env
    reloadLogger(); //clear cache
  }
});

test('logger excludes Console transport when verbose false', async () => {
  const orig = process.env.QERRORS_VERBOSE; //save env
  process.env.QERRORS_VERBOSE = 'false'; //disable console
  let captured; //hold config
  const restore = qtests.stubMethod(winston, 'createLogger', cfg => { captured = cfg; return { transports: cfg.transports, warn() {}, info() {}, error() {} }; }); //capture transports with warn for startup check
  const logger = await reloadLogger(); //reload module
  await logger;
  try {
    const hasConsole = captured.transports.some(t => t instanceof winston.transports.Console); //detect console
    assert.equal(hasConsole, false); //expect none
    assert.equal(logger.transports.length, captured.transports.length); //verify exports
  } finally {
    restore(); //cleanup stub
    if (orig === undefined) { delete process.env.QERRORS_VERBOSE; } else { process.env.QERRORS_VERBOSE = orig; } //restore env
    reloadLogger(); //reset
  }
});
</file>

<file path="test/verboseLog.test.js">
const test = require('node:test'); //node test runner
const assert = require('node:assert/strict'); //assert helpers
const qtests = require('qtests'); //stub utility
const { analyzeError } = require('../lib/qerrors'); //function under test

function runAnalyze() {
  const err = new Error('v');
  err.name = 'AxiosError'; //trigger early return path
  return analyzeError(err, 'ctx');
}

test('verboseLog uses console when QERRORS_VERBOSE=true', async () => {
  const orig = process.env.QERRORS_VERBOSE; //save original env
  process.env.QERRORS_VERBOSE = 'true'; //enable verbose output
  let logged = false; //track console.log usage
  const restore = qtests.stubMethod(console, 'log', () => { logged = true; });
  try {
    await runAnalyze(); //invoke analyzeError which calls verboseLog
    assert.equal(logged, true); //expect console.log called
  } finally {
    restore(); //restore stubbed log
    if (orig === undefined) { delete process.env.QERRORS_VERBOSE; } else { process.env.QERRORS_VERBOSE = orig; } //restore env
  }
});

test('verboseLog skips console when QERRORS_VERBOSE=false', async () => {
  const orig = process.env.QERRORS_VERBOSE; //store env
  process.env.QERRORS_VERBOSE = 'false'; //disable verbose output
  let logged = false; //track calls
  const restore = qtests.stubMethod(console, 'log', () => { logged = true; });
  try {
    await runAnalyze(); //run analyzeError with verbose disabled
    assert.equal(logged, false); //console.log should not run
  } finally {
    restore(); //cleanup stub
    if (orig === undefined) { delete process.env.QERRORS_VERBOSE; } else { process.env.QERRORS_VERBOSE = orig; } //reset env
  }
});

test('verboseLog skips console when QERRORS_VERBOSE unset', async () => {
  const orig = process.env.QERRORS_VERBOSE; //capture original value
  delete process.env.QERRORS_VERBOSE; //unset variable
  let logged = false; //track usage
  const restore = qtests.stubMethod(console, 'log', () => { logged = true; });
  try {
    await runAnalyze(); //execute analyzeError
    assert.equal(logged, false); //expect no console output
  } finally {
    restore(); //restore stub
    if (orig === undefined) { delete process.env.QERRORS_VERBOSE; } else { process.env.QERRORS_VERBOSE = orig; } //restore value
  }
});
</file>

<file path=".github/workflows/node-test.yml">
name: Node.js CI

on:
  push:
  pull_request:

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Use Node.js 18.x # updated from LTS to specific version for consistency
        uses: actions/setup-node@v3
        with:
          node-version: 18.x # sets Node version to 18.x for stable installs
          cache: 'npm'
      - run: npm ci # uses npm ci for deterministic install
      - run: npm test
</file>

<file path="stubs/denque.js">
// minimal denque stub providing queue methods for tests
class Denque {
  constructor(){ this.items = []; }
  push(val){ this.items.push(val); } //add item to end
  shift(){ return this.items.shift(); } //remove item from front
  get length(){ return this.items.length; } //queue size
}
module.exports = Denque; //export stub class
</file>

<file path="stubs/escape-html.js">
// minimal escape-html stub used for tests
module.exports = function escapeHtml(str) {
  return String(str)
    .replace(/&/g, '&amp;')
    .replace(/</g, '&lt;') //escape < for safety
    .replace(/>/g, '&gt;') //escape > for safety
    .replace(/"/g, '&quot;') //escape " for safety
    .replace(/'/g, '&#39;'); //escape ' for safety
};
</file>

<file path="test/centralizedErrorHandling.test.js">
const test = require('node:test'); //node test runner
const assert = require('node:assert/strict'); //strict assertion helpers

const qerrors = require('../lib/qerrors'); //qerrors module with centralized handling
const logger = require('../lib/logger'); //logger for stubbing
const qtests = require('qtests'); //stubbing utilities

function createRes() { //construct minimal Express-like response mock
  return {
    headersSent: false, //simulates whether headers have been sent
    statusCode: null, //captured status for assertions
    payload: null, //body content returned by status/json/send
    status(code) { this.statusCode = code; return this; }, //chainable setter
    json(data) { this.payload = data; return this; }, //capture JSON payload
    send(html) { this.payload = html; return this; } //capture HTML output
  };
}

async function stubLogger(loggerFn) { //stub logger error method
  const realLogger = await logger; //wait for logger instance
  return qtests.stubMethod(realLogger, 'error', loggerFn); //stub logger.error with provided function
}

test('logErrorWithSeverity logs with severity context', async () => {
  let criticalLogged = false; //track critical console output
  let highLogged = false; //track high severity console output

  const restoreLogger = await stubLogger(() => {}); //stub logger to prevent actual logging
  const restoreConsole = qtests.stubMethod(console, 'error', (msg) => { //stub console.error
    if (typeof msg === 'string' && msg.includes('CRITICAL ERROR')) criticalLogged = true;
    if (typeof msg === 'string' && msg.includes('HIGH SEVERITY ERROR')) highLogged = true;
  });

  try {
    const testError = new Error('Test error'); //create test error
    const context = { userId: 123 }; //test context
    
    // Test critical severity
    await qerrors.logErrorWithSeverity(testError, 'testFunction', context, qerrors.errorTypes.ErrorSeverity.CRITICAL);
    assert.ok(criticalLogged); //critical message should be logged to console
    
    // Reset and test high severity
    criticalLogged = false;
    highLogged = false;
    await qerrors.logErrorWithSeverity(testError, 'testFunction', context, qerrors.errorTypes.ErrorSeverity.HIGH);
    assert.ok(highLogged); //high severity message should be logged to console
    
    // Test medium severity (should not trigger console output)
    criticalLogged = false;
    highLogged = false;
    await qerrors.logErrorWithSeverity(testError, 'testFunction', context, qerrors.errorTypes.ErrorSeverity.MEDIUM);
    assert.ok(!criticalLogged); //medium severity should not trigger critical console output
    assert.ok(!highLogged); //medium severity should not trigger high console output

  } finally {
    restoreLogger(); //restore logger stub
    restoreConsole(); //restore console stub
  }
});

test('handleControllerError sends standardized response', async () => {
  const restoreLogger = await stubLogger(() => {}); //stub logger to prevent actual logging
  
  // Don't stub logErrorWithSeverity, just verify the response behavior
  try {
    const res = createRes(); //mock response object
    const testError = qerrors.errorTypes.createTypedError(
      'Validation failed',
      qerrors.errorTypes.ErrorTypes.VALIDATION,
      'VALIDATION_ERROR'
    ); //create typed validation error
    const context = { requestId: 'test-123' }; //test context

    await qerrors.handleControllerError(res, testError, 'testController', context, 'Custom user message');

    assert.equal(res.statusCode, 400); //validation error should return 400
    assert.ok(res.payload); //response should have payload
    assert.equal(res.payload.error.code, 'VALIDATION_ERROR'); //error code should match
    assert.equal(res.payload.error.message, 'Custom user message'); //custom message should be used
    assert.equal(res.payload.error.type, qerrors.errorTypes.ErrorTypes.VALIDATION); //type should match

  } finally {
    restoreLogger(); //restore logger stub
  }
});

test('handleControllerError defaults error type and uses error message', async () => {
  const restoreLogger = await stubLogger(() => {}); //stub logger

  try {
    const res = createRes(); //mock response object
    const testError = new Error('Generic error'); //plain error without type
    
    await qerrors.handleControllerError(res, testError, 'testController');

    assert.equal(res.statusCode, 500); //should default to 500 for system error
    assert.equal(res.payload.error.type, qerrors.errorTypes.ErrorTypes.SYSTEM); //should default to system error
    assert.equal(res.payload.error.message, 'Generic error'); //should use error message when no custom message

  } finally {
    restoreLogger(); //restore logger stub
  }
});

test('withErrorHandling executes operation and returns result on success', async () => {
  const testResult = { success: true }; //mock successful result
  const operation = async () => testResult; //mock successful operation
  
  const result = await qerrors.withErrorHandling(operation, 'testOperation');
  
  assert.deepEqual(result, testResult); //should return operation result
});

test('withErrorHandling logs error and returns fallback on failure', async () => {
  const restoreLogger = await stubLogger(() => {}); //stub logger to prevent actual logging
  
  try {
    const testError = new Error('Operation failed'); //test error
    testError.severity = qerrors.errorTypes.ErrorSeverity.HIGH; //set error severity
    const operation = async () => { throw testError; }; //mock failing operation
    const fallback = { fallback: true }; //fallback result
    
    const result = await qerrors.withErrorHandling(operation, 'testOperation', {}, fallback);
    
    assert.deepEqual(result, fallback); //should return fallback on error

  } finally {
    restoreLogger(); //restore logger stub
  }
});

test('withErrorHandling defaults to medium severity when error has no severity', async () => {
  const restoreLogger = await stubLogger(() => {}); //stub logger to prevent actual logging
  
  try {
    const testError = new Error('Operation failed'); //error without severity
    const operation = async () => { throw testError; }; //mock failing operation
    
    const result = await qerrors.withErrorHandling(operation, 'testOperation');
    
    assert.equal(result, null); //should return null when no fallback provided

  } finally {
    restoreLogger(); //restore logger stub
  }
});

test('withErrorHandling returns null fallback when no fallback provided', async () => {
  const restoreLogger = await stubLogger(() => {}); //stub logger to prevent actual logging

  try {
    const testError = new Error('Operation failed'); //test error
    const operation = async () => { throw testError; }; //mock failing operation
    
    const result = await qerrors.withErrorHandling(operation, 'testOperation');
    
    assert.equal(result, null); //should return null when no fallback provided

  } finally {
    restoreLogger(); //restore logger stub
  }
});
</file>

<file path="test/clearCache.test.js">
const test = require('node:test'); //node test runner
const assert = require('node:assert/strict'); //strict assertions
const qtests = require('qtests'); //helper for stubbing

function withOpenAIToken(token) { //temporarily modify OPENAI_TOKEN
  const orig = process.env.OPENAI_TOKEN; //remember current token
  if (token === undefined) { delete process.env.OPENAI_TOKEN; } else { process.env.OPENAI_TOKEN = token; }
  return () => { if (orig === undefined) { delete process.env.OPENAI_TOKEN; } else { process.env.OPENAI_TOKEN = orig; } };
}

function reloadQerrors() { //load qerrors fresh with current env
  delete require.cache[require.resolve('../lib/qerrors')];
  return require('../lib/qerrors');
}

test('clearAdviceCache empties cache', async () => {
  const restoreToken = withOpenAIToken('cache-token'); //set token for analysis
  const origLimit = process.env.QERRORS_CACHE_LIMIT; //save env limit
  process.env.QERRORS_CACHE_LIMIT = '2'; //ensure caching enabled
  const qerrors = reloadQerrors(); //reload module
  const { analyzeError, axiosInstance } = qerrors; //extract functions
  const restoreAxios = qtests.stubMethod(axiosInstance, 'post', async () => ({ data: { choices: [{ message: { content: { info: 'one' } } }] } }));
  try {
    const err = new Error('boom');
    err.stack = 'stack';
    err.uniqueErrorName = 'CACHECLR';
    const first = await analyzeError(err, 'ctx');
    assert.equal(first.info, 'one'); //initial call fetches advice
    restoreAxios(); //restore first stub
    let calledAgain = false;
    const restoreAxios2 = qtests.stubMethod(axiosInstance, 'post', async () => { calledAgain = true; return { data: { choices: [{ message: { content: { info: 'two' } } }] } }; });
    await analyzeError(err, 'ctx');
    assert.equal(calledAgain, false); //should use cache
    qerrors.clearAdviceCache(); //reset cache
    const afterClear = await analyzeError(err, 'ctx');
    restoreAxios2();
    assert.equal(afterClear.info, 'two'); //axios called again
    assert.equal(calledAgain, true); //verify second stub ran
  } finally {
    if (origLimit === undefined) { delete process.env.QERRORS_CACHE_LIMIT; } else { process.env.QERRORS_CACHE_LIMIT = origLimit; }
    restoreToken();
    reloadQerrors();
  }
});

test('cache limit above threshold clamps and warns', async () => {
  const orig = process.env.QERRORS_CACHE_LIMIT; //backup current env
  process.env.QERRORS_CACHE_LIMIT = '5000'; //set exaggerated limit
  const loggerPromise = require('../lib/logger'); //logger promise for stub
  const log = await loggerPromise; //wait for logger instance
  let warned = false; //track call state
  const restoreWarn = qtests.stubMethod(log, 'warn', () => { warned = true; });
  let limit; //will capture clamped limit
  try {
    const qerrors = reloadQerrors(); //reload module with large limit
    await new Promise(r => setImmediate(r)); //allow async warn callback
    limit = qerrors.getAdviceCacheLimit(); //fetch clamped limit value
  } finally {
    restoreWarn(); //restore logger warn
    if (orig === undefined) { delete process.env.QERRORS_CACHE_LIMIT; } else { process.env.QERRORS_CACHE_LIMIT = orig; }
    delete require.cache[require.resolve('../lib/qerrors')]; //reset state
    require('../lib/qerrors'); //reload defaults
  }
  assert.equal(limit, 1000); //expect clamp to safe threshold
  assert.equal(warned, true); //warning should fire
});
</file>

<file path="test/configFunctions.test.js">
const test = require('node:test'); //node test runner
const assert = require('node:assert/strict'); //assert helpers
const qtests = require('qtests'); //stubbing util

function withEnv(vars) {
  const orig = {};
  Object.entries(vars).forEach(([k, v]) => { orig[k] = process.env[k]; if (v === undefined) { delete process.env[k]; } else { process.env[k] = v; } });
  return () => { Object.entries(orig).forEach(([k, v]) => { if (v === undefined) { delete process.env[k]; } else { process.env[k] = v; } }); };
}

function reloadConfig() {
  delete require.cache[require.resolve('../lib/config')];
  return require('../lib/config');
}

// Scenario: getEnv returns environment variable when set
test('getEnv returns env var when present', () => {
  const restore = withEnv({ TEST_VAL: 'xyz' });
  const cfg = reloadConfig();
  try {
    assert.equal(cfg.getEnv('TEST_VAL'), 'xyz'); //returns provided env value
  } finally { restore(); }
});

// Scenario: getEnv falls back to default when undefined
test('getEnv falls back to default', () => {
  const restore = withEnv({ QERRORS_QUEUE_LIMIT: undefined });
  const cfg = reloadConfig();
  try {
    assert.equal(cfg.getEnv('QERRORS_QUEUE_LIMIT'), '100'); //falls back to default
  } finally { restore(); }
});

// Scenario: safeRun returns function result
test('safeRun returns result', () => {
  const cfg = reloadConfig();
  const res = cfg.safeRun('fn', () => 5, 0);
  assert.equal(res, 5); //returns function output
});

// Scenario: safeRun catches error and returns fallback
test('safeRun returns fallback on error', () => {
  const cfg = reloadConfig();
  let msg;
  const restoreErr = qtests.stubMethod(console, 'error', m => { msg = m; });
  try {
    const out = cfg.safeRun('fn', () => { throw new Error('boom'); }, 7, 'info');
    assert.equal(out, 7); //fallback value used
    assert.ok(msg.includes('fn failed')); //error logged for context
  } finally { restoreErr(); }
});

// Scenario: getInt parses env value
test('getInt parses integer env value', () => {
  const restore = withEnv({ QERRORS_TIMEOUT: '9000' });
  const cfg = reloadConfig();
  try {
    assert.equal(cfg.getInt('QERRORS_TIMEOUT'), 9000); //parses integer env
  } finally { restore(); }
});

// Scenario: getInt falls back to default on invalid env
test('getInt uses default when env invalid', () => {
  const restore = withEnv({ QERRORS_TIMEOUT: 'abc' });
  const cfg = reloadConfig();
  try {
    assert.equal(cfg.getInt('QERRORS_TIMEOUT'), 10000); //invalid env uses default
  } finally { restore(); }
});

// Scenario: getInt enforces minimum value
test('getInt enforces minimum bound', () => {
  const restore = withEnv({ QERRORS_TIMEOUT: '1' });
  const cfg = reloadConfig();
  try {
    assert.equal(cfg.getInt('QERRORS_TIMEOUT', 5), 5); //result respects minimum
  } finally { restore(); }
});
</file>

<file path="test/contextStringify.test.js">
const test = require('node:test'); //node test runner
const assert = require('node:assert/strict'); //assert helpers
const qtests = require('qtests'); //stubbing utility

const qerrorsModule = require('../lib/qerrors'); //module under test
const qerrors = qerrorsModule; //default export used for call
const { axiosInstance } = qerrorsModule; //axios instance for capture
const logger = require('../lib/logger'); //promise resolving logger for capture

function withOpenAIToken(token) { //temporarily set OPENAI_TOKEN
  const orig = process.env.OPENAI_TOKEN; //save original value
  if (token === undefined) { delete process.env.OPENAI_TOKEN; } else { process.env.OPENAI_TOKEN = token; } //apply new token
  return () => { //return restore function
    if (orig === undefined) { delete process.env.OPENAI_TOKEN; } else { process.env.OPENAI_TOKEN = orig; } //restore saved token
  };
}

function stubAxiosPost(content, capture) { //stub axiosInstance.post to capture body
  return qtests.stubMethod(axiosInstance, 'post', async (url, body) => { capture.body = body; return { data: { choices: [{ message: { content } }] } }; });
}

function createRes() { //minimal express like response object
  return { headersSent: false, statusCode: null, payload: null,
    status(code) { this.statusCode = code; return this; },
    json(data) { this.payload = data; return this; },
    send(html) { this.payload = html; return this; } };
}

async function stubLogger(fn) { //stub logger.error for capture
  const real = await logger; //await resolved logger
  return qtests.stubMethod(real, 'error', fn); //replace error method
}

test('qerrors stringifies object context for openai request', async () => {
  const restoreToken = withOpenAIToken('ctx-token'); //ensure token for analysis
  const capture = {}; //capture axios body
  const restoreAxios = stubAxiosPost({ ok: true }, capture); //stub axios
  const res = createRes(); //response mock
  const ctxObj = { foo: 'bar' }; //object context
  const err = new Error('boom'); //sample error
  try {
    await qerrors(err, ctxObj, {}, res); //invoke qerrors with object context
    await new Promise(r => setTimeout(r, 0)); //wait for analysis queue
  } finally {
    restoreAxios(); //restore stubbed axios
    restoreToken(); //restore env token
  }
  assert.ok(capture.body.messages[0].content.includes(JSON.stringify(ctxObj))); //ensure context stringified
});

test('qerrors handles circular context without throwing', async () => {
  const restoreToken = withOpenAIToken(undefined); //ensure analysis skipped
  let logged; //capture logger output
  const restoreLogger = await stubLogger(errObj => { logged = errObj; }); //stub logger
  const res = createRes(); //response mock
  const ctxObj = {}; ctxObj.self = ctxObj; //self reference
  const err = new Error('boom'); //sample error
  try {
    await qerrors(err, ctxObj, {}, res); //invoke with circular context
    await new Promise(r => setTimeout(r, 0)); //wait for queue
  } finally {
    restoreLogger(); //restore logger stub
    restoreToken(); //restore env token
  }
  assert.equal(res.statusCode, 500); //response still sent
  assert.ok(typeof logged.context === 'string'); //context logged as string
  assert.ok(logged.context.includes('[Circular')); //circular marker present
});
</file>

<file path="test/enhancedLogging.test.js">
/**
 * Enhanced Logging Tests for qerrors module
 * 
 * This test suite validates the enhanced logging functionality including
 * security-aware sanitization, performance monitoring, request correlation,
 * and structured logging capabilities.
 */

const { test } = require('node:test'); //node test framework
const assert = require('assert'); //node assert for test validation
const qtests = require('qtests'); //qerrors test utilities for mocking and stubbing
const logger = require('../lib/logger'); //enhanced logger module

// Test constants for validation
const SENSITIVE_DATA = {
    creditCard: '4532-1234-5678-9000',
    ssn: '123-45-6789',
    cvv: 'cvv: 123',
    password: 'password: secretpass123',
    apiKey: 'api_key: sk_test_123456789',
    token: 'token: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9',
    email: 'user@example.com',
    phone: '+1-555-123-4567'
};

const EXPECTED_SANITIZED = {
    creditCard: '[CARD-REDACTED]',
    ssn: '[SSN-REDACTED]',
    cvv: 'cvv: [REDACTED]',
    password: 'password: [REDACTED]',
    apiKey: 'api_key: [REDACTED]',
    token: 'token: [REDACTED]',
    email: '[EMAIL-REDACTED]',
    phone: '[PHONE-REDACTED]'
};

// Test sanitizeMessage function with various sensitive data patterns
test('sanitizeMessage masks credit card numbers', () => {
    const result = logger.sanitizeMessage(`Payment processed for card ${SENSITIVE_DATA.creditCard}`);
    assert.ok(result.includes(EXPECTED_SANITIZED.creditCard)); //credit card should be masked
    assert.ok(!result.includes(SENSITIVE_DATA.creditCard)); //original card number should not appear
});

test('sanitizeMessage masks SSN patterns', () => {
    const result = logger.sanitizeMessage(`User SSN: ${SENSITIVE_DATA.ssn}`);
    assert.ok(result.includes(EXPECTED_SANITIZED.ssn)); //SSN should be masked
    assert.ok(!result.includes(SENSITIVE_DATA.ssn)); //original SSN should not appear
});

test('sanitizeMessage masks CVV codes', () => {
    const result = logger.sanitizeMessage(SENSITIVE_DATA.cvv);
    assert.equal(result, EXPECTED_SANITIZED.cvv); //CVV should be properly masked with prefix preserved
});

test('sanitizeMessage masks passwords', () => {
    const result = logger.sanitizeMessage(SENSITIVE_DATA.password);
    assert.equal(result, EXPECTED_SANITIZED.password); //password should be masked with prefix preserved
});

test('sanitizeMessage masks API keys', () => {
    const result = logger.sanitizeMessage(SENSITIVE_DATA.apiKey);
    assert.equal(result, EXPECTED_SANITIZED.apiKey); //API key should be masked with prefix preserved
});

test('sanitizeMessage masks authentication tokens', () => {
    const result = logger.sanitizeMessage(SENSITIVE_DATA.token);
    assert.equal(result, EXPECTED_SANITIZED.token); //token should be masked with prefix preserved
});

test('sanitizeMessage masks email addresses', () => {
    const result = logger.sanitizeMessage(`Contact: ${SENSITIVE_DATA.email}`);
    assert.ok(result.includes(EXPECTED_SANITIZED.email)); //email should be masked
    assert.ok(!result.includes(SENSITIVE_DATA.email)); //original email should not appear
});

test('sanitizeMessage masks phone numbers', () => {
    const result = logger.sanitizeMessage(`Phone: ${SENSITIVE_DATA.phone}`);
    assert.ok(result.includes(EXPECTED_SANITIZED.phone)); //phone should be masked
    assert.ok(!result.includes(SENSITIVE_DATA.phone)); //original phone should not appear
});

test('sanitizeMessage handles non-string input', () => {
    const objectInput = { message: 'test', card: SENSITIVE_DATA.creditCard };
    const result = logger.sanitizeMessage(objectInput);
    assert.ok(typeof result === 'string'); //should convert to string
    assert.ok(result.includes(EXPECTED_SANITIZED.creditCard)); //should sanitize after conversion
});

// Test sanitizeContext function with nested objects and arrays
test('sanitizeContext handles simple objects', () => {
    const context = {
        user: 'john',
        cardNumber: SENSITIVE_DATA.creditCard,
        amount: 100
    };
    const result = logger.sanitizeContext(context);
    assert.equal(result.user, 'john'); //non-sensitive data preserved
    assert.equal(result.amount, 100); //numeric data preserved
    assert.equal(result.cardNumber, '[REDACTED]'); //sensitive key completely masked for security
});

test('sanitizeContext masks sensitive keys', () => {
    const context = {
        password: 'secretvalue',
        apiKey: 'keyvalue',
        token: 'tokenvalue',
        normalField: 'normalvalue'
    };
    const result = logger.sanitizeContext(context);
    assert.equal(result.password, '[REDACTED]'); //sensitive key masked
    assert.equal(result.apiKey, '[REDACTED]'); //sensitive key masked
    assert.equal(result.token, '[REDACTED]'); //sensitive key masked
    assert.equal(result.normalField, 'normalvalue'); //normal field preserved
});

test('sanitizeContext handles nested objects recursively', () => {
    const context = {
        user: {
            name: 'john',
            credentials: {
                password: 'secret123',
                apiKey: 'key123'
            }
        },
        payment: {
            cardInfo: SENSITIVE_DATA.creditCard,
            amount: 100
        }
    };
    const result = logger.sanitizeContext(context);
    assert.equal(result.user.name, 'john'); //normal nested field preserved
    assert.equal(result.user.credentials.password, '[REDACTED]'); //nested sensitive key masked
    assert.equal(result.user.credentials.apiKey, '[REDACTED]'); //nested sensitive key masked
    assert.equal(result.payment.amount, 100); //normal nested field preserved
    assert.ok(result.payment.cardInfo.includes('[CARD-REDACTED]')); //nested sensitive data sanitized in string
});

test('sanitizeContext handles arrays', () => {
    const context = {
        users: [
            { name: 'john', password: 'secret1' },
            { name: 'jane', password: 'secret2' }
        ],
        paymentInfo: [SENSITIVE_DATA.creditCard, '5555-4444-3333-2222']
    };
    const result = logger.sanitizeContext(context);
    assert.equal(result.users[0].name, 'john'); //array item field preserved
    assert.equal(result.users[0].password, '[REDACTED]'); //array item sensitive key masked
    assert.equal(result.users[1].name, 'jane'); //array item field preserved
    assert.equal(result.users[1].password, '[REDACTED]'); //array item sensitive key masked
    assert.ok(result.paymentInfo[0].includes('[CARD-REDACTED]')); //array sensitive data masked
    assert.ok(result.paymentInfo[1].includes('[CARD-REDACTED]')); //array sensitive data masked
});

test('sanitizeContext handles null and undefined values', () => {
    const context = {
        nullValue: null,
        undefinedValue: undefined,
        emptyString: '',
        zero: 0
    };
    const result = logger.sanitizeContext(context);
    assert.equal(result.nullValue, null); //null preserved
    assert.equal(result.undefinedValue, undefined); //undefined preserved
    assert.equal(result.emptyString, ''); //empty string preserved
    assert.equal(result.zero, 0); //zero preserved
});

// Test createEnhancedLogEntry function
test('createEnhancedLogEntry generates complete log structure', () => {
    const entry = logger.createEnhancedLogEntry('INFO', 'Test message', { user: 'john' }, 'req-123');
    
    assert.equal(entry.level, 'INFO'); //correct log level
    assert.equal(entry.message, 'Test message'); //message preserved
    assert.equal(entry.requestId, 'req-123'); //request ID included
    assert.equal(entry.context.user, 'john'); //context included
    assert.ok(entry.timestamp); //timestamp generated
    assert.ok(entry.service); //service name included
    assert.ok(entry.environment); //environment included
    assert.equal(typeof entry.pid, 'number'); //process ID included
    assert.ok(entry.hostname); //hostname included
});

test('createEnhancedLogEntry includes memory usage for high severity levels', () => {
    const warnEntry = logger.createEnhancedLogEntry('WARN', 'Warning message');
    const errorEntry = logger.createEnhancedLogEntry('ERROR', 'Error message');
    const infoEntry = logger.createEnhancedLogEntry('INFO', 'Info message');
    
    assert.ok(warnEntry.memory); //memory included for WARN level
    assert.ok(errorEntry.memory); //memory included for ERROR level
    assert.ok(!infoEntry.memory); //memory not included for INFO level
    
    assert.equal(typeof warnEntry.memory.heapUsed, 'number'); //heap usage is numeric
    assert.equal(typeof warnEntry.memory.heapTotal, 'number'); //heap total is numeric
    assert.equal(typeof warnEntry.memory.external, 'number'); //external memory is numeric
    assert.equal(typeof warnEntry.memory.rss, 'number'); //RSS is numeric
});

test('createEnhancedLogEntry sanitizes message and context', () => {
    const entry = logger.createEnhancedLogEntry('INFO', 
        `Payment for card ${SENSITIVE_DATA.creditCard}`, 
        { password: 'secret123', user: 'john' }
    );
    
    assert.ok(entry.message.includes('[CARD-REDACTED]')); //message sanitized
    assert.ok(!entry.message.includes(SENSITIVE_DATA.creditCard)); //original card not in message
    assert.equal(entry.context.password, '[REDACTED]'); //context sanitized
    assert.equal(entry.context.user, 'john'); //non-sensitive context preserved
});

// Test enhanced logging functions - simplified tests that work with existing logger structure
test('logInfo function exists and can be called', async () => {
    // Test that the function exists and doesn't throw when called
    assert.ok(typeof logger.logInfo === 'function'); //logInfo function exists
    
    // Test that calling it doesn't throw an error
    try {
        await logger.logInfo('Test message', { user: 'john' }, 'req-123');
        assert.ok(true); //function call completed without throwing
    } catch (error) {
        assert.fail(`logInfo should not throw: ${error.message}`);
    }
});

test('logError function exists and can be called', async () => {
    // Test that the function exists and doesn't throw when called
    assert.ok(typeof logger.logError === 'function'); //logError function exists
    
    try {
        await logger.logError('Error message', { operation: 'test' });
        assert.ok(true); //function call completed without throwing
    } catch (error) {
        assert.fail(`logError should not throw: ${error.message}`);
    }
});

// Test performance timer functionality with simplified validation
test('createPerformanceTimer returns a function', () => {
    const timer = logger.createPerformanceTimer('testOperation', 'req-123');
    assert.ok(typeof timer === 'function'); //timer should be a function
});

test('createPerformanceTimer function can be executed', async () => {
    const timer = logger.createPerformanceTimer('testOperation');
    
    try {
        const result = await timer(true, { custom: 'data' });
        assert.ok(result); //timer should return a result
        assert.ok(typeof result.duration_ms === 'number'); //duration should be numeric
        assert.equal(result.success, true); //success status should be preserved
        assert.equal(result.custom, 'data'); //additional context should be preserved
    } catch (error) {
        assert.fail(`Performance timer should not throw: ${error.message}`);
    }
});

test('createPerformanceTimer handles failure scenarios', async () => {
    const timer = logger.createPerformanceTimer('failedOperation');
    
    try {
        const result = await timer(false, { error: 'operation failed' });
        assert.ok(result); //timer should return a result even on failure
        assert.equal(result.success, false); //failure status should be preserved
        assert.equal(result.error, 'operation failed'); //error context should be preserved
    } catch (error) {
        assert.fail(`Performance timer should handle failures gracefully: ${error.message}`);
    }
});

// Test LOG_LEVELS constants
test('LOG_LEVELS contains all expected levels with priorities', () => {
    const levels = logger.LOG_LEVELS;
    
    assert.ok(levels.DEBUG); //DEBUG level exists
    assert.ok(levels.INFO); //INFO level exists
    assert.ok(levels.WARN); //WARN level exists
    assert.ok(levels.ERROR); //ERROR level exists
    assert.ok(levels.FATAL); //FATAL level exists
    assert.ok(levels.AUDIT); //AUDIT level exists
    
    assert.ok(levels.DEBUG.priority < levels.INFO.priority); //DEBUG < INFO priority
    assert.ok(levels.INFO.priority < levels.WARN.priority); //INFO < WARN priority
    assert.ok(levels.WARN.priority < levels.ERROR.priority); //WARN < ERROR priority
    assert.ok(levels.ERROR.priority < levels.FATAL.priority); //ERROR < FATAL priority
    assert.ok(levels.FATAL.priority < levels.AUDIT.priority); //FATAL < AUDIT priority
    
    assert.ok(levels.DEBUG.color); //DEBUG has color
    assert.ok(levels.DEBUG.name); //DEBUG has name
});
</file>

<file path="test/loggerFunctions.test.js">
const test = require('node:test'); //node test runner
const assert = require('node:assert/strict'); //assert helpers
const qtests = require('qtests'); //stubbing util

const loggerPromise = require('../lib/logger');
const { logStart, logReturn } = require('../lib/logger');

// Scenario: logStart logs start message

test('logStart logs function start', async () => {
  const log = await loggerPromise;
  let msg;
  const restore = qtests.stubMethod(log, 'info', m => { msg = m; });
  try {
    await logStart('fn', { a: 1 });
  } finally { restore(); }
  assert.equal(msg, 'fn start {"a":1}'); //info logged at start
});

// Scenario: logReturn logs return message

test('logReturn logs function return', async () => {
  const log = await loggerPromise;
  let msg;
  const restore = qtests.stubMethod(log, 'info', m => { msg = m; });
  try {
    await logReturn('fn', { b: 2 });
  } finally { restore(); }
  assert.equal(msg, 'fn return {"b":2}'); //info logged with return value
});
</file>

<file path="test/logLevel.test.js">
const test = require('node:test'); //node test runner
const assert = require('node:assert/strict'); //assert helpers
const qtests = require('qtests'); //stubbing util
const winston = require('winston'); //winston stub

function reloadLogger() { //reload logger with env changes
  delete require.cache[require.resolve('../lib/logger')];
  delete require.cache[require.resolve('../lib/config')];
  return require('../lib/logger');
}

test('logger uses QERRORS_LOG_LEVEL env var', async () => {
  const orig = process.env.QERRORS_LOG_LEVEL; //save original value
  process.env.QERRORS_LOG_LEVEL = 'debug'; //set custom level
  let captured; //capture config
  const restore = qtests.stubMethod(winston, 'createLogger', cfg => { captured = cfg; return { level: cfg.level, transports: cfg.transports, warn() {}, info() {}, error() {} }; }); //return stub logger
  const logger = await reloadLogger();
  try {
    assert.equal(captured.level, 'debug'); //logger configured with env level
    assert.equal((await logger).level, 'debug'); //promise resolves same level
  } finally {
    restore();
    if (orig === undefined) { delete process.env.QERRORS_LOG_LEVEL; } else { process.env.QERRORS_LOG_LEVEL = orig; }
    reloadLogger(); //reset cache
  }
});

test('logger defaults QERRORS_LOG_LEVEL when unset', async () => {
  const orig = process.env.QERRORS_LOG_LEVEL; //store original
  delete process.env.QERRORS_LOG_LEVEL; //unset for default test
  let captured; //capture config
  const restore = qtests.stubMethod(winston, 'createLogger', cfg => { captured = cfg; return { level: cfg.level, transports: cfg.transports, warn() {}, info() {}, error() {} }; }); //return stub logger
  const logger = await reloadLogger();
  try {
    assert.equal(captured.level, 'info'); //default level used when unset
    assert.equal((await logger).level, 'info'); //logger exposes default
  } finally {
    restore();
    if (orig === undefined) { delete process.env.QERRORS_LOG_LEVEL; } else { process.env.QERRORS_LOG_LEVEL = orig; }
    reloadLogger(); //reset cache
  }
});
</file>

<file path="AGENTS.md">
# AGENTS.md

## VISION

The qerrors module represents a paradigm shift from traditional error logging to intelligent error analysis. The core vision is to bridge the gap between error occurrence and resolution by leveraging AI to provide contextual debugging suggestions at the moment errors happen. This transforms error handling from a reactive debugging process into a proactive assistance system.

The business rationale centers on reducing developer debugging time and improving error resolution speed in production environments. By caching AI-generated advice and implementing queue-based analysis, the module balances the cost of AI API calls with the value of intelligent debugging assistance. The design assumes that most errors in production are repetitive patterns that can benefit from AI analysis, while avoiding infinite loops through careful axios error detection.

The module's economic model is built around cost-effective AI usage - caching prevents redundant API calls for identical errors, while concurrency limits prevent rate limiting charges. The queue-based approach ensures that expensive AI analysis never blocks critical application responses, maintaining user experience while providing debugging value.

The architecture prioritizes graceful degradation - the module must never break an application due to its own failures. This defensive approach influences every design decision, from the Promise-based async analysis to the careful separation of response generation and AI processing.

## FUNCTIONALITY

AI agents working on this codebase must understand that qerrors implements a sophisticated error handling middleware that must never cause additional errors. The module is designed to be "error-safe" meaning any failure in qerrors itself should fail and simply console.error rather than propagate.

Key agent boundaries:
- Never implement recursive error handling where qerrors processes its own errors
- Maintain the promise-based async pattern for AI analysis to prevent blocking application responses
- Preserve the LRU cache mechanism which is critical for cost control with AI APIs
- Respect the concurrency limiting system which prevents API rate limit violations

The AI analysis prompt engineering is specifically tuned for console output readability and practical debugging advice. Agents should not modify the prompt structure without understanding its optimization for avoiding generic responses and formatting issues in log files.

Expected behaviors for agents:
- Always test error scenarios without API tokens to ensure graceful degradation
- Verify that Express middleware contracts are maintained (proper next() handling)
- Ensure content negotiation works for both HTML and JSON responses
- Test queue overflow scenarios to verify rejection counting works correctly
- Validate that cache cleanup intervals don't interfere with application performance
- Confirm that verbose logging can be toggled without breaking functionality

## SCOPE

**In Scope:**
- Error handling middleware functionality and AI-powered analysis features
- Logging configuration and transport management
- Environment variable validation and configuration helpers
- Caching mechanisms for AI advice and queue management
- Express.js middleware integration and response handling
- Test coverage for all error handling scenarios

**Out of Scope:**
- Frontend error handling or client-side error reporting
- Database schema changes or data persistence beyond log files
- Authentication or authorization mechanisms
- Real-time error monitoring dashboards or alerting systems
- Integration with external monitoring services beyond OpenAI
- Performance profiling or application performance monitoring features

**Change Restrictions:**
- Do not modify the core error handling flow that prevents infinite recursion
- Do not alter the async analysis pattern that keeps responses fast
- Do not change the Express middleware signature without extensive testing

## CONSTRAINTS

**Protected Components:**
- The axios error detection logic in `analyzeError()` function must not be modified without understanding recursion prevention
- Environment variable defaults in `lib/config.js` require careful consideration as they affect production behavior
- The LRU cache TTL and cleanup mechanisms are performance-critical and must be preserved
- Test stubs in `/stubs` directory are dependency replacements and must maintain API compatibility
- The `postWithRetry()` function's exponential backoff algorithm is tuned for OpenAI API rate limits
- Socket connection pooling settings in the axios instance are optimized for AI API usage patterns
- The queue metrics collection system must not be modified without understanding memory implications

**Special Processes:**
- Any changes to OpenAI API integration require testing with and without API tokens
- Logging transport configuration changes need verification across different environments
- Cache limit modifications must consider memory usage implications in production
- Concurrency limit changes require load testing to avoid rate limiting issues

**Workflow Exceptions:**
- The module intentionally avoids standard function start/end logging to prevent noise in error scenarios
- Dependencies are intentionally minimal and should not be expanded without justification
- The module must remain compatible with Node.js 18+ as specified in package.json

## POLICY

**Module-Specific Policies:**
- This is an npm module that should remain framework-agnostic while providing Express middleware capabilities
- All AI API calls must implement retry logic with exponential backoff to handle transient failures
- Error messages must be developer-friendly and avoid generic phrases that don't aid debugging
- The module should gracefully handle OpenAI API changes and response format variations
- Version compatibility must be maintained for Node.js LTS versions (currently 18+)
- The module must never require external databases or persistent storage beyond file system logs
- AI prompt engineering should prioritize actionable debugging advice over generic error descriptions

**Testing Requirements:**
- Every new feature must include tests for both success and failure scenarios
- API integration tests must work with stubbed responses to avoid external dependencies
- Cache behavior must be tested for both hit and miss scenarios
- Queue limits and concurrency controls must be verified under load

**Security Considerations:**
- Environment variables containing API keys must never be logged or exposed in error messages
- User-provided error data must be sanitized when generating HTML responses
- The module must not introduce XSS vulnerabilities through error message display

**Maintenance Standards:**
- Keep dependencies minimal and prefer Node.js built-in modules where possible
- Maintain backward compatibility for major version increments
- Document any breaking changes clearly in changelog and migration guides
- Performance benchmarks must be maintained for key operations (cache lookups, queue processing)
- Memory usage patterns should be monitored, especially for long-running applications
- OpenAI API cost implications must be documented for any changes to prompt structure or frequency
</file>

<file path="setup.js">
const path = require('path'); // use Node path to build absolute stub directory
const Module = require('module'); // access internal module loader to refresh paths
const stubsPath = path.join(__dirname, 'stubs'); // resolve location of dependency stubs
process.env.NODE_PATH = process.env.NODE_PATH // prepend stubs directory to module lookup
  ? `${stubsPath}${path.delimiter}${process.env.NODE_PATH}` // keep existing NODE_PATH while prioritizing stubs
  : stubsPath; // when NODE_PATH is empty ensure stubs are still used
Module._initPaths(); // reinitialize resolution cache so Node picks up updated NODE_PATH
</file>

<file path="lib/envUtils.js">
/**
 * Core utility for identifying missing environment variables
 * 
 * This function serves as the foundation for all environment validation in qerrors.
 * It uses a functional programming approach with Array.filter for clean, readable code
 * that efficiently processes multiple variables in a single pass.
 * 
 * Design rationale:
 * - Pure function design enables easy testing and reuse
 * - Filter operation is more readable than manual loop constructs  
 * - Returns array format allows flexible handling by calling code
 * - Truthiness check handles both undefined and empty string cases
 * 
 * @param {string[]} varArr - Array of environment variable names to check
 * @returns {string[]} Array of missing variable names (empty if all present)
 */
function getMissingEnvVars(varArr) {
       const missingArr = varArr.filter(name => !process.env[name]); //identify missing environment variables using functional filter
       return missingArr; //return filtered array of missing variable names
}

/**
 * Throws an error if any required environment variables are missing
 * 
 * This function implements the "fail fast" principle for critical configuration.
 * It's designed for variables that are absolutely required for application function.
 * The thrown error includes all missing variables to help developers fix all issues at once.
 * 
 * @param {string[]} varArr - Array of required environment variable names
 * @throws {Error} If any variables are missing, with descriptive message
 * @returns {string[]} Empty array if no variables are missing (for testing purposes)
 */
function throwIfMissingEnvVars(varArr) {
       const missingEnvVars = getMissingEnvVars(varArr); //reuse detection utility

       if (missingEnvVars.length > 0) {
               const errorMessage = `Missing required environment variables: ${missingEnvVars.join(', ')}`; //(construct descriptive error message listing all missing vars)
               console.error(errorMessage); //(log prior to throw for immediate visibility)
               const err = new Error(errorMessage); //(create error object with detailed message)
               console.error(err); //(log error instead of calling qerrors to avoid infinite recursion in error handling module)
               throw err; //(propagate failure to stop application startup when critical config missing)
       }

       return missingEnvVars; //(return empty array when all required vars present, useful for testing)
}

/**
 * Logs warnings for missing optional environment variables
 * 
 * This function handles variables that enhance functionality but aren't strictly required.
 * It uses console.warn rather than throwing errors to allow graceful degradation.
 * The function is designed to provide helpful feedback without breaking the application.
 * 
 * @param {string[]} varArr - Array of optional environment variable names to check
 * @param {string} customMessage - Custom warning message to display (optional)
 * @returns {boolean} True if all variables are present, otherwise false
 */
function warnIfMissingEnvVars(varArr, customMessage = '') {
       const missingEnvVars = getMissingEnvVars(varArr); //reuse detection utility

       if (missingEnvVars.length > 0) {
               const warningMessage = customMessage ||
                       `Warning: Optional environment variables missing: ${missingEnvVars.join(', ')}. Some features may not work as expected.`; //(construct warning message with fallback default text)
               console.warn(warningMessage); //(log warning for optional vars without breaking application flow)
       }

       const result = missingEnvVars.length === 0; //(determine if any vars missing, compute boolean for simpler return type)
       return result; //(inform caller if all vars present, boolean instead of array for cleaner API)
}

module.exports = { //(export environment validation utilities for use across qerrors module)
       getMissingEnvVars, //(core detection function for identifying missing vars)
       throwIfMissingEnvVars, //(fail-fast validation for critical configuration)
       warnIfMissingEnvVars //(graceful degradation validation for optional configuration)
};
</file>

<file path="stubs/winston-daily-rotate-file.js">
// stub of winston-daily-rotate-file to avoid file system operations in tests
class DailyRotateFile {
  constructor(opts) {
    this.options = opts; //expose options like real module for tests
    // Use global tracking to ensure all instances are captured
    if (!global.DailyRotateFileCalls) global.DailyRotateFileCalls = [];
    global.DailyRotateFileCalls.push(opts);
    // Also track on class for backward compatibility
    DailyRotateFile.calls.push(opts); //record constructor usage
  }
}
DailyRotateFile.calls = []; //track constructor calls for tests
module.exports = DailyRotateFile; //export stub constructor
</file>

<file path="test/analyzeError.test.js">
const test = require('node:test'); //node builtin test runner
const assert = require('node:assert/strict'); //strict assertions for reliability
const qtests = require('qtests'); //qtests stubbing utilities
const crypto = require('crypto'); //node crypto for hashing count

const qerrorsModule = require('../lib/qerrors'); //import module under test
const { analyzeError } = qerrorsModule; //extract analyzeError for direct calls
const { axiosInstance } = qerrorsModule; //instance used inside analyzeError
const { postWithRetry } = qerrorsModule; //helper used for retrying requests
const config = require('../lib/config'); //load env defaults for assertions //(new import)


function withOpenAIToken(token) { //(temporarily set OPENAI_TOKEN)
  const orig = process.env.OPENAI_TOKEN; //(capture existing value)
  if (token === undefined) { //(check if token unset)
    delete process.env.OPENAI_TOKEN; //(remove from env)
  } else {
    process.env.OPENAI_TOKEN = token; //(assign token)
  }
  return () => { //(return restore)
    if (orig === undefined) { //(restore by delete)
      delete process.env.OPENAI_TOKEN; //(delete if absent before)
    } else {
      process.env.OPENAI_TOKEN = orig; //(otherwise restore value)
    }
  };
}

function withRetryEnv(retry, base, max) { //(temporarily set retry env vars)
  const origRetry = process.env.QERRORS_RETRY_ATTEMPTS; //(store original attempts)
  const origBase = process.env.QERRORS_RETRY_BASE_MS; //(store original delay)
  const origMax = process.env.QERRORS_RETRY_MAX_MS; //(store original cap)
  if (retry === undefined) { delete process.env.QERRORS_RETRY_ATTEMPTS; } else { process.env.QERRORS_RETRY_ATTEMPTS = String(retry); } //(apply retry)
  if (base === undefined) { delete process.env.QERRORS_RETRY_BASE_MS; } else { process.env.QERRORS_RETRY_BASE_MS = String(base); } //(apply delay)
  if (max === undefined) { delete process.env.QERRORS_RETRY_MAX_MS; } else { process.env.QERRORS_RETRY_MAX_MS = String(max); } //(apply cap)
  return () => { //(restore both variables)
    if (origRetry === undefined) { delete process.env.QERRORS_RETRY_ATTEMPTS; } else { process.env.QERRORS_RETRY_ATTEMPTS = origRetry; }
    if (origBase === undefined) { delete process.env.QERRORS_RETRY_BASE_MS; } else { process.env.QERRORS_RETRY_BASE_MS = origBase; }
    if (origMax === undefined) { delete process.env.QERRORS_RETRY_MAX_MS; } else { process.env.QERRORS_RETRY_MAX_MS = origMax; }
  };
}

function stubAxiosPost(content, capture) { //(capture axiosInstance.post args and stub response)
  return qtests.stubMethod(axiosInstance, 'post', async (url, body) => { //(store url and body for assertions)
    capture.url = url; //(save called url)
    capture.body = body; //(save called body)
    return { data: { choices: [{ message: { content } }] } }; //(return predictable api response as object)
  });
}

// Scenario: skip analyzing Axios errors to prevent infinite loops
test('analyzeError handles AxiosError gracefully', async () => {
  const err = new Error('axios fail');
  err.name = 'AxiosError';
  err.uniqueErrorName = 'AXERR';
  const result = await analyzeError(err, 'ctx');
  assert.equal(result, null); //(expect null when axios error is skipped)
});

// Scenario: return null when API token is missing
test('analyzeError returns null without token', async () => {
  const restoreToken = withOpenAIToken(undefined); //(unset OPENAI_TOKEN)
  try {
    const err = new Error('no token');
    err.uniqueErrorName = 'NOTOKEN';
    const result = await analyzeError(err, 'ctx');
    assert.equal(result, null); //should return null when token missing
  } finally {
    restoreToken(); //(restore original token)
  }
});

// Scenario: handle successful API response with JSON content
test('analyzeError processes JSON response from API', async () => {
  const restoreToken = withOpenAIToken('test-token'); //(set valid token)
  const capture = {}; //(object to collect axios call args)
  const restoreAxios = stubAxiosPost({ advice: 'test advice' }, capture); //(stub axios and capture arguments with object)
  try {
    const err = new Error('test error');
    err.uniqueErrorName = 'TESTERR';
    const result = await analyzeError(err, 'test context');
    assert.ok(result); //result should be defined on success
    assert.equal(result.advice, 'test advice'); //parsed advice should match
    assert.equal(capture.url, config.getEnv('QERRORS_OPENAI_URL')); //(assert api endpoint used)
    assert.equal(capture.body.model, 'gpt-4o'); //(validate model in request body)
    assert.ok(Array.isArray(capture.body.messages)); //(ensure messages array sent)
    assert.equal(capture.body.messages[0].role, 'user'); //(first message role should be user)
    assert.deepEqual(capture.body.response_format, { type: 'json_object' }); //(verify response_format object)
  } finally {
    restoreToken(); //(restore original token)
    restoreAxios(); //(restore axios)
  }
});

// Scenario: handle API response parsing errors gracefully
test('analyzeError handles JSON parse errors', async () => {
  const restoreToken = withOpenAIToken('test-token'); //(set valid token)
  const cap = {}; //(obj to capture axios args if needed)
  const restoreAxios = stubAxiosPost('invalid json', cap); //(stub axios with invalid JSON)
  try {
    const err = new Error('test error');
    err.uniqueErrorName = 'PARSEERR';
    const result = await analyzeError(err, 'test context');
    assert.equal(result, null); //(expect null when JSON parsing fails)
  } finally {
    restoreToken(); //(restore original token)
    restoreAxios(); //(restore axios)
  }
});

// Scenario: reuse cached advice when same error repeats
test('analyzeError returns cached advice on repeat call', async () => {
  const restoreToken = withOpenAIToken('cache-token'); //(set token for analysis)
  const capture = {}; //(capture axios parameters)
  const restoreAxios = stubAxiosPost({ advice: 'cached' }, capture); //(first api response as object)
  try {
    const err = new Error('cache me');
    err.stack = 'stack';
    err.uniqueErrorName = 'CACHE1';
    const first = await analyzeError(err, 'ctx');
    assert.equal(first.advice, 'cached'); //initial call stores advice
    restoreAxios(); //(remove first stub)
    let secondCalled = false; //(track second axios call)
    const restoreAxios2 = qtests.stubMethod(axiosInstance, 'post', async () => { secondCalled = true; return {}; });
    const err2 = new Error('cache me');
    err2.stack = 'stack';
    err2.uniqueErrorName = 'CACHE2';
    const second = await analyzeError(err2, 'ctx');
    restoreAxios2(); //(restore second stub)
    assert.equal(second.advice, 'cached'); //cache should supply same advice
    assert.equal(secondCalled, false); //(axios should not run second time)
  } finally {
    restoreToken(); //(restore environment)
  }
});

// Scenario: reuse provided qerrorsKey without rehashing
test('analyzeError reuses error.qerrorsKey when present', async () => {
  const restoreToken = withOpenAIToken('reuse-token'); //(set token for test)
  const capture = {}; //(capture axios parameters)
  const restoreAxios = stubAxiosPost({ info: 'first' }, capture); //(stub axios with object)
  let hashCount = 0; //(track calls to crypto.createHash)
  const origHash = crypto.createHash; //(store original function)
  const restoreHash = qtests.stubMethod(crypto, 'createHash', (...args) => { hashCount++; return origHash(...args); });
  try {
    const err = new Error('reuse error');
    err.stack = 'stack';
    err.uniqueErrorName = 'REUSEKEY';
    err.qerrorsKey = 'preset';
    const first = await analyzeError(err, 'ctx');
    assert.equal(first.info, 'first'); //advice from API stored
    assert.equal(hashCount, 0); //(ensure hashing not called)
    const again = await analyzeError(err, 'ctx');
    assert.equal(again.info, 'first'); //second call reuses advice without hash
  } finally {
    restoreHash(); //(restore crypto.createHash)
    restoreToken(); //(restore token)
    restoreAxios(); //(restore axios)
  }
});

test('analyzeError retries failed axios calls', async () => {
  const restoreToken = withOpenAIToken('retry-token'); //(set token for test)
  const restoreEnv = withRetryEnv(2, 1); //(set small retry delay for speed)
  let callCount = 0; //(track number of axios posts)
  const restoreAxios = qtests.stubMethod(axiosInstance, 'post', async () => { //(stub post to fail then succeed)
    callCount++; //(increment counter)
    if (callCount < 3) { throw new Error('fail'); } //(fail first two)
    return { data: { choices: [{ message: { content: { ok: true } } }] } }; //(success after retries)
  });
  try {
    const err = new Error('retry');
    err.uniqueErrorName = 'RETRYERR';
    const res = await analyzeError(err, 'ctx');
    assert.equal(res.ok, true); //(ensure success after retry)
    assert.equal(callCount, 3); //(called initial + 2 retries)
  } finally {
    restoreAxios(); //(restore axios)
    restoreEnv(); //(restore env vars)
    restoreToken(); //(restore token)
  }
});

test('analyzeError uses postWithRetry helper', async () => {
  const restoreToken = withOpenAIToken('helper-token'); //(set token for test)
  let helperCalled = false; //(flag when helper invoked)
  const restoreHelper = qtests.stubMethod(qerrorsModule, 'postWithRetry', async () => { //(stub helper)
    helperCalled = true; //(mark invocation)
    return { data: { choices: [{ message: { content: { ok: true } } }] } }; //(fake success response)
  });
  try {
    const err = new Error('helper');
    err.uniqueErrorName = 'HELPER';
    const result = await analyzeError(err, 'ctx');
    assert.equal(result.ok, true); //(expect parsed advice)
    assert.equal(helperCalled, true); //(ensure helper ran)
  } finally {
    restoreHelper(); //(restore stub)
    restoreToken(); //(restore token)
  }
});

function reloadQerrors() { //helper to reload module with current env for cache tests
  delete require.cache[require.resolve('../lib/qerrors')]; //remove cached module so env changes apply
  return require('../lib/qerrors'); //load qerrors again with new env
}

// Scenario: disable caching when limit is zero
test('analyzeError bypasses cache when limit is zero', async () => {
  const restoreToken = withOpenAIToken('zero-token'); //(set token for api)
  const origLimit = process.env.QERRORS_CACHE_LIMIT; //(store existing cache limit)
  process.env.QERRORS_CACHE_LIMIT = '0'; //(env value to disable cache)
  const fresh = reloadQerrors(); //(reload module with zero cache limit)
  const restoreAxios1 = qtests.stubMethod(fresh.axiosInstance, 'post', async () => ({ data: { choices: [{ message: { content: { msg: 1 } } }] } })); //(stub for first analysis)
  try {
    const err = new Error('nocache');
    err.stack = 'stack';
    err.uniqueErrorName = 'NOCACHE1';
    await fresh.analyzeError(err, 'ctx');
    restoreAxios1(); //(remove first stub)
    let secondCalled = false; //(track second axios call when cache disabled)
    const restoreAxios2 = qtests.stubMethod(fresh.axiosInstance, 'post', async () => { secondCalled = true; return { data: { choices: [{ message: { content: { msg: 2 } } }] } }; });
    const err2 = new Error('nocache');
    err2.stack = 'stack';
    err2.uniqueErrorName = 'NOCACHE2';
    await fresh.analyzeError(err2, 'ctx');
    restoreAxios2(); //(restore second stub)
    assert.equal(secondCalled, true); //(axios should run again without caching)
  } finally {
    if (origLimit === undefined) { delete process.env.QERRORS_CACHE_LIMIT; } else { process.env.QERRORS_CACHE_LIMIT = origLimit; }
    reloadQerrors(); //(restore default module state)
    restoreToken(); //(restore token)
  }
});

// Scenario: ensure hashing skipped when cache disabled
test('analyzeError does not hash when cache limit is zero', async () => {
  const restoreToken = withOpenAIToken('nohash-token'); //(set token for api)
  const origLimit = process.env.QERRORS_CACHE_LIMIT; //(store current limit)
  process.env.QERRORS_CACHE_LIMIT = '0'; //(disable caching)
  const fresh = reloadQerrors(); //(reload module with new env)
  let hashCount = 0; //(track hashing)
  const origHash = crypto.createHash; //(reference original)
  const restoreHash = qtests.stubMethod(crypto, 'createHash', (...args) => { hashCount++; return origHash(...args); }); //(count calls)
  try {
    const err = new Error('nohash');
    err.stack = 'stack';
    err.uniqueErrorName = 'NOHASH';
    await fresh.analyzeError(err, 'ctx');
    assert.equal(hashCount, 0); //(expect hashing skipped)
    assert.equal(err.qerrorsKey, undefined); //(ensure key not set)
  } finally {
    restoreHash(); //(restore createHash)
    if (origLimit === undefined) { delete process.env.QERRORS_CACHE_LIMIT; } else { process.env.QERRORS_CACHE_LIMIT = origLimit; }
    reloadQerrors(); //(reset module)
    restoreToken(); //(restore token)
  }
});
</file>

<file path="test/cleanupMetrics.test.js">
const test = require('node:test'); //node test runner
const assert = require('node:assert/strict'); //assert helpers
const qtests = require('qtests'); //stubbing util

function withEnv(vars) {
  const orig = {};
  Object.entries(vars).forEach(([k, v]) => { orig[k] = process.env[k]; if (v === undefined) { delete process.env[k]; } else { process.env[k] = v; } });
  return () => { Object.entries(orig).forEach(([k, v]) => { if (v === undefined) { delete process.env[k]; } else { process.env[k] = v; } }); };
}

function reloadQerrors() {
  delete require.cache[require.resolve('../lib/qerrors')];
  delete require.cache[require.resolve('../lib/config')];
  return require('../lib/qerrors');
}

// Scenario: startAdviceCleanup schedules interval and stopAdviceCleanup clears it
test('advice cleanup interval start and stop', () => {
  const restoreEnv = withEnv({ QERRORS_CACHE_TTL: '1', QERRORS_CACHE_LIMIT: '2' });
  const realSet = global.setInterval;
  const realClear = global.clearInterval;
  let called = 0; let ms; let unref = false; const handle = { unref() { unref = true; } };
  global.setInterval = (fn, m) => { called++; ms = m; return handle; };
  let cleared; global.clearInterval = h => { cleared = h; };
  const qerrors = reloadQerrors();
  try {
    qerrors.startAdviceCleanup();
    assert.equal(called, 1); //interval should be created once
    assert.equal(ms, 1000); //interval uses env ttl in ms
    assert.equal(unref, true); //interval handle unref'd
    qerrors.stopAdviceCleanup();
    assert.equal(cleared, handle); //cleanup clears same handle
  } finally {
    global.setInterval = realSet;
    global.clearInterval = realClear;
    restoreEnv();
    reloadQerrors();
  }
});

// Scenario: purgeExpiredAdvice calls underlying cache purge
test('purgeExpiredAdvice triggers cache purge', () => {
  const restoreEnv = withEnv({ QERRORS_CACHE_TTL: '1', QERRORS_CACHE_LIMIT: '1' });
  const { LRUCache } = require('lru-cache');
  let purged = false;
  const restorePur = qtests.stubMethod(LRUCache.prototype, 'purgeStale', function() { purged = true; });
  const qerrors = reloadQerrors();
  try {
    qerrors.purgeExpiredAdvice();
    assert.equal(purged, true); //cache purge executed
  } finally {
    restorePur();
    restoreEnv();
    reloadQerrors();
  }
});

// Scenario: startQueueMetrics schedules interval and stopQueueMetrics clears it
test('queue metrics interval start and stop', () => {
  const restoreEnv = withEnv({ QERRORS_METRIC_INTERVAL_MS: '5' });
  const realSet = global.setInterval;
  const realClear = global.clearInterval;
  let called = 0; let ms; let unref = false; const handle = { unref() { unref = true; } };
  global.setInterval = (fn, m) => { called++; ms = m; return handle; };
  let cleared; global.clearInterval = h => { cleared = h; };
  const qerrors = reloadQerrors();
  try {
    qerrors.startQueueMetrics();
    assert.equal(called, 1); //metrics interval created
    assert.equal(ms, 5); //interval uses env value
    assert.equal(unref, true); //handle unref'd for cleanup
    qerrors.stopQueueMetrics();
    assert.equal(cleared, handle); //interval cleared correctly
  } finally {
    global.setInterval = realSet;
    global.clearInterval = realClear;
    restoreEnv();
    reloadQerrors();
  }
});

// Scenario: getAdviceCacheLimit clamps values
test('getAdviceCacheLimit reflects clamped env', () => {
  const restoreEnv = withEnv({ QERRORS_CACHE_LIMIT: '2000' });
  const qerrors = reloadQerrors();
  try {
    assert.equal(qerrors.getAdviceCacheLimit(), 1000); //limit clamped to max
  } finally {
    restoreEnv();
    reloadQerrors();
  }
});
</file>

<file path="package.json">
{
  "name": "qerrors",
  "version": "1.2.4",
  "description": "Intelligent error handling middleware with AI-powered analysis, environment validation, caching, and production-ready logging. Provides OpenAI-based error suggestions, queue management, retry mechanisms, and comprehensive configuration options for Node.js applications.",
  "main": "index.js",
  "scripts": {
    "test": "node -r ./setup.js --test"
  },
  "keywords": [
    "error",
    "logger",
    "middleware",
    "debugging",
    "AI",
    "openai",
    "environment",
    "validation",
    "caching",
    "retry",
    "queue",
    "winston",
    "express",
    "nodejs"
  ],
  "author": "Q",
  "license": "ISC",
  "dependencies": {
    "axios": "^1.9.0",
    "denque": "^2.1.0",
    "escape-html": "^1.0.3",
    "lru-cache": "^10.0.0",
    "qtests": "^1.0.4",
    "winston": "^3.13.0",
    "winston-daily-rotate-file": "^5.0.0"
  },
  "directories": {
    "lib": "lib"
  },
  "repository": {
    "type": "git",
    "url": "https://github.com/Bijikyu/qerrors"
  },
  "engines": {
    "node": ">=18"
  }
}
</file>

<file path="replit.md">
# qerrors - Intelligent Error Handling Middleware

## Overview

qerrors is a Node.js middleware library that combines traditional error logging with AI-powered debugging assistance. It provides intelligent error analysis using OpenAI's GPT models while maintaining production-ready reliability through graceful degradation, caching, and queue management.

The system is designed with a "never break the application" philosophy - all AI features are optional and the middleware will continue functioning even when external services fail.

## System Architecture

### Core Components
- **Error Handling Middleware**: Express.js compatible middleware for capturing and processing errors
- **AI Analysis Engine**: OpenAI GPT-4o integration for generating contextual debugging advice
- **Caching Layer**: LRU cache with TTL for cost-effective AI advice storage
- **Queue Management**: Concurrency-limited queue system for managing AI analysis requests
- **Logging System**: Winston-based structured logging with file rotation

### Technology Stack
- **Runtime**: Node.js 18+
- **HTTP Client**: Axios with custom retry logic and connection pooling
- **Caching**: Custom LRU cache with time-to-live support
- **Queue**: Denque-based double-ended queue for O(1) operations
- **Logging**: Enhanced Winston with security-aware sanitization, performance monitoring, and structured logging
- **Security**: HTML escaping for safe error output plus comprehensive data sanitization

## Key Components

### Error Processing Pipeline
1. **Error Capture**: Middleware intercepts errors from Express applications
2. **Unique Identification**: Generates crypto-based unique identifiers for error tracking
3. **Context Analysis**: Extracts and processes error context including stack traces
4. **Security Sanitization**: Removes sensitive data from logs using pattern-based detection
5. **AI Analysis**: Queues errors for OpenAI analysis with caching and retry logic
6. **Enhanced Logging**: Structured logging with performance monitoring and request correlation
7. **Response Generation**: Returns structured JSON or HTML responses based on Accept headers

### Configuration System
- **Environment Variables**: 20+ configurable parameters for fine-tuning behavior
- **Defaults**: Production-ready defaults with conservative resource limits
- **Validation**: Built-in environment variable validation with helpful error messages
- **Dynamic Configuration**: Runtime configuration changes without restarts

### Queue and Concurrency Management
- **Concurrency Limiting**: Configurable concurrent AI analysis requests (default: 5)
- **Queue Management**: Bounded queue with overflow protection (default: 100 pending)
- **Metrics**: Built-in queue health monitoring and logging
- **Backpressure**: Graceful degradation when system is overloaded

## Data Flow

1. **Error Occurrence**: Application error triggers middleware
2. **Error Enrichment**: Unique ID generation and context extraction
3. **Immediate Response**: HTTP response sent to client without waiting for AI analysis
4. **Background Analysis**: Error queued for AI processing with concurrency control
5. **Cache Check**: System checks for existing advice before API call
6. **AI Analysis**: OpenAI API call with retry logic and timeout protection
7. **Cache Storage**: Results stored in LRU cache for future identical errors
8. **Logging**: Structured logs written to rotating files

## External Dependencies

### Required Services
- **OpenAI API**: GPT-4o model for error analysis (optional - graceful degradation when unavailable)

### NPM Dependencies
- **axios**: HTTP client with retry and connection pooling
- **winston**: Structured logging framework
- **winston-daily-rotate-file**: Log rotation management
- **denque**: High-performance queue implementation
- **lru-cache**: Memory-efficient caching with TTL support
- **escape-html**: Security-focused HTML escaping
- **qtests**: Testing utilities for mocking and stubbing

## Deployment Strategy

### Environment Configuration
- **Development**: Verbose logging enabled, reduced cache sizes, immediate error feedback
- **Production**: File-only logging, optimized cache settings, queue metrics monitoring
- **High Traffic**: Increased concurrency limits, larger caches, enhanced connection pooling

### Resource Management
- **Memory**: LRU cache with configurable limits and TTL-based cleanup
- **Network**: Connection pooling with configurable socket limits
- **File System**: Rotating logs with size and time-based retention policies
- **API Costs**: Intelligent caching prevents redundant OpenAI API calls

### Monitoring and Observability
- **Queue Metrics**: Periodic logging of queue depth and processing rates
- **Error Tracking**: Unique error IDs for correlation across logs
- **Performance Monitoring**: Built-in timing and resource usage tracking
- **Health Checks**: Environment validation on startup with helpful warnings

## Changelog

```
Changelog:
- June 17, 2025. Initial setup
- June 17, 2025. Enhanced error middleware with meta-error handling, headers protection, and improved fallback responses
- June 17, 2025. Integrated comprehensive enhanced logging system with security-aware sanitization, performance monitoring, request correlation, and structured logging capabilities
```

## User Preferences

```
Preferred communication style: Simple, everyday language.
```
</file>

<file path="lib/errorTypes.js">
/**
 * Error classification and standardized handling utilities for qerrors
 * 
 * This module provides standardized error handling patterns extending the core qerrors
 * functionality with structured error classification, severity mapping, and Express-specific
 * response utilities. It implements error handling best practices including:
 * 
 * 1. Standardized error response format for API consistency
 * 2. Error classification for appropriate handling strategies
 * 3. Context-aware logging for debugging and monitoring
 * 4. Request ID tracking for error correlation
 * 5. Severity-based error routing and alerting
 * 
 * Design rationale:
 * - Extends existing qerrors functionality rather than replacing it
 * - Provides consistent error classification across applications
 * - Enables appropriate HTTP status code mapping
 * - Supports severity-based monitoring and alerting
 * - Maintains backward compatibility with existing qerrors usage
 */

'use strict'; //(enable strict mode for error types module)

const crypto = require('crypto'); //node crypto for request ID generation
const { randomUUID } = require('crypto'); //import UUID generator for request tracking

/**
 * Error type classification for appropriate handling strategies
 * 
 * Design rationale: Different error types require different handling approaches.
 * This classification enables appropriate response codes, user messages,
 * logging levels, and recovery strategies.
 */
const ErrorTypes = {
    VALIDATION: 'validation',           // User input errors (400)
    AUTHENTICATION: 'authentication',   // Auth failures (401)
    AUTHORIZATION: 'authorization',     // Permission errors (403)
    NOT_FOUND: 'not_found',            // Resource not found (404)
    RATE_LIMIT: 'rate_limit',          // Rate limiting (429)
    NETWORK: 'network',                // External service errors (502/503)
    DATABASE: 'database',              // Database errors (500)
    SYSTEM: 'system',                  // Internal system errors (500)
    CONFIGURATION: 'configuration'      // Config/setup errors (500)
};

/**
 * Error severity levels for logging and alerting
 * 
 * Design rationale: Different error severities require different response strategies.
 * This classification enables appropriate logging, alerting, and escalation.
 */
const ErrorSeverity = {
    LOW: 'low',           // Expected errors, user mistakes
    MEDIUM: 'medium',     // Operational issues, recoverable
    HIGH: 'high',         // Service degradation, requires attention
    CRITICAL: 'critical'  // Service disruption, immediate response needed
};

/**
 * Maps error types to appropriate HTTP status codes
 * 
 * Design rationale: Consistent HTTP status code mapping ensures proper client
 * behavior and follows REST API conventions.
 */
const ERROR_STATUS_MAP = {
    [ErrorTypes.VALIDATION]: 400,
    [ErrorTypes.AUTHENTICATION]: 401,
    [ErrorTypes.AUTHORIZATION]: 403,
    [ErrorTypes.NOT_FOUND]: 404,
    [ErrorTypes.RATE_LIMIT]: 429,
    [ErrorTypes.NETWORK]: 502,
    [ErrorTypes.DATABASE]: 500,
    [ErrorTypes.SYSTEM]: 500,
    [ErrorTypes.CONFIGURATION]: 500
};

/**
 * Maps error types to severity levels for monitoring
 * 
 * Design rationale: Automatic severity classification enables appropriate
 * alerting and escalation without manual intervention.
 */
const ERROR_SEVERITY_MAP = {
    [ErrorTypes.VALIDATION]: ErrorSeverity.LOW,
    [ErrorTypes.AUTHENTICATION]: ErrorSeverity.LOW,
    [ErrorTypes.AUTHORIZATION]: ErrorSeverity.MEDIUM,
    [ErrorTypes.NOT_FOUND]: ErrorSeverity.LOW,
    [ErrorTypes.RATE_LIMIT]: ErrorSeverity.MEDIUM,
    [ErrorTypes.NETWORK]: ErrorSeverity.MEDIUM,
    [ErrorTypes.DATABASE]: ErrorSeverity.HIGH,
    [ErrorTypes.SYSTEM]: ErrorSeverity.HIGH,
    [ErrorTypes.CONFIGURATION]: ErrorSeverity.CRITICAL
};

/**
 * Extracts or generates request ID for error correlation
 * 
 * Design rationale: Request tracking enables correlation of errors across
 * distributed systems and helps with debugging user-specific issues.
 * 
 * @param {Object} req - Express request object (optional)
 * @returns {string} Request ID for correlation
 */
function getRequestId(req) { //extract or generate request identifier for tracking
    if (req && req.headers) { //extract from headers when available
        return req.headers['x-request-id'] || 
               req.headers['x-correlation-id'] || 
               req.headers['request-id'] ||
               randomUUID(); //generate when header missing
    }
    return randomUUID(); //generate when no request object
}

/**
 * Creates a standardized error object with consistent format
 * 
 * Design rationale: Standardized error format ensures consistent API responses
 * and enables proper error handling on the client side. Includes all
 * necessary information for debugging and user feedback.
 * 
 * @param {string} code - Error code for programmatic handling
 * @param {string} message - Human-readable error message
 * @param {string} type - Error type from ErrorTypes enum
 * @param {Object} context - Additional context for debugging
 * @returns {Object} Standardized error object
 */
function createStandardError(code, message, type, context = {}) { //build standard error object with consistent format
    return {
        code, //error code for programmatic handling
        message, //human readable error description
        type, //classification from ErrorTypes enum
        timestamp: new Date().toISOString(), //ISO timestamp for chronological analysis
        requestId: context.requestId || getRequestId(context.req), //correlation identifier
        context: { //additional debugging information
            ...context,
            req: undefined, //remove req object to prevent circular references in JSON
            res: undefined  //remove res object to prevent circular references in JSON
        }
    };
}

/**
 * Sends standardized JSON error response
 * 
 * Design rationale: Centralized response logic ensures consistent API
 * behavior and reduces code duplication across controllers.
 * 
 * @param {Object} res - Express response object
 * @param {number} statusCode - HTTP status code
 * @param {Object} errorObject - Standardized error object
 */
function sendErrorResponse(res, statusCode, errorObject) { //send consistent JSON error response
    if (res && !res.headersSent) { //prevent double response errors
        res.status(statusCode).json({ error: errorObject }); //structured error response format
    }
}

/**
 * Creates a typed error with classification and context
 * 
 * Design rationale: Factory function for creating errors with proper
 * classification, enabling consistent handling across the application.
 * 
 * @param {string} message - Error message
 * @param {string} type - Error type from ErrorTypes
 * @param {string} code - Error code for identification
 * @param {Object} context - Additional context
 * @returns {Error} Enhanced error object with type information
 */
function createTypedError(message, type, code = 'GENERIC_ERROR', context = {}) { //create error with type classification
    const error = new Error(message); //base error object
    error.type = type; //attach error type for handling logic
    error.code = code; //attach error code for programmatic identification
    error.context = context; //attach context for debugging
    error.statusCode = ERROR_STATUS_MAP[type] || 500; //determine HTTP status from type
    error.severity = ERROR_SEVERITY_MAP[type] || ErrorSeverity.MEDIUM; //determine severity from type
    return error; //return enhanced error object
}

/**
 * Factory for creating specific error types with predefined configurations
 * 
 * Design rationale: Provides convenient error creation functions for common
 * error scenarios, ensuring consistent error codes and messages across the
 * application while reducing boilerplate code.
 */
const ErrorFactory = {
    /**
     * Creates validation error for user input issues
     * 
     * @param {string} message - Validation error message
     * @param {string} field - Optional field name that failed validation
     * @param {Object} context - Additional context for debugging
     * @returns {Object} Standardized validation error object
     */
    validation(message, field = null, context = {}) { //create validation error with field context
        return createStandardError(
            'VALIDATION_ERROR', //consistent validation error code
            message, //user-provided validation message
            ErrorTypes.VALIDATION, //validation error type
            { ...context, field } //include field context for debugging
        );
    },

    /**
     * Creates authentication error for login/auth issues
     * 
     * @param {string} message - Auth error message
     * @param {Object} context - Additional context for debugging
     * @returns {Object} Standardized authentication error object
     */
    authentication(message = 'Authentication required', context = {}) { //create auth error with default message
        return createStandardError(
            'AUTHENTICATION_ERROR', //consistent auth error code
            message, //auth failure message
            ErrorTypes.AUTHENTICATION, //authentication error type
            context //debugging context
        );
    },

    /**
     * Creates authorization error for permission issues
     * 
     * @param {string} message - Authorization error message
     * @param {Object} context - Additional context for debugging
     * @returns {Object} Standardized authorization error object
     */
    authorization(message = 'Insufficient permissions', context = {}) { //create authz error with default message
        return createStandardError(
            'AUTHORIZATION_ERROR', //consistent authz error code
            message, //permission failure message
            ErrorTypes.AUTHORIZATION, //authorization error type
            context //debugging context
        );
    },

    /**
     * Creates not found error for missing resources
     * 
     * @param {string} resource - Name of the missing resource
     * @param {Object} context - Additional context for debugging
     * @returns {Object} Standardized not found error object
     */
    notFound(resource, context = {}) { //create not found error with resource context
        return createStandardError(
            'NOT_FOUND', //consistent not found error code
            `${resource} not found`, //resource-specific not found message
            ErrorTypes.NOT_FOUND, //not found error type
            context //debugging context
        );
    },

    /**
     * Creates rate limit error for quota violations
     * 
     * @param {string} message - Rate limit error message
     * @param {Object} context - Additional context for debugging
     * @returns {Object} Standardized rate limit error object
     */
    rateLimit(message = 'Rate limit exceeded', context = {}) { //create rate limit error with default message
        return createStandardError(
            'RATE_LIMIT_EXCEEDED', //consistent rate limit error code
            message, //rate limit violation message
            ErrorTypes.RATE_LIMIT, //rate limit error type
            context //debugging context
        );
    },

    /**
     * Creates network error for external service issues
     * 
     * @param {string} message - Network error message
     * @param {string} service - Optional name of the external service
     * @param {Object} context - Additional context for debugging
     * @returns {Object} Standardized network error object
     */
    network(message, service = null, context = {}) { //create network error with service context
        return createStandardError(
            'NETWORK_ERROR', //consistent network error code
            message, //network failure message
            ErrorTypes.NETWORK, //network error type
            { ...context, service } //include service context for debugging
        );
    },

    /**
     * Creates database error for data persistence issues
     * 
     * @param {string} message - Database error message
     * @param {string} operation - Optional database operation that failed
     * @param {Object} context - Additional context for debugging
     * @returns {Object} Standardized database error object
     */
    database(message, operation = null, context = {}) { //create database error with operation context
        return createStandardError(
            'DATABASE_ERROR', //consistent database error code
            message, //database failure message
            ErrorTypes.DATABASE, //database error type
            { ...context, operation } //include operation context for debugging
        );
    },

    /**
     * Creates system error for internal issues
     * 
     * @param {string} message - System error message
     * @param {string} component - Optional system component that failed
     * @param {Object} context - Additional context for debugging
     * @returns {Object} Standardized system error object
     */
    system(message, component = null, context = {}) { //create system error with component context
        return createStandardError(
            'SYSTEM_ERROR', //consistent system error code
            message, //system failure message
            ErrorTypes.SYSTEM, //system error type
            { ...context, component } //include component context for debugging
        );
    }
};

/**
 * Express middleware for global error handling with improved error safety
 * 
 * Design rationale: Catches any unhandled errors in the Express middleware chain
 * and ensures they are properly logged and responded to with consistent format.
 * This provides a safety net for the entire application while avoiding circular dependencies.
 * Includes meta-error handling to prevent complete system failure.
 * 
 * @param {Error} error - Error object from Express middleware chain
 * @param {Object} req - Express request object
 * @param {Object} res - Express response object
 * @param {Function} next - Express next function
 */
function errorMiddleware(error, req, res, next) { //global Express error middleware with enhanced safety
    try {
        const context = { //build request context for debugging
            req, //include request object for qerrors analysis
            url: req.url, //capture request URL
            method: req.method, //capture HTTP method
            ip: req.ip, //capture client IP for tracking
            userAgent: req.headers['user-agent'] //capture user agent for debugging
        };

        const errorType = error.type || ErrorTypes.SYSTEM; //default to system error when type missing
        const severity = ERROR_SEVERITY_MAP[errorType]; //determine severity from error type
        const statusCode = ERROR_STATUS_MAP[errorType]; //determine HTTP status from error type

        // Create standardized error response object
        const errorResponse = createStandardError(
            error.code || 'INTERNAL_ERROR', //error code for programmatic handling
            error.message || 'An internal error occurred', //error message for display
            errorType, //error classification
            context //debugging context
        );

        // Only send response if headers haven't been sent already
        // This prevents "Cannot set headers after they are sent" errors
        if (!res.headersSent) {
            sendErrorResponse(res, statusCode, errorResponse);
        }

    } catch (metaError) {
        // Handle meta-errors (errors in error handling itself)
        // This provides a fallback to prevent complete system failure
        console.error('Meta-error in errorMiddleware:', metaError.message); //log meta-error for debugging
        
        if (!res.headersSent) {
            // Send minimal error response as last resort
            try {
                res.status(500).json({ 
                    error: { 
                        code: 'SYSTEM_ERROR',
                        message: 'An internal error occurred',
                        timestamp: new Date().toISOString()
                    }
                });
            } catch (finalError) {
                // Ultimate fallback - just end the response
                console.error('Final error in errorMiddleware:', finalError.message);
                if (!res.headersSent) {
                    res.status(500).end();
                }
            }
        }
    }
}

/**
 * Simplified error handler for basic error responses
 * 
 * Design rationale: Provides a lightweight alternative to the full handleControllerError
 * for cases where simple error responses are needed without the full classification system.
 * This matches the pattern shown in legacy code while maintaining qerrors integration.
 * 
 * @param {Object} res - Express response object
 * @param {Error} error - The error object that occurred
 * @param {string} message - Human-readable error message for the client
 * @param {Object} req - Optional Express request object for additional context
 */
function handleSimpleError(res, error, message, req) { //simplified error response handler
    try {
        // Log error through qerrors with appropriate context
        const qerrors = require('./qerrors'); //load qerrors for logging
        if (req) {
            qerrors(error, message, req); //log error with full request context for better debugging
        } else {
            qerrors(error, message); //log error without request context for background operations
        }
        
        // Only send response if headers haven't been sent already
        // This prevents "Cannot set headers after they are sent" errors
        if (!res.headersSent) {
            const errorResponse = createStandardError(
                'INTERNAL_ERROR', //error code for programmatic handling
                message, //user-provided error message
                ErrorTypes.SYSTEM, //default to system error type
                {} //empty context for simple errors
            );
            sendErrorResponse(res, 500, errorResponse);
        }
    } catch (metaError) {
        // Handle meta-errors (errors in error handling itself)
        // This provides a fallback to prevent complete system failure
        console.error('Meta-error in handleSimpleError:', metaError.message); //log meta-error for debugging
        if (!res.headersSent) {
            try {
                res.status(500).json({ error: message }); //minimal fallback response
            } catch (finalError) {
                console.error('Final error in handleSimpleError:', finalError.message);
                res.status(500).end(); //ultimate fallback
            }
        }
    }
}

module.exports = { //(export error handling utilities for use across qerrors module)
    ErrorTypes, //(error classification constants)
    ErrorSeverity, //(severity level constants)
    ERROR_STATUS_MAP, //(type to HTTP status mapping)
    ERROR_SEVERITY_MAP, //(type to severity mapping)
    getRequestId, //(request ID extraction utility)
    createStandardError, //(standardized error object factory)
    sendErrorResponse, //(consistent response utility)
    createTypedError, //(typed error factory function)
    ErrorFactory, //(convenient error creation utilities)
    errorMiddleware, //(Express global error handling middleware)
    handleSimpleError //(simplified error response handler)
};
</file>

<file path="test/errorTypes.test.js">
const test = require('node:test'); //node test runner
const assert = require('node:assert/strict'); //strict assertion helpers

const errorTypes = require('../lib/errorTypes'); //error types module under test
const qtests = require('qtests'); //stubbing utilities

test('ErrorTypes constants are properly defined', () => {
  assert.equal(typeof errorTypes.ErrorTypes, 'object'); //ensure ErrorTypes exported
  assert.equal(errorTypes.ErrorTypes.VALIDATION, 'validation'); //verify validation type
  assert.equal(errorTypes.ErrorTypes.AUTHENTICATION, 'authentication'); //verify auth type
  assert.equal(errorTypes.ErrorTypes.AUTHORIZATION, 'authorization'); //verify authz type
  assert.equal(errorTypes.ErrorTypes.NOT_FOUND, 'not_found'); //verify not found type
  assert.equal(errorTypes.ErrorTypes.RATE_LIMIT, 'rate_limit'); //verify rate limit type
  assert.equal(errorTypes.ErrorTypes.NETWORK, 'network'); //verify network type
  assert.equal(errorTypes.ErrorTypes.DATABASE, 'database'); //verify database type
  assert.equal(errorTypes.ErrorTypes.SYSTEM, 'system'); //verify system type
  assert.equal(errorTypes.ErrorTypes.CONFIGURATION, 'configuration'); //verify config type
});

test('ErrorSeverity constants are properly defined', () => {
  assert.equal(typeof errorTypes.ErrorSeverity, 'object'); //ensure ErrorSeverity exported
  assert.equal(errorTypes.ErrorSeverity.LOW, 'low'); //verify low severity
  assert.equal(errorTypes.ErrorSeverity.MEDIUM, 'medium'); //verify medium severity
  assert.equal(errorTypes.ErrorSeverity.HIGH, 'high'); //verify high severity
  assert.equal(errorTypes.ErrorSeverity.CRITICAL, 'critical'); //verify critical severity
});

test('ERROR_STATUS_MAP maps types to correct HTTP status codes', () => {
  assert.equal(errorTypes.ERROR_STATUS_MAP[errorTypes.ErrorTypes.VALIDATION], 400); //validation maps to 400
  assert.equal(errorTypes.ERROR_STATUS_MAP[errorTypes.ErrorTypes.AUTHENTICATION], 401); //auth maps to 401
  assert.equal(errorTypes.ERROR_STATUS_MAP[errorTypes.ErrorTypes.AUTHORIZATION], 403); //authz maps to 403
  assert.equal(errorTypes.ERROR_STATUS_MAP[errorTypes.ErrorTypes.NOT_FOUND], 404); //not found maps to 404
  assert.equal(errorTypes.ERROR_STATUS_MAP[errorTypes.ErrorTypes.RATE_LIMIT], 429); //rate limit maps to 429
  assert.equal(errorTypes.ERROR_STATUS_MAP[errorTypes.ErrorTypes.NETWORK], 502); //network maps to 502
  assert.equal(errorTypes.ERROR_STATUS_MAP[errorTypes.ErrorTypes.DATABASE], 500); //database maps to 500
  assert.equal(errorTypes.ERROR_STATUS_MAP[errorTypes.ErrorTypes.SYSTEM], 500); //system maps to 500
  assert.equal(errorTypes.ERROR_STATUS_MAP[errorTypes.ErrorTypes.CONFIGURATION], 500); //config maps to 500
});

test('ERROR_SEVERITY_MAP maps types to correct severity levels', () => {
  assert.equal(errorTypes.ERROR_SEVERITY_MAP[errorTypes.ErrorTypes.VALIDATION], errorTypes.ErrorSeverity.LOW); //validation is low severity
  assert.equal(errorTypes.ERROR_SEVERITY_MAP[errorTypes.ErrorTypes.AUTHENTICATION], errorTypes.ErrorSeverity.LOW); //auth is low severity
  assert.equal(errorTypes.ERROR_SEVERITY_MAP[errorTypes.ErrorTypes.AUTHORIZATION], errorTypes.ErrorSeverity.MEDIUM); //authz is medium severity
  assert.equal(errorTypes.ERROR_SEVERITY_MAP[errorTypes.ErrorTypes.NOT_FOUND], errorTypes.ErrorSeverity.LOW); //not found is low severity
  assert.equal(errorTypes.ERROR_SEVERITY_MAP[errorTypes.ErrorTypes.RATE_LIMIT], errorTypes.ErrorSeverity.MEDIUM); //rate limit is medium severity
  assert.equal(errorTypes.ERROR_SEVERITY_MAP[errorTypes.ErrorTypes.NETWORK], errorTypes.ErrorSeverity.MEDIUM); //network is medium severity
  assert.equal(errorTypes.ERROR_SEVERITY_MAP[errorTypes.ErrorTypes.DATABASE], errorTypes.ErrorSeverity.HIGH); //database is high severity
  assert.equal(errorTypes.ERROR_SEVERITY_MAP[errorTypes.ErrorTypes.SYSTEM], errorTypes.ErrorSeverity.HIGH); //system is high severity
  assert.equal(errorTypes.ERROR_SEVERITY_MAP[errorTypes.ErrorTypes.CONFIGURATION], errorTypes.ErrorSeverity.CRITICAL); //config is critical severity
});

test('getRequestId extracts ID from request headers', () => {
  const req1 = { headers: { 'x-request-id': 'test-123' } }; //mock request with x-request-id
  assert.equal(errorTypes.getRequestId(req1), 'test-123'); //should extract x-request-id

  const req2 = { headers: { 'x-correlation-id': 'corr-456' } }; //mock request with x-correlation-id
  assert.equal(errorTypes.getRequestId(req2), 'corr-456'); //should extract x-correlation-id

  const req3 = { headers: { 'request-id': 'req-789' } }; //mock request with request-id
  assert.equal(errorTypes.getRequestId(req3), 'req-789'); //should extract request-id
});

test('getRequestId generates UUID when no headers available', () => {
  const req1 = { headers: {} }; //empty headers
  const id1 = errorTypes.getRequestId(req1); //get generated ID
  assert.equal(typeof id1, 'string'); //should be string
  assert.ok(id1.length > 0); //should have content

  const req2 = null; //no request object
  const id2 = errorTypes.getRequestId(req2); //get generated ID
  assert.equal(typeof id2, 'string'); //should be string
  assert.ok(id2.length > 0); //should have content

  assert.notEqual(id1, id2); //different calls should generate different IDs
});

test('createStandardError builds properly formatted error object', () => {
  const context = { userId: 123, action: 'test' }; //sample context
  const error = errorTypes.createStandardError(
    'TEST_ERROR',
    'Test error message',
    errorTypes.ErrorTypes.VALIDATION,
    context
  );

  assert.equal(error.code, 'TEST_ERROR'); //code should match
  assert.equal(error.message, 'Test error message'); //message should match
  assert.equal(error.type, errorTypes.ErrorTypes.VALIDATION); //type should match
  assert.equal(typeof error.timestamp, 'string'); //timestamp should be string
  assert.equal(typeof error.requestId, 'string'); //requestId should be string
  assert.equal(error.context.userId, 123); //context should be preserved
  assert.equal(error.context.action, 'test'); //context should be preserved
  assert.equal(error.context.req, undefined); //req should be removed
  assert.equal(error.context.res, undefined); //res should be removed
});

test('createStandardError removes req and res from context', () => {
  const mockReq = { headers: { 'x-request-id': 'test' } }; //mock request
  const mockRes = { status: () => {} }; //mock response
  const context = { req: mockReq, res: mockRes, data: 'keep' }; //context with req/res

  const error = errorTypes.createStandardError('TEST', 'message', 'validation', context);

  assert.equal(error.context.req, undefined); //req should be removed
  assert.equal(error.context.res, undefined); //res should be removed
  assert.equal(error.context.data, 'keep'); //other data should remain
});

test('sendErrorResponse sends JSON with correct status', () => {
  let capturedStatus; //capture status code
  let capturedData; //capture response data
  let statusCalled = false; //track if status was called
  let jsonCalled = false; //track if json was called

  const mockRes = { //mock response object
    headersSent: false,
    status(code) { 
      capturedStatus = code; 
      statusCalled = true;
      return this; 
    },
    json(data) { 
      capturedData = data; 
      jsonCalled = true;
      return this; 
    }
  };

  const errorObj = { code: 'TEST', message: 'test' }; //sample error object
  errorTypes.sendErrorResponse(mockRes, 400, errorObj);

  assert.ok(statusCalled); //status should be called
  assert.ok(jsonCalled); //json should be called
  assert.equal(capturedStatus, 400); //status should be 400
  assert.deepEqual(capturedData, { error: errorObj }); //response should wrap error
});

test('sendErrorResponse does not send when headers already sent', () => {
  let statusCalled = false; //track if status was called
  let jsonCalled = false; //track if json was called

  const mockRes = { //mock response with headers sent
    headersSent: true,
    status() { statusCalled = true; return this; },
    json() { jsonCalled = true; return this; }
  };

  const errorObj = { code: 'TEST', message: 'test' }; //sample error object
  errorTypes.sendErrorResponse(mockRes, 400, errorObj);

  assert.ok(!statusCalled); //status should not be called
  assert.ok(!jsonCalled); //json should not be called
});

test('createTypedError creates error with proper classification', () => {
  const error = errorTypes.createTypedError(
    'Database connection failed',
    errorTypes.ErrorTypes.DATABASE,
    'DB_CONN_ERROR',
    { host: 'localhost' }
  );

  assert.ok(error instanceof Error); //should be Error instance
  assert.equal(error.message, 'Database connection failed'); //message should match
  assert.equal(error.type, errorTypes.ErrorTypes.DATABASE); //type should match
  assert.equal(error.code, 'DB_CONN_ERROR'); //code should match
  assert.equal(error.statusCode, 500); //status should be mapped from type
  assert.equal(error.severity, errorTypes.ErrorSeverity.HIGH); //severity should be mapped from type
  assert.deepEqual(error.context, { host: 'localhost' }); //context should be preserved
});

test('createTypedError uses defaults when optional parameters omitted', () => {
  const error = errorTypes.createTypedError(
    'Simple error',
    errorTypes.ErrorTypes.VALIDATION
  );

  assert.equal(error.code, 'GENERIC_ERROR'); //should use default code
  assert.deepEqual(error.context, {}); //should use empty context
  assert.equal(error.statusCode, 400); //should map status from validation type
  assert.equal(error.severity, errorTypes.ErrorSeverity.LOW); //should map severity from validation type
});

test('ErrorFactory.validation creates properly formatted validation error', () => {
  const error = errorTypes.ErrorFactory.validation('Email is required', 'email', { userId: 123 });
  
  assert.equal(error.code, 'VALIDATION_ERROR'); //should use validation error code
  assert.equal(error.message, 'Email is required'); //should use provided message
  assert.equal(error.type, errorTypes.ErrorTypes.VALIDATION); //should be validation type
  assert.equal(error.context.field, 'email'); //should include field context
  assert.equal(error.context.userId, 123); //should preserve additional context
  assert.equal(typeof error.timestamp, 'string'); //should include timestamp
  assert.equal(typeof error.requestId, 'string'); //should include request ID
});

test('ErrorFactory.authentication creates auth error with default message', () => {
  const error = errorTypes.ErrorFactory.authentication();
  
  assert.equal(error.code, 'AUTHENTICATION_ERROR'); //should use auth error code
  assert.equal(error.message, 'Authentication required'); //should use default message
  assert.equal(error.type, errorTypes.ErrorTypes.AUTHENTICATION); //should be auth type
});

test('ErrorFactory.authentication accepts custom message and context', () => {
  const error = errorTypes.ErrorFactory.authentication('Invalid token', { token: 'abc123' });
  
  assert.equal(error.message, 'Invalid token'); //should use custom message
  assert.equal(error.context.token, 'abc123'); //should include context
});

test('ErrorFactory.authorization creates authz error with default message', () => {
  const error = errorTypes.ErrorFactory.authorization();
  
  assert.equal(error.code, 'AUTHORIZATION_ERROR'); //should use authz error code
  assert.equal(error.message, 'Insufficient permissions'); //should use default message
  assert.equal(error.type, errorTypes.ErrorTypes.AUTHORIZATION); //should be authz type
});

test('ErrorFactory.notFound creates resource-specific error', () => {
  const error = errorTypes.ErrorFactory.notFound('User', { id: 456 });
  
  assert.equal(error.code, 'NOT_FOUND'); //should use not found error code
  assert.equal(error.message, 'User not found'); //should include resource in message
  assert.equal(error.type, errorTypes.ErrorTypes.NOT_FOUND); //should be not found type
  assert.equal(error.context.id, 456); //should include context
});

test('ErrorFactory.rateLimit creates rate limit error with default message', () => {
  const error = errorTypes.ErrorFactory.rateLimit();
  
  assert.equal(error.code, 'RATE_LIMIT_EXCEEDED'); //should use rate limit error code
  assert.equal(error.message, 'Rate limit exceeded'); //should use default message
  assert.equal(error.type, errorTypes.ErrorTypes.RATE_LIMIT); //should be rate limit type
});

test('ErrorFactory.network creates network error with service context', () => {
  const error = errorTypes.ErrorFactory.network('Connection timeout', 'external-api', { timeout: 5000 });
  
  assert.equal(error.code, 'NETWORK_ERROR'); //should use network error code
  assert.equal(error.message, 'Connection timeout'); //should use provided message
  assert.equal(error.type, errorTypes.ErrorTypes.NETWORK); //should be network type
  assert.equal(error.context.service, 'external-api'); //should include service context
  assert.equal(error.context.timeout, 5000); //should preserve additional context
});

test('ErrorFactory.database creates database error with operation context', () => {
  const error = errorTypes.ErrorFactory.database('Query failed', 'SELECT', { table: 'users' });
  
  assert.equal(error.code, 'DATABASE_ERROR'); //should use database error code
  assert.equal(error.message, 'Query failed'); //should use provided message
  assert.equal(error.type, errorTypes.ErrorTypes.DATABASE); //should be database type
  assert.equal(error.context.operation, 'SELECT'); //should include operation context
  assert.equal(error.context.table, 'users'); //should preserve additional context
});

test('ErrorFactory.system creates system error with component context', () => {
  const error = errorTypes.ErrorFactory.system('Memory allocation failed', 'cache', { size: '1GB' });
  
  assert.equal(error.code, 'SYSTEM_ERROR'); //should use system error code
  assert.equal(error.message, 'Memory allocation failed'); //should use provided message
  assert.equal(error.type, errorTypes.ErrorTypes.SYSTEM); //should be system type
  assert.equal(error.context.component, 'cache'); //should include component context
  assert.equal(error.context.size, '1GB'); //should preserve additional context
});

test('errorMiddleware handles errors with proper response format', () => {
  let capturedStatus; //capture status code
  let capturedData; //capture response data
  
  const mockReq = { //mock Express request
    url: '/api/test',
    method: 'GET',
    ip: '127.0.0.1',
    headers: { 'user-agent': 'test-agent' }
  };
  
  const mockRes = { //mock Express response
    headersSent: false,
    status(code) { 
      capturedStatus = code; 
      return this; 
    },
    json(data) { 
      capturedData = data; 
      return this; 
    }
  };
  
  const testError = errorTypes.createTypedError(
    'Test error',
    errorTypes.ErrorTypes.VALIDATION,
    'TEST_ERROR'
  ); //create typed error for middleware
  
  errorTypes.errorMiddleware(testError, mockReq, mockRes, () => {});
  
  assert.equal(capturedStatus, 400); //validation error should return 400
  assert.ok(capturedData.error); //response should contain error object
  assert.equal(capturedData.error.code, 'TEST_ERROR'); //error code should match
  assert.equal(capturedData.error.message, 'Test error'); //error message should match
  assert.equal(capturedData.error.type, errorTypes.ErrorTypes.VALIDATION); //type should match
});

test('errorMiddleware defaults untyped errors to system type', () => {
  let capturedStatus; //capture status code
  let capturedData; //capture response data
  
  const mockReq = { //mock Express request
    url: '/api/test',
    method: 'GET',
    ip: '127.0.0.1',
    headers: {}
  };
  
  const mockRes = { //mock Express response
    headersSent: false,
    status(code) { 
      capturedStatus = code; 
      return this; 
    },
    json(data) { 
      capturedData = data; 
      return this; 
    }
  };
  
  const plainError = new Error('Plain error'); //untyped error
  
  errorTypes.errorMiddleware(plainError, mockReq, mockRes, () => {});
  
  assert.equal(capturedStatus, 500); //should default to 500 for system error
  assert.equal(capturedData.error.type, errorTypes.ErrorTypes.SYSTEM); //should default to system type
  assert.equal(capturedData.error.code, 'INTERNAL_ERROR'); //should use default error code
});

test('errorMiddleware handles headers already sent', () => {
  let statusCalled = false; //track if status was called
  let jsonCalled = false; //track if json was called
  
  const mockReq = { //mock Express request
    url: '/api/test',
    method: 'GET',
    ip: '127.0.0.1',
    headers: {}
  };
  
  const mockRes = { //mock Express response with headers sent
    headersSent: true,
    status() { statusCalled = true; return this; },
    json() { jsonCalled = true; return this; }
  };
  
  const testError = new Error('Test error'); //test error
  
  errorTypes.errorMiddleware(testError, mockReq, mockRes, () => {});
  
  assert.ok(!statusCalled); //status should not be called when headers sent
  assert.ok(!jsonCalled); //json should not be called when headers sent
});

test('errorMiddleware handles meta-errors gracefully', () => {
  let consoleCalled = false; //track console.error calls
  let fallbackCalled = false; //track fallback response
  
  const restoreConsole = qtests.stubMethod(console, 'error', () => { consoleCalled = true; });
  
  const mockReq = { //mock Express request
    url: '/api/test',
    method: 'GET',
    ip: '127.0.0.1',
    headers: {}
  };
  
  const mockRes = { //mock response that throws on sendErrorResponse
    headersSent: false,
    status() { return this; },
    json() { throw new Error('JSON error'); }, //throw on json to trigger meta-error handling
    end() { fallbackCalled = true; }
  };
  
  try {
    const testError = new Error('Test error'); //test error
    errorTypes.errorMiddleware(testError, mockReq, mockRes, () => {});
    
    assert.ok(consoleCalled); //console.error should be called for meta-error
    assert.ok(fallbackCalled); //fallback response should be attempted
  } finally {
    restoreConsole(); //restore console stub
  }
});

test('handleSimpleError sends basic error response', async () => {
  let capturedStatus; //capture status code
  let capturedData; //capture response data
  
  const mockRes = { //mock Express response
    headersSent: false,
    status(code) { 
      capturedStatus = code; 
      return this; 
    },
    json(data) { 
      capturedData = data; 
      return this; 
    }
  };
  
  const testError = new Error('Test error'); //test error
  const message = 'Something went wrong'; //error message
  
  // Add small delay to allow async operations to complete
  await new Promise(resolve => setTimeout(resolve, 10));
  errorTypes.handleSimpleError(mockRes, testError, message);
  await new Promise(resolve => setTimeout(resolve, 10));
  
  assert.equal(capturedStatus, 500); //should return 500 status
  assert.ok(capturedData.error); //should have error object
  assert.equal(capturedData.error.code, 'INTERNAL_ERROR'); //should use internal error code
  assert.equal(capturedData.error.message, message); //should use provided message
  assert.equal(typeof capturedData.error.timestamp, 'string'); //should include timestamp
});

test('handleSimpleError includes request context when provided', () => {
  const mockRes = { //mock Express response
    headersSent: false,
    status() { return this; },
    json() { return this; }
  };
  
  const mockReq = { //mock Express request
    url: '/api/test',
    method: 'POST'
  };
  
  const testError = new Error('Test error'); //test error
  const message = 'Request failed'; //error message
  
  // Test passes if no errors are thrown with request context
  errorTypes.handleSimpleError(mockRes, testError, message, mockReq);
  assert.ok(true); //test passes if function completes without throwing
});

test('handleSimpleError handles meta-errors gracefully', () => {
  let consoleCalled = false; //track console.error calls
  let fallbackCalled = false; //track fallback response
  
  const restoreConsole = qtests.stubMethod(console, 'error', () => { consoleCalled = true; });
  
  const mockRes = { //mock response that throws errors during error response creation
    headersSent: false,
    status() { return this; },
    json() { throw new Error('JSON error'); }, //throw on json to trigger meta-error handling
    end() { fallbackCalled = true; }
  };
  
  try {
    const testError = new Error('Test error'); //test error
    const message = 'Test message'; //error message
    
    errorTypes.handleSimpleError(mockRes, testError, message);
    
    assert.ok(consoleCalled); //console.error should be called for meta-error  
    assert.ok(fallbackCalled); //fallback response should be attempted
  } finally {
    restoreConsole(); //restore console stub
  }
});

test('handleSimpleError respects headers already sent', () => {
  let statusCalled = false; //track if status was called
  let jsonCalled = false; //track if json was called
  
  const mockRes = { //mock response with headers sent
    headersSent: true,
    status() { statusCalled = true; return this; },
    json() { jsonCalled = true; return this; }
  };
  
  const testError = new Error('Test error'); //test error
  const message = 'Test message'; //error message
  
  errorTypes.handleSimpleError(mockRes, testError, message);
  
  assert.ok(!statusCalled); //status should not be called when headers sent
  assert.ok(!jsonCalled); //json should not be called when headers sent
});
</file>

<file path="index.js">
'use strict'; //enforce strict parsing and error handling across module

/**
 * Main entry point for the qerrors package - an intelligent error handling middleware
 * that combines traditional error logging with AI-powered error analysis.
 * 
 * This module exports both the core qerrors function and the underlying logger,
 * providing flexibility for different use cases while maintaining a clean API.
 * 
 * Design rationale:
 * - Separates concerns by keeping qerrors logic and logging logic in separate modules
 * - Provides both individual exports and a default export for different import patterns
 * - Maintains backward compatibility through multiple export strategies
 * - Uses strict mode to catch common JavaScript pitfalls early
 */

const qerrors = require('./lib/qerrors'); //load primary error handler implementation
const logger = require('./lib/logger'); //load configured winston logger used by qerrors
const errorTypes = require('./lib/errorTypes'); //load error classification and handling utilities
const sanitization = require('./lib/sanitization'); //load data sanitization utilities
const queueManager = require('./lib/queueManager'); //load queue management utilities
const utils = require('./lib/utils'); //load common utility functions
const config = require('./lib/config'); //load configuration utilities
const envUtils = require('./lib/envUtils'); //load environment validation utilities

/**
 * Error logger middleware that logs errors and provides AI-powered suggestions.
 * @param {Error} error - The error object
 * @param {string} context - Context where the error occurred
 * @param {Object} [req] - Express request object (optional)
 * @param {Object} [res] - Express response object (optional)
 * @param {Function} [next] - Express next function (optional)
 * @returns {Promise<void>}
 */

module.exports = { //(primary export object allows destructuring imports like { qerrors, logger, errorTypes } providing clear explicit imports while keeping related functionality grouped)
  qerrors, //(main error handling function users interact with)
  logger, //(winston logger instance for consistent logging, exposes same configured logger qerrors uses internally)
  errorTypes, //(error classification and handling utilities for standardized error management)
  logErrorWithSeverity: qerrors.logErrorWithSeverity, //(severity-based logging function for enhanced error categorization)
  handleControllerError: qerrors.handleControllerError, //(standardized controller error handler with automatic response formatting)
  withErrorHandling: qerrors.withErrorHandling, //(async operation wrapper with integrated error handling)
  createTypedError: errorTypes.createTypedError, //(typed error factory for consistent error classification)
  createStandardError: errorTypes.createStandardError, //(standardized error object factory)
  ErrorTypes: errorTypes.ErrorTypes, //(error type constants for classification)
  ErrorSeverity: errorTypes.ErrorSeverity, //(severity level constants for monitoring)
  ErrorFactory: errorTypes.ErrorFactory, //(convenient error creation utilities for common scenarios)
  errorMiddleware: errorTypes.errorMiddleware, //(Express global error handling middleware)
  handleSimpleError: errorTypes.handleSimpleError, //(simplified error response handler for basic scenarios)

  // Enhanced logging utilities with security and performance monitoring
  logDebug: logger.logDebug, //(enhanced debug logging with sanitization)
  logInfo: logger.logInfo, //(enhanced info logging with sanitization)
  logWarn: logger.logWarn, //(enhanced warn logging with performance monitoring)
  logError: logger.logError, //(enhanced error logging with performance monitoring)
  logFatal: logger.logFatal, //(enhanced fatal logging with performance monitoring)
  logAudit: logger.logAudit, //(enhanced audit logging for compliance)
  createPerformanceTimer: logger.createPerformanceTimer, //(performance timer utility for operation monitoring)
  createEnhancedLogEntry: logger.createEnhancedLogEntry, //(enhanced log entry creator with metadata)
  LOG_LEVELS: logger.LOG_LEVELS, //(log level constants with priorities and colors)

  // Data sanitization utilities for security
  sanitizeMessage: sanitization.sanitizeMessage, //(message sanitization utility for security)
  sanitizeContext: sanitization.sanitizeContext, //(context sanitization utility for security)
  addCustomSanitizationPattern: sanitization.addCustomSanitizationPattern, //(register custom sanitization rules)
  clearCustomSanitizationPatterns: sanitization.clearCustomSanitizationPatterns, //(clear custom patterns for testing)
  sanitizeWithCustomPatterns: sanitization.sanitizeWithCustomPatterns, //(enhanced sanitization with custom rules)

  // Queue management and monitoring utilities
  createLimiter: queueManager.createLimiter, //(concurrency limiting utility)
  getQueueLength: queueManager.getQueueLength, //(queue depth monitoring)
  getQueueRejectCount: queueManager.getQueueRejectCount, //(reject count monitoring)
  startQueueMetrics: queueManager.startQueueMetrics, //(start periodic metrics)
  stopQueueMetrics: queueManager.stopQueueMetrics, //(stop periodic metrics)

  // Common utility functions
  generateUniqueId: utils.generateUniqueId, //(unique identifier generation)
  createTimer: utils.createTimer, //(performance timing utilities)
  deepClone: utils.deepClone, //(deep object cloning)
  safeRun: utils.safeRun, //(safe function execution wrapper)
  verboseLog: utils.verboseLog, //(conditional verbose logging)

  // Configuration and environment utilities
  getEnv: config.getEnv, //(environment variable getter with defaults)
  getInt: config.getInt, //(integer parsing with validation)
  getMissingEnvVars: envUtils.getMissingEnvVars, //(environment validation)
  throwIfMissingEnvVars: envUtils.throwIfMissingEnvVars, //(required environment validation)
  warnIfMissingEnvVars: envUtils.warnIfMissingEnvVars //(optional environment validation)
};

module.exports.default = qerrors; //(default export for backward compatibility allowing both 'const qerrors = require("qerrors")' and destructuring patterns, dual strategy accommodates different developer preferences)
</file>

<file path="test/logger.test.js">
const test = require('node:test'); //node test runner
const assert = require('node:assert/strict'); //strict assertion helpers

const logger = require('../lib/logger'); //logger promise under test
const qtests = require('qtests'); //stubbing utilities
const winston = require('winston'); //winston stub to intercept config
const DailyRotateFile = require('winston-daily-rotate-file'); //daily rotate stub
const fs = require('fs'); //filesystem for stubbing mkdir behaviour

function reloadLogger() { //reload logger with current env
  delete require.cache[require.resolve('../lib/logger')];
  delete require.cache[require.resolve('../lib/config')];
  // Clear winston-daily-rotate-file from cache to get fresh stub instance
  const stubPath = require.resolve('winston-daily-rotate-file');
  delete require.cache[stubPath];
  return require('../lib/logger');
}

// Scenario: verify logger exposes basic Winston-style methods
test('logger exposes standard logging methods', async () => {
  const log = await logger; //wait for initialization
  assert.equal(typeof log.error, 'function'); //error method present
  assert.equal(typeof log.warn, 'function'); //warn method present
  assert.equal(typeof log.info, 'function'); //info method present
});

test('logger uses daily rotate when QERRORS_LOG_MAX_DAYS set', async () => {
  const orig = process.env.QERRORS_LOG_MAX_DAYS; //store original days
  const origDisable = process.env.QERRORS_DISABLE_FILE_LOGS; //store original disable flag
  process.env.QERRORS_LOG_MAX_DAYS = '2'; //enable two day rotation
  delete process.env.QERRORS_DISABLE_FILE_LOGS; //ensure file logs are enabled
  let captured; //will capture config passed to createLogger
  
  const restore = qtests.stubMethod(winston, 'createLogger', (cfg) => { 
    captured = cfg; 
    return { transports: cfg.transports, warn() {}, info() {}, error() {} }; 
  }); //include warn for startup check
  const log = await reloadLogger();
  await log; //ensure init completed
  try {
    // Verify that 2 transports are created and they are DailyRotateFile instances
    assert.equal(captured.transports.length, 2); //two transports created
    assert.equal(captured.transports[0].constructor.name, 'DailyRotateFile'); //first is daily rotate
    assert.equal(captured.transports[1].constructor.name, 'DailyRotateFile'); //second is daily rotate
    // Verify the maxFiles configuration matches expected pattern for daily retention
    assert.equal(captured.transports[0].options.maxFiles, '2d'); //retention uses env days
  } finally {
    restore();
    if (orig === undefined) { delete process.env.QERRORS_LOG_MAX_DAYS; } else { process.env.QERRORS_LOG_MAX_DAYS = orig; }
    if (origDisable === undefined) { delete process.env.QERRORS_DISABLE_FILE_LOGS; } else { process.env.QERRORS_DISABLE_FILE_LOGS = origDisable; }
    reloadLogger(); //reset logger cache
  }
});

test('file transports active when mkdirSync succeeds', async () => {
  const origDisable = process.env.QERRORS_DISABLE_FILE_LOGS; //save flag state
  delete process.env.QERRORS_DISABLE_FILE_LOGS; //ensure files allowed
  let captured; //capture logger config
  const restoreLogger = qtests.stubMethod(winston, 'createLogger', cfg => { captured = cfg; return { transports: cfg.transports, warn() {}, info() {}, error() {} }; }); //capture transports
  let callCount = 0; //track mkdir calls
  const restoreMkdir = qtests.stubMethod(fs.promises, 'mkdir', async () => { callCount++; }); //stub async mkdir
  const log = await reloadLogger();
  await log;
  try {
    assert.ok(callCount > 0); //directory attempted
    assert.ok((await log).transports.length >= 2); //file transports configured
    assert.ok(captured.transports.length >= 2); //logger received file transports
  } finally {
    restoreLogger();
    restoreMkdir();
    if (origDisable === undefined) { delete process.env.QERRORS_DISABLE_FILE_LOGS; } else { process.env.QERRORS_DISABLE_FILE_LOGS = origDisable; }
    reloadLogger(); //reset logger
  }
});

test('logger continues with console transport when mkdirSync fails', async () => {
  const origVerbose = process.env.QERRORS_VERBOSE; //save current verbose
  process.env.QERRORS_VERBOSE = 'true'; //ensure console transport
  let captured; //capture logger config
  const restoreLogger = qtests.stubMethod(winston, 'createLogger', (cfg) => { captured = cfg; return { transports: cfg.transports, warn() {}, info() {}, error() {} }; }); //include warn for startup check
  const restoreMkdir = qtests.stubMethod(fs.promises, 'mkdir', async () => { throw new Error('fail'); }); //simulate failure with async mkdir
  let errMsg; //capture console error message
  const restoreErr = qtests.stubMethod(console, 'error', (msg) => { errMsg = msg; });
  const log = await reloadLogger();
  await log;
  try {
    assert.ok((await log).transports.length > 0); //logger returned usable instance
    assert.ok(captured.transports.length >= 1); //console transport configured even if files remain
    assert.ok(errMsg.includes('Failed to create log directory')); //error logged
  } finally {
    restoreLogger();
    restoreMkdir();
    restoreErr();
    if (origVerbose === undefined) { delete process.env.QERRORS_VERBOSE; } else { process.env.QERRORS_VERBOSE = origVerbose; }
  reloadLogger(); //reset cached module
  }
});

test('file logs stay disabled after mkdir failure when env unset', async () => {
  const origVerbose = process.env.QERRORS_VERBOSE; //preserve verbose setting
  const origDisable = process.env.QERRORS_DISABLE_FILE_LOGS; //preserve disable flag
  process.env.QERRORS_VERBOSE = 'true'; //enable console transport for test
  delete process.env.QERRORS_DISABLE_FILE_LOGS; //simulate no disable env var
  let captured; //capture logger configuration
  const restoreLogger = qtests.stubMethod(winston, 'createLogger', cfg => { captured = cfg; return { transports: cfg.transports, warn() {}, info() {}, error() {} }; }); //capture transports
  const restoreMkdir = qtests.stubMethod(fs.promises, 'mkdir', async () => { throw new Error('fail'); }); //simulate mkdir failure
  const restoreErr = qtests.stubMethod(console, 'error', () => {}); //suppress console error output during test
  const log = await reloadLogger();
  await log;
  try {
    assert.equal(captured.transports.length, 1); //only console transport should be active
    assert.ok(captured.transports[0] instanceof winston.transports.Console); //verify transport is console
  } finally {
    restoreLogger();
    restoreMkdir();
    restoreErr();
    if (origVerbose === undefined) { delete process.env.QERRORS_VERBOSE; } else { process.env.QERRORS_VERBOSE = origVerbose; }
    if (origDisable === undefined) { delete process.env.QERRORS_DISABLE_FILE_LOGS; } else { process.env.QERRORS_DISABLE_FILE_LOGS = origDisable; }
    reloadLogger(); //reset cached module
  }
});

test('logger warns when max days zero with file logs', async () => {
  const origDays = process.env.QERRORS_LOG_MAX_DAYS; //save env day setting
  const origDisable = process.env.QERRORS_DISABLE_FILE_LOGS; //save disable flag
  process.env.QERRORS_LOG_MAX_DAYS = '0'; //explicit zero days
  delete process.env.QERRORS_DISABLE_FILE_LOGS; //ensure file logs active
  let warned = false; //track warn call
  const restore = qtests.stubMethod(winston, 'createLogger', cfg => { return { transports: cfg.transports, warn: () => { warned = true; }, info() {}, error() {} }; }); //provide stub logger
  await reloadLogger(); //load module which should warn
  try {
    assert.equal(warned, true); //expect warning
  } finally {
    restore();
    if (origDays === undefined) { delete process.env.QERRORS_LOG_MAX_DAYS; } else { process.env.QERRORS_LOG_MAX_DAYS = origDays; }
    if (origDisable === undefined) { delete process.env.QERRORS_DISABLE_FILE_LOGS; } else { process.env.QERRORS_DISABLE_FILE_LOGS = origDisable; }
    reloadLogger(); //reset logger
  }
});

test('logger defaults to console when mkdir fails and verbose unset', async () => {
  const origVerbose = process.env.QERRORS_VERBOSE; //preserve verbose state
  const origDisable = process.env.QERRORS_DISABLE_FILE_LOGS; //preserve disable state
  delete process.env.QERRORS_VERBOSE; //unset verbose so fallback logic triggers
  delete process.env.QERRORS_DISABLE_FILE_LOGS; //allow file logs so mkdir will attempt
  let captured; //capture logger configuration
  const restoreLogger = qtests.stubMethod(winston, 'createLogger', cfg => { captured = cfg; return { transports: cfg.transports, warn() {}, info() {}, error() {} }; }); //intercept createLogger
  const restoreMkdir = qtests.stubMethod(fs.promises, 'mkdir', async () => { throw new Error('fail'); }); //force init failure
  const restoreErr = qtests.stubMethod(console, 'error', () => {}); //suppress console error
  const logPromise = await reloadLogger();
  await logPromise;
  try {
    const hasConsole = captured.transports.some(t => t instanceof winston.transports.Console); //look for console transport
    assert.equal(hasConsole, true); //expect console added
    assert.ok((await logPromise).transports.length >= 1); //logger exposes transport
  } finally {
    restoreLogger();
    restoreMkdir();
    restoreErr();
    if (origVerbose === undefined) { delete process.env.QERRORS_VERBOSE; } else { process.env.QERRORS_VERBOSE = origVerbose; }
    if (origDisable === undefined) { delete process.env.QERRORS_DISABLE_FILE_LOGS; } else { process.env.QERRORS_DISABLE_FILE_LOGS = origDisable; }
    reloadLogger(); //reset logger cache
  }
});
</file>

<file path="lib/config.js">
'use strict'; //(enable strict mode for defaults module)

/**
 * Configuration defaults for qerrors module
 * 
 * These defaults represent carefully balanced values for production use. Each setting
 * has been chosen based on practical testing and common deployment scenarios.
 * 
 * Design rationale:
 * - Conservative defaults prevent resource exhaustion while allowing customization
 * - String values maintain consistency with environment variable parsing
 * - Values scale appropriately for both development and production environments
 * - OpenAI integration defaults balance API cost with functionality
 */

const defaults = { //default environment variable values for all qerrors configuration options
  QERRORS_CONCURRENCY: '5', //max concurrent analyses
  QERRORS_CACHE_LIMIT: '50', //LRU cache size
  QERRORS_CACHE_TTL: '86400', //seconds each cache entry remains valid //(new default ttl)
  QERRORS_QUEUE_LIMIT: '100', //max waiting analyses before rejecting //(new env default)
  QERRORS_SAFE_THRESHOLD: '1000', //upper limit for concurrency and queue //(new config default)

  QERRORS_RETRY_ATTEMPTS: '2', //number of API retries //(renamed env var and updated default)
  QERRORS_RETRY_BASE_MS: '100', //base delay for retries //(renamed env var and updated default)
  QERRORS_RETRY_MAX_MS: '2000', //cap wait time for exponential backoff //(new env default)
  QERRORS_TIMEOUT: '10000', //axios request timeout in ms
  QERRORS_MAX_SOCKETS: '50', //max sockets per http/https agent
  QERRORS_MAX_FREE_SOCKETS: '256', //max idle sockets per agent //(new env default)
  QERRORS_MAX_TOKENS: '2048', //max tokens for openai responses //(new env default)
  QERRORS_OPENAI_URL: 'https://api.openai.com/v1/chat/completions', //endpoint used for analysis //(new openai url default)

  QERRORS_LOG_MAXSIZE: String(1024 * 1024), //log file size in bytes
  QERRORS_LOG_MAXFILES: '5', //number of rotated log files
  QERRORS_LOG_MAX_DAYS: '0', //days to retain rotated logs //(0 disables time rotation)
  QERRORS_VERBOSE: 'false', //default off so unset env won't spam console
  QERRORS_LOG_DIR: 'logs', //directory for rotated logs
  QERRORS_DISABLE_FILE_LOGS: '', //flag to disable file transports when set
  QERRORS_SERVICE_NAME: 'qerrors', //service identifier for logger //(new default)

  QERRORS_LOG_LEVEL: 'info', //logger output severity default

  QERRORS_METRIC_INTERVAL_MS: '30000' //interval for queue metrics in ms //(new default)

};



module.exports = defaults; //export defaults for external use

function getEnv(name) { //return env var or default when undefined
  return process.env[name] !== undefined ? process.env[name] : defaults[name];
}

module.exports.getEnv = getEnv; //expose getEnv helper

function safeRun(name, fn, fallback, info) { //utility wrapper for try/catch //(added helper)
  try { return fn(); } catch (err) { console.error(`${name} failed`, info); return fallback; } //(log and fall back)
}

module.exports.safeRun = safeRun; //export safeRun for env utils //(make accessible)

function getInt(name, min = 1) { //parse env integer with minimum enforcement
  const int = parseInt(getEnv(name), 10); //attempt parse
  const defaultVal = typeof defaults[name] === 'number' ? defaults[name] : parseInt(defaults[name], 10); //(handle numeric defaults safely)
  const val = Number.isNaN(int) ? defaultVal : int; //default when NaN
  return val >= min ? val : min; //enforce allowed minimum
}

module.exports.getInt = getInt; //export helper for qerrors usage //(central helper)
</file>

<file path="lib/logger.js">
/**
 * Enhanced Winston logger configuration for qerrors module
 * 
 * This module provides a comprehensive logging infrastructure that supports structured
 * logging, multiple log levels, performance monitoring, security-aware sanitization,
 * and production-ready log management. It extends Winston with enhanced features
 * designed for error handling applications that require detailed audit trails.
 * 
 * Enhanced features:
 * - Security-aware message sanitization to prevent logging sensitive data
 * - Request correlation IDs for tracking user journeys across services
 * - Performance monitoring with memory usage tracking
 * - Structured JSON logging with consistent metadata
 * - Environment-specific configuration for development vs production
 * - Multi-transport approach ensures logs are captured in multiple formats/locations
 * - Custom printf format balances readability with structured data
 * - Stack trace inclusion aids debugging complex error scenarios
 */

const { createLogger, format, transports } = require('winston'); //import winston logging primitives
const path = require('path'); //path for building log file paths
const fs = require('fs'); //filesystem for logDir creation
const config = require('./config'); //load configuration for env defaults
const { sanitizeMessage, sanitizeContext } = require('./sanitization'); //import sanitization utilities
// DailyRotateFile loaded dynamically in buildLogger to ensure stub system works in tests

/**
 * Log Levels Configuration with Enhanced Metadata
 * 
 * Purpose: Defines hierarchical log levels for filtering and routing messages
 * Each level has a numeric priority for comparison and filtering operations.
 * Higher numbers indicate higher priority/severity levels.
 * 
 * Level usage guidelines:
 * - DEBUG: Detailed debugging information for development
 * - INFO: General operational messages about system behavior
 * - WARN: Warning conditions that should be noted but don't stop operation
 * - ERROR: Error conditions that require attention
 * - FATAL: Critical errors that may cause system shutdown
 * - AUDIT: Security and compliance-related events requiring permanent retention
 */
const LOG_LEVELS = {
  DEBUG: { priority: 10, color: '\x1b[36m', name: 'DEBUG' }, // Cyan
  INFO:  { priority: 20, color: '\x1b[32m', name: 'INFO' },  // Green
  WARN:  { priority: 30, color: '\x1b[33m', name: 'WARN' },  // Yellow
  ERROR: { priority: 40, color: '\x1b[31m', name: 'ERROR' }, // Red
  FATAL: { priority: 50, color: '\x1b[35m', name: 'FATAL' }, // Magenta
  AUDIT: { priority: 60, color: '\x1b[34m', name: 'AUDIT' }  // Blue
};

const rotationOpts = { maxsize: Number(process.env.QERRORS_LOG_MAXSIZE) || 1024 * 1024, maxFiles: Number(process.env.QERRORS_LOG_MAXFILES) || 5, tailable: true }; //(use env config when rotating logs)
// maxDays is calculated dynamically in buildLogger to respect environment changes
const logDir = process.env.QERRORS_LOG_DIR || 'logs'; //directory to store log files
let disableFileLogs = !!process.env.QERRORS_DISABLE_FILE_LOGS; //track file log state //(respect env flag)



/**
 * Enhanced Log Entry Creation with Performance Monitoring
 * 
 * Purpose: Creates consistent, enriched log entries with comprehensive metadata
 * Includes request correlation, performance metrics, and environment context.
 */
function createEnhancedLogEntry(level, message, context = {}, requestId = null) { //create structured log entry with enhanced metadata
    const levelConfig = LOG_LEVELS[level.toUpperCase()] || LOG_LEVELS.INFO;
    
    const entry = {
        timestamp: new Date().toISOString(),
        level: levelConfig.name,
        message: sanitizeMessage(message, levelConfig.name),
        service: config.getEnv('QERRORS_SERVICE_NAME'), //use existing qerrors service name configuration
        version: process.env.npm_package_version || '1.0.0', //application version for debugging
        environment: process.env.NODE_ENV || 'development',
        pid: process.pid, //process ID for multi-instance debugging
        hostname: require('os').hostname() //hostname for distributed system tracking
    };

    // Add request correlation ID if available
    if (requestId) {
        entry.requestId = requestId;
    }

    // Add sanitized context data if provided
    if (context && Object.keys(context).length > 0) {
        entry.context = sanitizeContext(context, levelConfig.name);
    }

    // Add memory usage for performance monitoring on higher severity levels
    if (levelConfig.priority >= LOG_LEVELS.WARN.priority) {
        const memUsage = process.memoryUsage();
        entry.memory = {
            heapUsed: Math.round(memUsage.heapUsed / 1024 / 1024), //heap memory in MB
            heapTotal: Math.round(memUsage.heapTotal / 1024 / 1024), //total heap in MB
            external: Math.round(memUsage.external / 1024 / 1024), //external memory in MB
            rss: Math.round(memUsage.rss / 1024 / 1024) //resident set size in MB
        };
    }

    return entry;
}

const fileFormat = format.combine( //formatter for JSON file logs with timestamp and stack
        format.timestamp({ format: 'YYYY-MM-DD HH:mm:ss' }), //timestamp for chronological sorting
        format.errors({ stack: true }), //include stack traces in log object
        format.splat(), //enable printf style interpolation
        format.json() //output structured JSON for log processors
); //makes structured logs easy to parse

const consoleFormat = format.combine( //formatter for readable console output
        format.timestamp({ format: 'YYYY-MM-DD HH:mm:ss' }), //timestamp for readability
        format.errors({ stack: true }), //include stack
        format.splat(), //support sprintf like syntax
        format.printf(({ timestamp, level, message, stack }) => `${timestamp} ${level}: ${message}${stack ? '\n' + stack : ''}`) //custom printable string
); //keeps console output compact and readable
/**
 * Asynchronously initializes the logging directory structure
 * 
 * This function handles the complexity of directory creation in both development
 * and production environments. It uses async operations to avoid blocking the
 * main thread during filesystem operations.
 * 
 * Design rationale:
 * - Async/await prevents blocking during directory creation
 * - Recursive creation handles nested directory paths
 * - Error handling allows graceful degradation when filesystem access fails
 * - Separate function enables testing and reusability
 */
async function initLogDir() { //prepare log directory asynchronously ensuring proper filesystem structure
        try { await fs.promises.mkdir(logDir, { recursive: true }); } //(create directory asynchronously with recursive option for nested paths)
        catch (err) { console.error(`Failed to create log directory ${logDir}: ${err.message}`); disableFileLogs = true; } //(record failure and disable file logging to prevent repeated errors)
}



/**
 * Winston logger instance with multi-format, multi-transport configuration
 *
 * Transport strategy:
 * 1. Error-only file for focused error analysis and alerting
 * 2. Combined file for comprehensive audit trail and debugging
 * 3. Console for immediate development feedback and debugging
 *
 * Format strategy uses dedicated configurations:
 * - File transports log JSON for ingestion by aggregation tools
 * - Console transport uses printf for readable development output
 * - Each includes timestamp, stack traces and splat interpolation
 */
async function buildLogger() { //(create logger after directory preparation complete)
        await initLogDir(); //(ensure directory exists before configuring file transports)
        const maxDays = Number(process.env.QERRORS_LOG_MAX_DAYS) || 0; //days to retain logs //(calculate dynamically to respect env changes)
        disableFileLogs = disableFileLogs || !!process.env.QERRORS_DISABLE_FILE_LOGS; //(preserve directory failure flag while applying env override)
        const DailyRotateFile = require('winston-daily-rotate-file'); //(load dynamically to ensure test stubs work)
       const log = createLogger({ //(build configured winston logger instance with multi-transport setup)
        level: config.getEnv('QERRORS_LOG_LEVEL'), //(log level from env variable defaulting to 'info' for errors, warnings, and info messages)
        defaultMeta: { service: config.getEnv('QERRORS_SERVICE_NAME') }, //(default metadata added to all log entries, service identification helps in multi-service environments)
        transports: (() => { //(multi-transport configuration for comprehensive log coverage)
               const arr = []; //(start with empty transport array)
               if (!disableFileLogs) { //(add file transports when directory creation successful)
                        if (maxDays > 0) { //(use daily rotation when retention period configured)
                                arr.push(new DailyRotateFile({ filename: path.join(logDir, 'error-%DATE%.log'), level: 'error', datePattern: 'YYYY-MM-DD', maxFiles: `${maxDays}d`, maxSize: rotationOpts.maxsize, format: fileFormat })); //(error-only file with daily rotation for focused error analysis)
                                arr.push(new DailyRotateFile({ filename: path.join(logDir, 'combined-%DATE%.log'), datePattern: 'YYYY-MM-DD', maxFiles: `${maxDays}d`, maxSize: rotationOpts.maxsize, format: fileFormat })); //(combined log file with daily rotation for comprehensive audit trail)
                        } else {
                                const fileCap = rotationOpts.maxFiles > 0 ? rotationOpts.maxFiles : 30; //(fallback file count cap when time rotation disabled)
                                arr.push(new transports.File({ filename: path.join(logDir, 'error.log'), level: 'error', ...rotationOpts, maxFiles: fileCap, format: fileFormat })); //(size-based rotation for error files with count limit)
                                arr.push(new transports.File({ filename: path.join(logDir, 'combined.log'), ...rotationOpts, maxFiles: fileCap, format: fileFormat })); //(size-based rotation for combined files with count limit)
                        }
               }
               if (process.env.QERRORS_VERBOSE === 'true') { arr.push(new transports.Console({ format: consoleFormat })); } //(console transport only when verbose mode enabled)
               if (arr.length === 0) { arr.push(new transports.Console({ format: consoleFormat })); } //fallback console transport ensures logger always has output
               return arr; //(return configured transport array)
        })()
       });
       if (process.env.QERRORS_VERBOSE === 'true') { log.warn('QERRORS_VERBOSE=true can impact performance at scale'); } //warn when verbose may slow logging
       if (maxDays === 0 && !disableFileLogs) { log.warn('QERRORS_LOG_MAX_DAYS is 0; log files may grow without bound'); } //(warn about unlimited log retention)
       return log; //(return fully configured logger instance)
}

const logger = buildLogger(); //(create promise-based logger instance when module imported)

async function logStart(name, data) { const log = await logger; log.info(`${name} start ${JSON.stringify(data)}`); } //(log function start with data, uses promise to ensure logger ready)
async function logReturn(name, data) { const log = await logger; log.info(`${name} return ${JSON.stringify(data)}`); } //(log function return with result data, uses promise to invoke logger safely)

/**
 * Enhanced Logging Functions with Security and Performance Monitoring
 * 
 * These functions provide enhanced logging capabilities with built-in sanitization,
 * request correlation, and performance monitoring while maintaining backward
 * compatibility with the existing Winston logger.
 */

/**
 * Enhanced debug logging with sanitization and context
 * 
 * @param {string} message - Log message
 * @param {Object} context - Additional context data
 * @param {string} requestId - Optional request correlation ID
 */
async function logDebug(message, context = {}, requestId = null) { //enhanced debug logging with sanitization
    const log = await logger;
    const entry = createEnhancedLogEntry('DEBUG', message, context, requestId);
    log.debug(entry);
}

/**
 * Enhanced info logging with sanitization and context
 * 
 * @param {string} message - Log message
 * @param {Object} context - Additional context data
 * @param {string} requestId - Optional request correlation ID
 */
async function logInfo(message, context = {}, requestId = null) { //enhanced info logging with sanitization
    const log = await logger;
    const entry = createEnhancedLogEntry('INFO', message, context, requestId);
    log.info(entry);
}

/**
 * Enhanced warning logging with sanitization and performance monitoring
 * 
 * @param {string} message - Log message
 * @param {Object} context - Additional context data
 * @param {string} requestId - Optional request correlation ID
 */
async function logWarn(message, context = {}, requestId = null) { //enhanced warn logging with performance monitoring
    const log = await logger;
    const entry = createEnhancedLogEntry('WARN', message, context, requestId);
    log.warn(entry);
}

/**
 * Enhanced error logging with sanitization and performance monitoring
 * 
 * @param {string} message - Log message
 * @param {Object} context - Additional context data
 * @param {string} requestId - Optional request correlation ID
 */
async function logError(message, context = {}, requestId = null) { //enhanced error logging with performance monitoring
    const log = await logger;
    const entry = createEnhancedLogEntry('ERROR', message, context, requestId);
    log.error(entry);
}

/**
 * Enhanced fatal logging with sanitization and performance monitoring
 * 
 * @param {string} message - Log message
 * @param {Object} context - Additional context data
 * @param {string} requestId - Optional request correlation ID
 */
async function logFatal(message, context = {}, requestId = null) { //enhanced fatal logging with performance monitoring
    const log = await logger;
    const entry = createEnhancedLogEntry('FATAL', message, context, requestId);
    log.error(entry); //winston doesn't have fatal level, use error with enhanced metadata
}

/**
 * Enhanced audit logging for compliance and security events
 * 
 * @param {string} message - Audit message
 * @param {Object} context - Additional context data
 * @param {string} requestId - Optional request correlation ID
 */
async function logAudit(message, context = {}, requestId = null) { //enhanced audit logging for compliance
    const log = await logger;
    const entry = createEnhancedLogEntry('AUDIT', message, context, requestId);
    log.info(entry); //use info level for audit logs with enhanced metadata
}

/**
 * Performance Timer Utility
 * 
 * Purpose: Provides easy performance monitoring for operations
 * Returns a function that can be called to log the elapsed time.
 */
function createPerformanceTimer(operation, requestId = null) { //create performance timer for operation monitoring
    const startTime = process.hrtime.bigint();
    const startMemory = process.memoryUsage();
    
    return async function logPerformance(success = true, additionalContext = {}) {
        const endTime = process.hrtime.bigint();
        const endMemory = process.memoryUsage();
        const duration = Number(endTime - startTime) / 1000000; //convert to milliseconds
        
        const context = {
            operation,
            duration_ms: Math.round(duration * 100) / 100, //round to 2 decimal places
            memory_delta: {
                heapUsed: Math.round((endMemory.heapUsed - startMemory.heapUsed) / 1024), //KB change
                external: Math.round((endMemory.external - startMemory.external) / 1024) //KB change
            },
            success,
            ...additionalContext
        };
        
        const message = `${operation} completed in ${context.duration_ms}ms (${success ? 'success' : 'failure'})`;
        
        if (success) {
            await logInfo(message, context, requestId);
        } else {
            await logWarn(message, context, requestId);
        }
        
        return context; //return performance data for further processing
    };
}

module.exports = logger; //(export promise that resolves to winston logger instance for async initialization)
module.exports.logStart = logStart; //(export start logging helper for function entry tracking)
module.exports.logReturn = logReturn; //(export return logging helper for function exit tracking)

// Enhanced logging functions with security and performance monitoring
module.exports.logDebug = logDebug; //(export enhanced debug logging)
module.exports.logInfo = logInfo; //(export enhanced info logging)
module.exports.logWarn = logWarn; //(export enhanced warn logging)
module.exports.logError = logError; //(export enhanced error logging)
module.exports.logFatal = logFatal; //(export enhanced fatal logging)
module.exports.logAudit = logAudit; //(export enhanced audit logging)

// Utility functions for enhanced logging capabilities
module.exports.createPerformanceTimer = createPerformanceTimer; //(export performance timer utility)
module.exports.sanitizeMessage = sanitizeMessage; //(export message sanitization utility)
module.exports.sanitizeContext = sanitizeContext; //(export context sanitization utility)
module.exports.createEnhancedLogEntry = createEnhancedLogEntry; //(export enhanced log entry creator)
module.exports.LOG_LEVELS = LOG_LEVELS; //(export log level constants)
</file>

<file path="lib/qerrors.js">
/**
 * Core qerrors module - provides intelligent error analysis using OpenAI's API
 * 
 * This module implements a sophisticated error handling system that not only logs errors
 * but also provides AI-powered analysis and suggestions for resolution. The design balances
 * practical error handling needs with advanced AI capabilities.
 * 
 * Key design decisions:
 * - Uses OpenAI GPT models for error analysis to provide contextual debugging help
 * - Implements graceful degradation when AI services are unavailable
 * - Generates unique error identifiers for tracking and correlation
 * - Supports both Express middleware usage and standalone error handling
 */


'use strict'; //(enable strict mode for improved error detection)
const config = require('./config'); //load default environment variables and helpers
const errorTypes = require('./errorTypes'); //error classification and handling utilities

const logger = require('./logger'); //centralized winston logger configuration promise
const axios = require('axios'); //HTTP client used for OpenAI API calls
const http = require('http'); //node http for agent keep alive
const https = require('https'); //node https for agent keep alive
const crypto = require('crypto'); //node crypto for hashing cache keys
const { randomUUID } = require('crypto'); //import UUID generator for unique names
const Denque = require('denque'); //double ended queue for O(1) dequeue
const escapeHtml = require('escape-html'); //secure HTML escaping library
const util = require('util'); //node util to stringify circular context safely
/**
 * Creates a custom concurrency limiter for controlling OpenAI API calls
 * 
 * This implementation replaces the p-limit npm package to reduce dependencies
 * while providing exactly the functionality needed for qerrors. The design
 * prioritizes simplicity and reliability over feature completeness.
 * 
 * Design rationale:
 * - Custom implementation reduces npm dependency footprint
 * - Simple queue structure using Denque provides O(1) operations
 * - Direct control over queuing logic enables specific behavior needed for error analysis
 * - Exposed metrics allow monitoring of queue health in production
 * 
 * @param {number} max - Maximum number of concurrent operations
 * @returns {Function} Limiter function that accepts async operations
 */
function createLimiter(max) { //(local concurrency limiter to avoid p-limit dependency while providing identical functionality)
        let active = 0; //count currently running tasks
        const queue = new Denque(); //queued functions waiting for a slot with O(1) shift
        const next = () => { //execute next when possible
                if (active >= max || queue.length === 0) return; //respect limit
                const { fn, resolve, reject } = queue.shift(); //get next job
                active++; //increase active before run
                Promise.resolve().then(fn).then(val => { //run job then resolve
                        active--; //decrement active after success
                        resolve(val); //pass value
                        next(); //run following job
                }).catch(err => { //handle rejection
                        active--; //decrement active on failure
                        reject(err); //propagate error
                        next(); //continue queue
                });
        };
        const limiter = fn => new Promise((resolve, reject) => { //limiter wrapper
                queue.push({ fn, resolve, reject }); //add to queue
                next(); //attempt run
        });
        Object.defineProperties(limiter, { //expose counters like p-limit
                activeCount: { get: () => active },
                pendingCount: { get: () => queue.length }
        });
        return limiter; //return throttle function
}
const { LRUCache } = require('lru-cache'); //LRU cache class used for caching advice


/**
 * Conditional logging utility for debugging and development feedback
 * 
 * This function provides optional verbose output that can be enabled via environment
 * variable. It's designed to help developers understand qerrors behavior without
 * impacting production performance when disabled.
 * 
 * Design rationale:
 * - Environment-controlled logging prevents performance impact in production
 * - Direct console.log usage avoids logger dependency cycles
 * - Simple boolean check minimizes overhead when disabled
 * - Centralized control allows easy debugging toggle across entire module
 */
function verboseLog(msg) { //conditional console output helper for debugging without logger dependency
        if (config.getEnv('QERRORS_VERBOSE') === 'true') console.log(msg); //only log when enabled to avoid production noise
}

function stringifyContext(ctx) { //safely stringify context without errors
        console.log(`stringifyContext is running with ${typeof ctx}`); //trace helper entry
        try { const out = typeof ctx === 'string' ? ctx : JSON.stringify(ctx); console.log(`stringifyContext is returning ${out}`); return out; } catch { const out = util.inspect(ctx, { depth: 5 }); console.log(`stringifyContext is returning ${out}`); return out; } //fallback to util.inspect on circular data
}

const rawConc = config.getInt('QERRORS_CONCURRENCY'); //(raw concurrency from env)
const rawQueue = config.getInt('QERRORS_QUEUE_LIMIT'); //(raw queue limit from env)

const SAFE_THRESHOLD = config.getInt('QERRORS_SAFE_THRESHOLD'); //limit considered safe for concurrency and queue without enforced minimum //(configurable)
const CONCURRENCY_LIMIT = Math.min(rawConc, SAFE_THRESHOLD); //(clamp concurrency to safe threshold)
const QUEUE_LIMIT = Math.min(rawQueue, SAFE_THRESHOLD); //(clamp queue limit to safe threshold)
if (rawConc > SAFE_THRESHOLD || rawQueue > SAFE_THRESHOLD) { logger.then(l => l.warn(`High qerrors limits clamped conc ${rawConc} queue ${rawQueue}`)); } //(warn when original limits exceed threshold)

const rawSockets = config.getInt('QERRORS_MAX_SOCKETS'); //raw sockets from env
const MAX_SOCKETS = Math.min(rawSockets, SAFE_THRESHOLD); //clamp sockets to safe threshold
if (rawSockets > SAFE_THRESHOLD) { logger.then(l => l.warn(`max sockets clamped ${rawSockets}`)); } //warn on clamp when limit exceeded

const rawFreeSockets = config.getInt('QERRORS_MAX_FREE_SOCKETS'); //raw free socket count from env //(new env)
const MAX_FREE_SOCKETS = Math.min(rawFreeSockets, SAFE_THRESHOLD); //clamp free sockets to safe threshold //(new const)
if (rawFreeSockets > SAFE_THRESHOLD) { logger.then(l => l.warn(`max free sockets clamped ${rawFreeSockets}`)); } //warn when clamped //(new warn)


const parsedLimit = config.getInt('QERRORS_CACHE_LIMIT', 0); //parse limit with zero allowed
const ADVICE_CACHE_LIMIT = parsedLimit === 0 ? 0 : Math.min(parsedLimit, SAFE_THRESHOLD); //clamp to safe threshold when >0
if (parsedLimit > SAFE_THRESHOLD) { logger.then(l => l.warn(`cache limit clamped ${parsedLimit}`)); } //warn after logger ready
const CACHE_TTL_SECONDS = config.getInt('QERRORS_CACHE_TTL', 0); //expire advice after ttl seconds when nonzero //(new ttl env)

const adviceCache = new LRUCache({ max: ADVICE_CACHE_LIMIT || 0, ttl: CACHE_TTL_SECONDS * 1000 }); //create cache with ttl and max settings

let warnedMissingToken = false; //track if missing token message already logged

const axiosInstance = axios.create({ //axios instance with keep alive agents
        httpAgent: new http.Agent({ keepAlive: true, maxSockets: MAX_SOCKETS, maxFreeSockets: MAX_FREE_SOCKETS }), //reuse http connections with max free limit //(updated agent)
        httpsAgent: new https.Agent({ keepAlive: true, maxSockets: MAX_SOCKETS, maxFreeSockets: MAX_FREE_SOCKETS }), //reuse https connections with max free limit //(updated agent)
        timeout: config.getInt('QERRORS_TIMEOUT') //abort request after timeout
});



const limit = createLimiter(CONCURRENCY_LIMIT); //create limiter with stored concurrency without external module

let queueRejectCount = 0; //track how many analyses the queue rejects
let cleanupHandle = null; //hold interval id for periodic cache purge
let metricHandle = null; //store interval id for queue metric logging
const METRIC_INTERVAL_MS = config.getInt('QERRORS_METRIC_INTERVAL_MS', 0); //interval for metrics, zero disables

function startAdviceCleanup() { //(kick off periodic advice cleanup)
        if (CACHE_TTL_SECONDS === 0 || ADVICE_CACHE_LIMIT === 0 || cleanupHandle) { return; } //(skip when ttl or cache disabled or already scheduled)
        cleanupHandle = setInterval(purgeExpiredAdvice, CACHE_TTL_SECONDS * 1000); //(run purge at ttl interval)
        cleanupHandle.unref(); //(allow process exit without clearing interval)
}

function stopAdviceCleanup() { //(stop periodic purge when needed)
        if (!cleanupHandle) { return; } //(do nothing when no interval)
        clearInterval(cleanupHandle); //(cancel interval)
        cleanupHandle = null; //(reset handle state)
}

function logQueueMetrics() { //(write queue metrics to logger)
        logger.then(l => l.info(`metrics queueLength=${getQueueLength()} queueRejects=${getQueueRejectCount()}`));
        //(info level ensures operators can monitor queue health without triggering qerrors recursion on logging errors)
}

function startQueueMetrics() { //(begin periodic queue metric logging)
        if (metricHandle || METRIC_INTERVAL_MS === 0) { return; } //(avoid multiple intervals or disabled)
        metricHandle = setInterval(logQueueMetrics, METRIC_INTERVAL_MS); //(schedule logging every interval)
        metricHandle.unref(); //(allow process exit without manual cleanup)
}

function stopQueueMetrics() { //(halt metric emission)
        if (!metricHandle) { return; } //(no-op when not running)
        clearInterval(metricHandle); //(cancel metrics interval)
        metricHandle = null; //(reset handle state)
}



async function scheduleAnalysis(err, ctx) { //limit analyzeError concurrency
        startAdviceCleanup(); //(ensure cleanup interval scheduled once)
        const idle = limit.activeCount === 0 && limit.pendingCount === 0; //track if queue idle before scheduling
        const total = limit.pendingCount + limit.activeCount; //sum queued and active analyses
        if (total >= QUEUE_LIMIT) { queueRejectCount++; (await logger).warn(`analysis queue full pending ${limit.pendingCount} active ${limit.activeCount}`); return Promise.reject(new Error('queue full')); } //(reject when queue limit reached)
        const run = limit(() => analyzeError(err, ctx)); //queue via limiter and get promise
        if (idle) startQueueMetrics(); //(start metrics when queue transitions from idle)
        await run.finally(() => { if (limit.activeCount === 0 && limit.pendingCount === 0) stopQueueMetrics(); }); //(await finally to ensure proper cleanup timing)
        return run; //return scheduled promise
}

function getQueueRejectCount() { return queueRejectCount; } //expose reject count


function clearAdviceCache() { adviceCache.clear(); if (adviceCache.size === 0) { stopAdviceCleanup(); } } //empty cache and stop interval when empty

function purgeExpiredAdvice() { //trigger lru-cache cleanup cycle
        if (CACHE_TTL_SECONDS === 0 || ADVICE_CACHE_LIMIT === 0) { return; } //skip when ttl or cache disabled
        adviceCache.purgeStale(); if (adviceCache.size === 0) { stopAdviceCleanup(); } //remove expired entries and stop interval when empty
} //lru-cache handles its own batch logic

function getQueueLength() { return limit.pendingCount; } //expose queue length




async function postWithRetry(url, data, opts, capMs) { //post wrapper with retry logic and cap
        const retries = config.getInt('QERRORS_RETRY_ATTEMPTS'); //default retry count
        const base = config.getInt('QERRORS_RETRY_BASE_MS'); //base delay ms
        const cap = capMs !== undefined ? capMs : config.getInt('QERRORS_RETRY_MAX_MS', 0); //choose cap
        for (let i = 0; i <= retries; i++) { //attempt request with retries
                try { return await axiosInstance.post(url, data, opts); } //(try post once)
                catch (err) { //handle failure and compute wait
                        if (i >= retries) throw err; //throw when out of retries
                        const jitter = Math.random() * base; //random jitter added to delay
                        let wait = base * 2 ** i + jitter; //compute exponential delay with jitter
                        if (err.response && (err.response.status === 429 || err.response.status === 503)) { //detect rate limit
                                const retryAfter = err.response.headers?.['retry-after']; //header with wait seconds
                                if (retryAfter) { //parse header when provided
                                        const secs = Number(retryAfter); //numeric seconds when parsed
                                        if (!Number.isNaN(secs)) { wait = secs * 1000; } //use parsed seconds
                                        else {
                                                const date = Date.parse(retryAfter); //parse HTTP date string
                                                if (!Number.isNaN(date)) { wait = date - Date.now(); } //ms until retry date
                                        }
                                } else { wait *= 2; } //double delay when header missing
                        }
                        if (cap > 0 && wait > cap) { wait = cap; } //enforce cap when provided
                        await new Promise(r => setTimeout(r, wait)); //pause before next attempt
                }
        }
}
/**
 * Analyzes an error using OpenAI's API to provide intelligent debugging suggestions
 * 
 * This function represents the core AI-powered feature of qerrors. It sends error details
 * to OpenAI's API and returns actionable advice for developers.
 * 
 * Design rationale:
 * - Early return for AxiosErrors prevents infinite loops when network issues occur
 * - Environment variable check ensures graceful degradation without API keys
 * - Prompt engineering optimizes for practical, console-readable advice
 * - Response validation handles various API response formats safely
 * - Temperature=1 provides creative but relevant suggestions
 * - Max tokens=2048 balances detail with cost considerations
 * 
 * @param {Error} error - The error object containing name, message, and stack trace
 * @param {string} contextString - Contextual information already stringified by qerrors
 * @returns {Promise<Object|null>} - AI-generated advice object or null if analysis fails or is skipped for Axios errors //(update return description)
 */
async function analyzeError(error, contextString) {
        if (typeof error.name === 'string' && error.name.includes('AxiosError')) { //(skip axios error objects early to prevent infinite loops when our API calls fail)
                verboseLog(`Axios Error`); //(log axios detection for analysis skip)
                return null; //(avoid API call when axios error encountered)
        };

        verboseLog(`qerrors error analysis is running for
                        error name: "${error.uniqueErrorName}",
                        error message: "${error.message}",
                        with context: "${contextString}"`); //(log analysis attempt for debugging with pre-stringified context)

        if (ADVICE_CACHE_LIMIT !== 0 && !error.qerrorsKey) { //generate hash key when caching
                error.qerrorsKey = crypto.createHash('sha256').update(`${error.message}${error.stack}`).digest('hex'); //create cache key from message and stack
        }

        if (ADVICE_CACHE_LIMIT !== 0) { //lookup cached advice when enabled
                const cached = adviceCache.get(error.qerrorsKey); //fetch entry from lru-cache
                if (cached) { verboseLog(`cache hit for ${error.uniqueErrorName}`); return cached; } //return when present and valid
        }

        if (!process.env.OPENAI_TOKEN) { //(graceful degradation when API token unavailable)
                if (!warnedMissingToken) { //(check if warning already logged to avoid console spam)
                        console.error(`Missing OPENAI_TOKEN in environment variables.`); //(inform developer about missing token)
                        warnedMissingToken = true; //(set flag so we do not warn again on subsequent calls)
                }
                return null; //(skip analysis when token absent)
        }
        
        const truncatedStack = (error.stack || '').split('\n').slice(0, 20).join('\n'); //(limit stack trace to 20 lines for smaller API payloads and faster processing)
        const errorPrompt = `Analyze this error and provide debugging advice. You must respond with a valid JSON object containing an "advice" field with a concise solution:

Error: ${error.name} - ${error.message}
Context: ${contextString}
Stack: ${truncatedStack}`; //(JSON format prompt for structured response with explicit instruction)
        
        // OpenAI API call with optimized parameters for error analysis
        // Model choice balances capability with cost and response time
        // Parameters tuned for creative but focused debugging suggestions

        let response; //(will hold axios response from OpenAI API call)
        const openaiBody = { //(payload for OpenAI API structured for optimal error analysis)
                model: 'gpt-4o', //(GPT-4o model for optimal error analysis quality and speed)
                messages: [{ role: 'user', content: errorPrompt }], //(user role prompt to analyze error with context)
                response_format: { type: 'json_object' }, //(structured JSON response expected for consistent parsing)
                temperature: 1, //(creative but focused suggestions, balanced for debugging advice)
                max_tokens: config.getInt('QERRORS_MAX_TOKENS'), //(limit response length using configurable env setting)
                top_p: 1, //(full vocabulary access for technical terminology)
                frequency_penalty: 0, //(allow repetition when useful for error analysis)
                presence_penalty: 0 //(permit technical term usage without penalty)
        };
        try {
                response = await module.exports.postWithRetry(config.getEnv('QERRORS_OPENAI_URL'), openaiBody, { //use env url for retry //(use new env)
                        headers: {
                                'Authorization': `Bearer ${process.env.OPENAI_TOKEN}`,
                                'Content-Type': 'application/json'
                        }
                });
        } catch (apiErr) {
                verboseLog(`OpenAI request failed after retries`); //(log final failure after all retry attempts exhausted)
                return null; //(abort analysis when request fails entirely to prevent blocking)
        }
        let advice = response?.data?.choices?.[0]?.message?.content || null; //(capture raw advice which may be JSON string from API response)
        if (typeof advice === 'string') { //(convert string to object when possible for structured access)
                try { advice = JSON.parse(advice); } catch { advice = null; }; //(ignore parse errors gracefully to prevent crashes on malformed JSON)
        }
        if (advice && typeof advice === 'object') { //(validate response structure and handle different API response formats with defensive programming)
                verboseLog(`qerrors is returning advice for
                                the error name: "${error.uniqueErrorName}",
                                with the error message: "${error.message}",
                                with context: "${contextString}"`); //(log successful advice return with pre-stringified context)
                
                //(cache and return the parsed advice object directly)
                verboseLog(`${error.uniqueErrorName} ${JSON.stringify(advice)}`); //(stringify advice for consistent logging)
                if (ADVICE_CACHE_LIMIT !== 0) { adviceCache.set(error.qerrorsKey, advice); startAdviceCleanup(); } //cache advice and ensure cleanup interval
                return advice;
        } else {
                verboseLog(`Problem in analyzeError function of qerrors for ${error.uniqueErrorName}: ${error.message}`); //(log analysis failure for debugging and monitoring)
                return null; //(graceful failure allows application to continue without API dependency)
        }
}

/**
 * Main qerrors function - comprehensive error handling with AI analysis and smart response handling
 * 
 * This is the primary entry point for error processing. It handles the complete error lifecycle:
 * logging, analysis, response generation, and middleware chain continuation.
 * 
 * Design philosophy:
 * - Works as both Express middleware and standalone error handler
 * - Generates unique identifiers for error tracking and correlation
 * - Provides intelligent response format detection (HTML vs JSON)
 * - Maintains Express middleware contract while adding AI capabilities
 * - Implements defensive programming to prevent secondary errors
 * 
 * @param {Error} error - The error object to process
 * @param {string|Object} context - Descriptive context about where/when error occurred; objects are JSON stringified
 * @param {Object} [req] - Express request object (optional, enables middleware features)
 * @param {Object} [res] - Express response object (optional, enables automatic responses)
 * @param {Function} [next] - Express next function (optional, enables middleware chaining)
 * @returns {Promise<void>}
 */
async function qerrors(error, context, req, res, next) {
        // Input validation - prevent processing null/undefined errors
        // Early return prevents downstream errors and provides clear feedback
        if (!error) {
                console.warn('qerrors called without an error object');
                return;
        }

        // Context defaulting ensures we always have meaningful error context
        // This helps with debugging and error correlation across logs
        context = context || 'unknown context';
        const contextString = stringifyContext(context); //normalize context using helper to avoid circular errors
        
        // Generate unique error identifier for tracking and correlation
        // Format: "ERROR: " + errorType + timestamp + randomString
        // This allows linking related log entries and tracking error resolution
        const uniqueErrorName = `ERROR:${error.name}_${randomUUID()}`; //generate identifier via crypto uuid
        
        // Log error processing start with full context
        // Multi-line format improves readability in log aggregation systems
        verboseLog(`qerrors is running for error message: "${error.message}",
                        with context: "${contextString}",
                        assigning it the unique error name: "${uniqueErrorName}"`);
        
        // Generate ISO timestamp for consistent log timing across time zones
        // This is critical for distributed systems and log correlation
        const timestamp = new Date().toISOString(); //create standardized timestamp for logs
        
        // Destructure error properties with sensible defaults
        // This pattern handles custom error objects that may lack standard properties
        // Default values prevent undefined fields in logs and responses
        const {
                message = 'An error occurred', // Generic fallback message
                statusCode = 500, // HTTP 500 for unspecified server errors
                isOperational = true, // Assume operational error unless specified otherwise
        } = error;
        
        // Create comprehensive error log object
        // Structure designed for JSON logging systems and error tracking services
        // Includes all essential debugging information in a standardized format
        const errorLog = {
                uniqueErrorName, // For correlation and tracking
                timestamp, // For chronological analysis
                message, // Human-readable error description
                statusCode, // HTTP status for web context
                isOperational, // Distinguishes expected vs unexpected errors
                context: contextString, // Contextual information for debugging now stringified
                stack: error.stack // Full stack trace for technical debugging
        };
        
        // Augment original error object with unique identifier
        // This allows downstream code to reference this specific error instance
        error.uniqueErrorName = uniqueErrorName;
        
        // Log error through winston logger for persistent storage and processing
        // Uses structured logging format compatible with log aggregation systems
        (await logger).error(errorLog);
        

        
        // HTTP response handling - only if Express response object is available
        // Check headersSent prevents "Cannot set headers after they are sent" errors
        if (res && !res.headersSent) { //(send response only if headers not already sent to prevent double response errors)
                const acceptHeader = req?.headers?.['accept'] || null; //(inspect client preference for HTML via content negotiation for appropriate response format)
                
                if (acceptHeader && acceptHeader.includes('text/html')) { //(browser client detected via Accept header)
                        const safeMsg = escapeHtml(message); //(escape message for safe HTML display preventing XSS)
                        const safeStack = escapeHtml(error.stack || 'No stack trace available'); //(escape stack trace for safe HTML rendering)
                        const htmlErrorPage = `
                                <!DOCTYPE html>
                                <html>
                                <head>
                                        <title>Error: ${statusCode}</title>
                                        <style>
                                                body { font-family: sans-serif; padding: 2em; }
                                                .error { color: #d32f2f; }
                                                pre { background: #f5f5f5; padding: 1em; border-radius: 4px; overflow: auto; }
                                        </style>
                                </head>
                                <body>
                                        <h1 class="error">Error: ${statusCode}</h1>
                                        <h2>${safeMsg}</h2>
                                        <pre>${safeStack}</pre>
                                </body>
                                </html>
                        `; //(generate HTML error page for browser requests with inline CSS to avoid external dependencies)
                        res.status(statusCode).send(htmlErrorPage); //(send user-friendly HTML error page with technical details for developers)
                } else {
                        res.status(statusCode).json({ error: errorLog }); //(JSON response for API clients and AJAX requests with structured format for programmatic error handling)
                }
        }
        if (next) { //(Express middleware chain continuation when next function provided)
                if (!res || !res.headersSent) { //(only call next if headers not sent to prevent response conflicts)
                        next(error); //(pass error to next middleware for additional processing while maintaining Express contract)
                }
        }

        Promise.resolve() //(start async analysis without blocking response to maintain fast error handling)
                .then(() => scheduleAnalysis(error, contextString)) //(invoke queued analysis after sending response with context string)
                .catch(async (analysisErr) => (await logger).error(analysisErr)); //(log any scheduleAnalysis failures to prevent silent errors)

        verboseLog(`qerrors ran`); //(log completion after scheduling analysis for debugging flow)
}

/**
 * Logs error with appropriate severity and context using qerrors integration
 * 
 * Design rationale: Centralized error logging ensures consistent log format
 * and enables proper monitoring and alerting. Different severities enable
 * appropriate routing to different logging destinations.
 * 
 * @param {Object} error - Error object or Error instance
 * @param {string} functionName - Name of function where error occurred
 * @param {Object} context - Request context and additional information
 * @param {string} severity - Error severity level from ErrorSeverity
 */
async function logErrorWithSeverity(error, functionName, context = {}, severity = errorTypes.ErrorSeverity.MEDIUM) { //log with severity context using qerrors
        const logContext = { //build enhanced context with severity information
                ...context,
                severity, //attach severity for filtering and alerting
                timestamp: new Date().toISOString(), //standardized timestamp
                requestId: context.requestId || errorTypes.getRequestId(context.req) //ensure request correlation
        };

        // Use existing qerrors for consistent logging and AI analysis
        await qerrors(error, functionName, logContext);

        // Additional console logging based on severity for immediate visibility
        if (severity === errorTypes.ErrorSeverity.CRITICAL) {
                console.error(`CRITICAL ERROR in ${functionName}:`, { //immediate critical error visibility
                        error: error.message || error,
                        context: logContext
                });
        } else if (severity === errorTypes.ErrorSeverity.HIGH) {
                console.error(`HIGH SEVERITY ERROR in ${functionName}:`, { //immediate high severity visibility
                        error: error.message || error,
                        context: logContext
                });
        }
}

/**
 * Handles controller errors with standardized response using qerrors integration
 * 
 * Design rationale: Provides consistent error handling across all controllers
 * while maintaining existing qerrors functionality. Automatically determines
 * appropriate status codes and response format based on error classification.
 * 
 * @param {Object} res - Express response object
 * @param {Object} error - Error object or Error instance
 * @param {string} functionName - Name of function where error occurred
 * @param {Object} context - Request context
 * @param {string} userMessage - Optional user-friendly message override
 */
async function handleControllerError(res, error, functionName, context = {}, userMessage = null) { //send standardized error response with qerrors integration
        const errorType = error.type || errorTypes.ErrorTypes.SYSTEM; //default to system error when type missing
        const severity = errorTypes.ERROR_SEVERITY_MAP[errorType]; //determine severity from error type
        const statusCode = errorTypes.ERROR_STATUS_MAP[errorType]; //determine HTTP status from error type

        // Log the error with appropriate severity using qerrors
        await logErrorWithSeverity(error, functionName, context, severity);

        // Create standardized error response object
        const errorResponse = errorTypes.createStandardError(
                error.code || 'INTERNAL_ERROR', //error code for programmatic handling
                userMessage || error.message || 'An internal error occurred', //user-friendly message
                errorType, //error classification
                context //debugging context
        );

        // Send standardized JSON response using errorTypes utility
        errorTypes.sendErrorResponse(res, statusCode, errorResponse);
}

/**
 * Wraps async operations with standardized error handling using qerrors
 * 
 * Design rationale: Reduces boilerplate code in controllers while ensuring
 * consistent error handling through qerrors. Automatically catches and handles
 * errors according to their type and severity.
 * 
 * @param {Function} operation - Async operation to execute
 * @param {string} functionName - Name for logging purposes
 * @param {Object} context - Request context
 * @param {*} fallback - Fallback value on error (optional)
 * @returns {*} Operation result or fallback value
 */
async function withErrorHandling(operation, functionName, context = {}, fallback = null) { //execute operation with qerrors safety net
        try {
                const result = await operation(); //execute provided async operation
                verboseLog(`${functionName} completed successfully`); //log successful completion when verbose
                return result; //return operation result
        } catch (error) {
                // Determine error severity and log through qerrors
                const severity = error.severity || errorTypes.ErrorSeverity.MEDIUM; //use error severity or default
                await logErrorWithSeverity(error, functionName, context, severity); //log with qerrors integration
                return fallback; //return fallback value on error
        }
}

module.exports = qerrors; //(export main qerrors function as default export providing primary interface most users interact with)

module.exports.analyzeError = analyzeError; //(expose analyzeError for testing and advanced usage scenarios allowing unit testing of AI analysis in isolation)
module.exports.axiosInstance = axiosInstance; //export axios instance for testing
module.exports.postWithRetry = postWithRetry; //export retry helper for tests
module.exports.getQueueRejectCount = getQueueRejectCount; //export queue reject count

module.exports.clearAdviceCache = clearAdviceCache; //export cache clearing function
module.exports.purgeExpiredAdvice = purgeExpiredAdvice; //export ttl cleanup function
module.exports.startAdviceCleanup = startAdviceCleanup; //export cleanup scheduler
module.exports.stopAdviceCleanup = stopAdviceCleanup; //export cleanup canceller

module.exports.startQueueMetrics = startQueueMetrics; //export metrics scheduler
module.exports.stopQueueMetrics = stopQueueMetrics; //export metrics canceller

module.exports.getQueueLength = getQueueLength; //export queue length
function getAdviceCacheLimit() { return ADVICE_CACHE_LIMIT; } //expose clamped cache limit for tests
module.exports.getAdviceCacheLimit = getAdviceCacheLimit; //export clamp accessor

module.exports.logErrorWithSeverity = logErrorWithSeverity; //export severity-based logging function
module.exports.handleControllerError = handleControllerError; //export standardized controller error handler
module.exports.withErrorHandling = withErrorHandling; //export async operation wrapper
module.exports.errorTypes = errorTypes; //export error classification utilities
</file>

<file path="README.md">
# qerrors

Intelligent error handling middleware that combines traditional logging with AI-powered debugging assistance. When errors occur, qerrors automatically generates contextual suggestions using OpenAI's GPT models while maintaining fast response times through asynchronous analysis and intelligent caching.

## Environment Variables


qerrors reads several environment variables to tune its behavior. A small configuration file in the library sets sensible defaults when these variables are not defined. Only `OPENAI_TOKEN` must be provided manually to enable AI analysis. Obtain your key from [OpenAI](https://openai.com) and set the variable in your environment.

If `OPENAI_TOKEN` is omitted qerrors still logs errors, but AI-generated advice will be skipped.

**Security Note**: Keep your OpenAI API key secure. Never commit it to version control or expose it in client-side code. Use environment variables or secure configuration management.

**Dependencies**: This package includes production-grade security improvements with the `escape-html` library for safe HTML output.

* `OPENAI_TOKEN` &ndash; your OpenAI API key.

* `QERRORS_OPENAI_URL` &ndash; OpenAI API endpoint (default `https://api.openai.com/v1/chat/completions`).
* `QERRORS_CONCURRENCY` &ndash; maximum concurrent analyses (default `5`, raise for high traffic, values over `1000` are clamped).


* `QERRORS_CACHE_LIMIT` &ndash; size of the advice cache (default `50`, set to `0` to disable caching, values over `1000` are clamped).
* `QERRORS_CACHE_TTL` &ndash; seconds before cached advice expires (default `86400`).
* `QERRORS_QUEUE_LIMIT` &ndash; maximum queued analyses before rejecting new ones (default `100`, raise when under heavy load, values over `QERRORS_SAFE_THRESHOLD` are clamped).
* `QERRORS_SAFE_THRESHOLD` &ndash; limit at which `QERRORS_CONCURRENCY` and `QERRORS_QUEUE_LIMIT` are clamped (default `1000`, increase to raise their allowed upper bound).


* `QERRORS_RETRY_ATTEMPTS` &ndash; attempts when calling OpenAI (default `2`).
* `QERRORS_RETRY_BASE_MS` &ndash; base delay in ms for retries (default `100`).
* `QERRORS_RETRY_MAX_MS` &ndash; cap on retry backoff in ms (default `2000`).
* `QERRORS_TIMEOUT` &ndash; axios request timeout in ms (default `10000`).
* `QERRORS_MAX_SOCKETS` &ndash; maximum sockets per agent (default `50`, increase for high traffic).
* `QERRORS_MAX_FREE_SOCKETS` &ndash; maximum idle sockets per agent (default `256`).

* `QERRORS_MAX_TOKENS` &ndash; max tokens for each OpenAI request (default `2048`). Uses GPT-4o model for error analysis.

* `QERRORS_METRIC_INTERVAL_MS` &ndash; interval for queue metric logging in milliseconds (default `30000`, set to `0` to disable).


* `QERRORS_LOG_MAXSIZE` &ndash; logger rotation size in bytes (default `1048576`).
* `QERRORS_LOG_MAXFILES` &ndash; number of rotated log files (default `5`).
  * `QERRORS_LOG_MAX_DAYS` &ndash; days to retain daily logs (default `0`). A value of `0` keeps all logs forever and emits a startup warning; set a finite number in production to manage disk usage.
* `QERRORS_VERBOSE` &ndash; enable console logging (`false` by default). Set `QERRORS_VERBOSE=false` for production deployments to keep logs from flooding the console and rely on file output instead.
* `QERRORS_LOG_DIR` &ndash; directory for logger output (default `logs`).
* `QERRORS_DISABLE_FILE_LOGS` &ndash; disable file transports when set.
* `QERRORS_LOG_LEVEL` &ndash; logger output level (default `info`).
* `QERRORS_SERVICE_NAME` &ndash; service name added to logger metadata (default `qerrors`).

For high traffic scenarios raise `QERRORS_CONCURRENCY`, `QERRORS_QUEUE_LIMIT`, `QERRORS_MAX_SOCKETS`, and `QERRORS_MAX_FREE_SOCKETS`. Set `QERRORS_VERBOSE=false` in production to reduce console overhead.


Set QERRORS_CONCURRENCY to adjust how many analyses run simultaneously;
if not set the default limit is 5; raise this for high traffic.

Use QERRORS_QUEUE_LIMIT to cap how many analyses can wait in line before rejection;
if not set the default limit is 100; increase when expecting heavy load.
The pending queue uses a double ended queue from the denque package for efficient O(1) dequeues.

Whenever the queue rejects an analysis the module increments an internal counter.
Check it with `qerrors.getQueueRejectCount()`.

Call `qerrors.clearAdviceCache()` to manually empty the advice cache.
Use `qerrors.startAdviceCleanup()` to begin automatic purging of expired entries.
Call `qerrors.stopAdviceCleanup()` if you need to halt the cleanup interval.
Call `qerrors.purgeExpiredAdvice()` to run a purge instantly.
After each purge or clear operation the module checks the cache size and stops cleanup when it reaches zero, restarting the interval when new advice is cached.
Check the current cache limit with `qerrors.getAdviceCacheLimit()`.

Use `qerrors.getQueueLength()` to monitor how many analyses are waiting.

The module logs `queueLength` and `queueRejects` at a regular interval (default `30s`). Use `QERRORS_METRIC_INTERVAL_MS` to change the period or set `0` to disable logging. Logging starts with the first queued analysis and stops automatically when no analyses remain.

Call `qerrors.startQueueMetrics()` to manually begin metric logging and `qerrors.stopQueueMetrics()` to halt it when needed.

QERRORS_MAX_SOCKETS lets you limit how many sockets the http agents open;
if not set the default is 50; raise this to handle high traffic.
QERRORS_MAX_FREE_SOCKETS caps idle sockets the agents keep for reuse;
if not set the default is 256 which matches Node's agent default.
QERRORS_MAX_TOKENS sets the token limit for OpenAI responses;
if not set the default is 2048 which balances cost and detail.



The retry behaviour can be tuned with QERRORS_RETRY_ATTEMPTS, QERRORS_RETRY_BASE_MS and QERRORS_RETRY_MAX_MS which default to 2, 100 and 2000 respectively.
When the API responds with 429 or 503 qerrors uses the `Retry-After` header to wait before retrying; if the header is missing the computed delay is doubled.

You can optionally set `QERRORS_CACHE_LIMIT` to adjust how many advice entries are cached; set `0` to disable caching (default is 50, values over `1000` are clamped). Use `QERRORS_CACHE_TTL` to control how long each entry stays valid in seconds (default is 86400).

Additional options control the logger's file rotation:

* `QERRORS_LOG_MAXSIZE` - max log file size in bytes before rotation (default `1048576`)
* `QERRORS_LOG_MAXFILES` - number of rotated files to keep (default `5`)
  * `QERRORS_LOG_MAX_DAYS` - number of days to keep daily logs (default `0`). A value of `0` retains logs forever and triggers a startup warning; specify a finite number in production to manage disk usage.
* `QERRORS_LOG_DIR` - path for log files (default `logs`)
* `QERRORS_DISABLE_FILE_LOGS` - omit file logs when set
* `QERRORS_SERVICE_NAME` - service name added to logger metadata (default `qerrors`)




## License

ISC

## Installation

**Requirements**: Node.js 18 or higher

```bash
npm install qerrors
```

## Usage

### Basic Setup

First, set your OpenAI API key:
```bash
export OPENAI_TOKEN="your-openai-api-key-here"
```

Import the module:
```javascript
// Import just qerrors:
const {qerrors} = require('qerrors');
// OR import both qerrors and logger:
const { qerrors, logger } = require('qerrors');
const log = await logger; //await logger initialization before use

// Import centralized error handling utilities:
const { 
  qerrors, 
  handleControllerError, 
  withErrorHandling, 
  createTypedError,
  ErrorTypes,
  ErrorSeverity,
  ErrorFactory,
  errorMiddleware
} = require('qerrors');
```

## Centralized Error Handling

The module now includes centralized error handling utilities that provide standardized error classification, severity-based logging, and automated response formatting:

### Error Classification

```javascript
// Create typed errors with automatic classification
const validationError = createTypedError(
  'Invalid email format',
  ErrorTypes.VALIDATION,
  'INVALID_EMAIL'
);

const dbError = createTypedError(
  'Connection timeout',
  ErrorTypes.DATABASE,
  'DB_TIMEOUT'
);

// Available error types:
ErrorTypes.VALIDATION      // 400 - User input errors
ErrorTypes.AUTHENTICATION  // 401 - Auth failures  
ErrorTypes.AUTHORIZATION   // 403 - Permission errors
ErrorTypes.NOT_FOUND       // 404 - Resource not found
ErrorTypes.RATE_LIMIT      // 429 - Rate limiting
ErrorTypes.NETWORK         // 502 - External service errors
ErrorTypes.DATABASE        // 500 - Database errors
ErrorTypes.SYSTEM          // 500 - Internal system errors
ErrorTypes.CONFIGURATION   // 500 - Config/setup errors
```

### Convenient Error Factory

```javascript
// Use ErrorFactory for common error scenarios with consistent formatting
const validationError = ErrorFactory.validation('Email is required', 'email');
const authError = ErrorFactory.authentication('Invalid credentials');
const notFoundError = ErrorFactory.notFound('User');
const dbError = ErrorFactory.database('Connection failed', 'INSERT');

// All factory methods accept optional context
const networkError = ErrorFactory.network(
  'API timeout', 
  'payment-service', 
  { timeout: 5000, retries: 3 }
);
```

### Controller Error Handling

```javascript
// Standardized error handling in Express controllers
app.get('/api/users/:id', async (req, res) => {
  try {
    const user = await getUserById(req.params.id);
    if (!user) {
      const error = createTypedError(
        'User not found',
        ErrorTypes.NOT_FOUND,
        'USER_NOT_FOUND'
      );
      return handleControllerError(res, error, 'getUserById', { userId: req.params.id });
    }
    res.json(user);
  } catch (error) {
    handleControllerError(res, error, 'getUserById', { userId: req.params.id });
  }
});
```

### Async Operation Wrapper

```javascript
// Wrap async operations with automatic error handling
const result = await withErrorHandling(
  async () => {
    return await complexAsyncOperation();
  },
  'complexAsyncOperation',
  { userId: req.user.id },
  { fallback: 'default_value' } // optional fallback
);
```

### Severity-Based Logging

```javascript
// Log errors with appropriate severity levels
await logErrorWithSeverity(
  error,
  'functionName',
  { context: 'additional info' },
  ErrorSeverity.CRITICAL
);

// Available severity levels:
ErrorSeverity.LOW       // Expected errors, user mistakes
ErrorSeverity.MEDIUM    // Operational issues, recoverable  
ErrorSeverity.HIGH      // Service degradation, requires attention
ErrorSeverity.CRITICAL  // Service disruption, immediate response needed
```

### Global Error Middleware

```javascript
// Add global error handling to your Express app
const express = require('express');
const app = express();

// Your routes here...
app.get('/api/users/:id', async (req, res) => {
  const user = await getUserById(req.params.id);
  if (!user) {
    throw ErrorFactory.notFound('User');
  }
  res.json(user);
});

// Add error middleware as the last middleware
app.use(errorMiddleware);

// The middleware will automatically:
// - Log errors with qerrors AI analysis
// - Send standardized JSON responses
// - Map error types to appropriate HTTP status codes
// - Include request context for debugging
```

## Basic Usage

```javascript
// Example of using qerrors as Express middleware:
app.use((err, req, res, next) => {
        qerrors(err, 'RouteName', req, res, next);
});

// Using qerrors in any catch block:
function doFunction(req, res, next) {
        try {
                //code
        } catch (error) {
                qerrors(error, "doFunction", req, res, next); //req res and next are optional
        }
}

// Response Format: qerrors automatically detects client type
// - Browser requests (Accept: text/html) receive HTML error pages
// - API requests receive JSON error responses with structured data

// Example for javascript that is not express related (node / service code / biz logic)
function doFunction(param) {
        try {
                //code
        } catch (error) {
                qerrors(error, "doFunction", param);
        }
}

// ... or if multiple params:
function doFunction(param1, param2) {
        try {
                //code
        } catch (error) {
                qerrors(error, "doFunction", {param1, param2}); 
        }
}

// Using the Winston logger directly:
log.info('Application started');
log.warn('Something might be wrong');
log.error('An error occurred', { errorDetails: error });
// Optional helpers for consistent function logging
await logger.logStart('myFunction', {input});
await logger.logReturn('myFunction', {result});
```

### Environment Validation Helpers

Use the optional utilities in `lib/envUtils.js` to verify configuration before starting your application.

```javascript
const { throwIfMissingEnvVars, warnIfMissingEnvVars, getMissingEnvVars } = require('qerrors/lib/envUtils');

throwIfMissingEnvVars(['OPENAI_TOKEN']); // aborts if mandatory variables are missing
warnIfMissingEnvVars(['MY_OPTIONAL_VAR']); // logs a warning but continues
const missing = getMissingEnvVars(['OPTIONAL_ONE', 'OPTIONAL_TWO']);
```


### Features

- **AI-Powered Analysis**: Automatically generates debugging suggestions using OpenAI GPT-4o model
- **Express Middleware**: Seamless integration with Express.js applications
- **Content Negotiation**: Returns HTML pages for browsers, JSON for API clients
- **Intelligent Caching**: Prevents duplicate API calls for identical errors
- **Queue Management**: Handles high-traffic scenarios with configurable concurrency limits
- **Graceful Degradation**: Functions normally even without OpenAI API access
- **Comprehensive Logging**: Multi-transport Winston logging with file rotation

### Logging

File transports output JSON objects with timestamps and stack traces. Console
output, enabled when `QERRORS_VERBOSE=true`, uses a compact printf format for
readability.

### Error Response Formats

**HTML Response** (for browsers):
```html
<!DOCTYPE html>
<html>
<head><title>Error: 500</title></head>
<body>
    <h1 class="error">Error: 500</h1>
    <h2>Internal Server Error</h2>
    <pre>Error stack trace...</pre>
</body>
</html>
```

**JSON Response** (for APIs):
```json
{
  "error": {
    "uniqueErrorName": "ERROR:TypeError_abc123",
    "timestamp": "2024-01-01T00:00:00.000Z",
    "message": "Cannot read property 'foo' of undefined",
    "statusCode": 500,
    "context": "userController",
    "stack": "TypeError: Cannot read property..."
  }
}
```

## Testing

The test suite uses Node's built-in test runner with custom stubs for offline testing.
Tests include comprehensive coverage of error handling, AI integration, and middleware functionality.
Current test status: 87/87 tests passing (100% success rate).

Run tests from the project directory:
```bash
npm test
```
Or directly:
```bash
node -r ./setup.js --test
```

**Test Coverage Includes:**
- Core error handling and middleware functionality
- OpenAI API integration with mock responses
- Environment variable validation and configuration
- Cache management and TTL behavior
- Queue concurrency and rejection handling
- Logger configuration across different environments

GitHub Actions runs this test suite automatically on every push and pull request using Node.js LTS. The workflow caches npm dependencies to speed up subsequent runs.
</file>

</files>
